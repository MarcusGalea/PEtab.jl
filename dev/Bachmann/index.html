<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Medium sized models and adjoint sensitivity analysis · PEtab.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link rel="canonical" href="https://sebapersson.github.io/PEtab.jl/Bachmann/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">PEtab.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../Boehm/">Getting started</a></li><li><span class="tocitem">Tutorials</span><ul><li><a class="tocitem" href="../Brannmark/">Models with preequilibration (steady-state simulation)</a></li><li class="is-active"><a class="tocitem" href>Medium sized models and adjoint sensitivity analysis</a><ul class="internal"><li><a class="tocitem" href="#Adjoint-sensitivity-analysis"><span>Adjoint sensitivity analysis</span></a></li><li><a class="tocitem" href="#Forward-sensitivity-analysis-and-Gauss-Newton-hessian-approximation"><span>Forward sensitivity analysis and Gauss-Newton hessian approximation</span></a></li></ul></li><li><a class="tocitem" href="../Beer/">Models with many conditions specific parameters</a></li><li><a class="tocitem" href="../Parameter_estimation/">Parameter estimation</a></li></ul></li><li><a class="tocitem" href="../Gradient_hessian_support/">Supported gradient and hessian methods</a></li><li><a class="tocitem" href="../Best_options/">Choosing the best options for a PEtab problem</a></li><li><a class="tocitem" href="../API_choosen/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Tutorials</a></li><li class="is-active"><a href>Medium sized models and adjoint sensitivity analysis</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Medium sized models and adjoint sensitivity analysis</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/sebapersson/PEtab.jl/blob/main/docs/src/Bachmann.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Medium-sized-models-(Bachmann-model)"><a class="docs-heading-anchor" href="#Medium-sized-models-(Bachmann-model)">Medium-sized models (Bachmann model)</a><a id="Medium-sized-models-(Bachmann-model)-1"></a><a class="docs-heading-anchor-permalink" href="#Medium-sized-models-(Bachmann-model)" title="Permalink"></a></h1><p>In this tutorial we show to create <code>PEtabODEproblem</code> for the medium-sized Bachmann model, and i) how to compute the gradient via forward-sensitivity equations, ii) compute the gradient via adjoint sensitivity analysis and iii) how to compute the Gauss-Newton hessian approximation. The latter often perform better than the (L)-BFGS Hessian approximation.</p><p>To run the code you need the Bachmann PEtab files which can be found <a href="https://github.com/sebapersson/PEtab.jl/tree/main/examples/Bachmann">here</a>. A fully runnable example of this tutorial can be found <a href="https://github.com/sebapersson/PEtab.jl/tree/main/examples/Bachmann.jl">here</a>.</p><p>First we read the model and load necessary libraries.</p><pre><code class="language-julia hljs">using PEtab
using OrdinaryDiffEq
using Sundials # For CVODE_BDF
using SciMLSensitivity # For adjoint
using Printf
 
pathYaml = joinpath(@__DIR__, &quot;Bachmann&quot;, &quot;Bachmann_MSB2011.yaml&quot;) 
petabModel = readPEtabModel(pathYaml, verbose=true)</code></pre><pre><code class="nohighlight hljs">PEtabModel for model Bachmann. ODE-system has 25 states and 39 parameters.
Generated Julia files are at ...</code></pre><h2 id="Adjoint-sensitivity-analysis"><a class="docs-heading-anchor" href="#Adjoint-sensitivity-analysis">Adjoint sensitivity analysis</a><a id="Adjoint-sensitivity-analysis-1"></a><a class="docs-heading-anchor-permalink" href="#Adjoint-sensitivity-analysis" title="Permalink"></a></h2><p>For a subset of medium-sized and definitely for big models gradients are most efficiently computed via adjoint sensitivity analysis (<code>gradientMethod=:Adjoint</code>). For adjoint there are several tuneable options that can improve performance, some key ones are:</p><ol><li><code>odeSolverGradientOptions</code> - Which ODE solver and solver tolerances (<code>abstol</code> and <code>reltol</code>) to use when computing the gradient (in this case when solving the adjoint ODE-system). Below we use <code>CVODE_BDF()</code> which currently is the best performing stiff solver for the adjoint problem in Julia.</li><li><code>sensealg</code> - which adjoint algorithm to use. Currently, we support <code>InterpolatingAdjoint</code> and <code>QuadratureAdjoint</code> from SciMLSensitivity (see their <a href="https://github.com/SciML/SciMLSensitivity.jl">documentation</a> for info). The user can provide any of the options these methods are compatible with, so if you want to use the ReverseDiffVJP an acceptable option is; <code>sensealg=InterpolatingAdjoint(autojacvec=ReversDiffVJP())</code>.</li></ol><ul><li><strong>Note1</strong> - currently adjoint sensitivity analysis is not as reliable in Julia as in AMICI (https://github.com/SciML/SciMLSensitivity.jl/issues/795), but our benchmarks show that SciMLSensitivity has the potential to be faster.</li><li><strong>Note2</strong> - the compilation times can be quite substantial for adjoint sensitivity analysis.</li><li><strong>Note3</strong> - below we use QNDF for the cost which often is one of the best Julia solvers for larger models.</li></ul><pre><code class="language-julia hljs">solverOptions = getODESolverOptions(QNDF(), abstol=1e-8, reltol=1e-8) 
solverGradientOptions = getODESolverOptions(CVODE_BDF(), abstol=1e-8, reltol=1e-8) 
petabProblem = setupPEtabODEProblem(petabModel, solverOptions, 
                                    odeSolverGradientOptions=solverGradientOptions,
                                    gradientMethod=:Adjoint, 
                                    sensealg=InterpolatingAdjoint(autojacvec=EnzymeVJP())) 
p = petabProblem.θ_nominalT 
gradient = zeros(length(p)) 
cost = petabProblem.computeCost(p)
petabProblem.computeGradient!(gradient, p)
@printf(&quot;Cost = %.2f\n&quot;, cost)
@printf(&quot;First element in the gradient = %.2e\n&quot;, gradient[1])</code></pre><pre><code class="nohighlight hljs">Cost = -418.41
First element in the gradient = -1.70e-03</code></pre><h2 id="Forward-sensitivity-analysis-and-Gauss-Newton-hessian-approximation"><a class="docs-heading-anchor" href="#Forward-sensitivity-analysis-and-Gauss-Newton-hessian-approximation">Forward sensitivity analysis and Gauss-Newton hessian approximation</a><a id="Forward-sensitivity-analysis-and-Gauss-Newton-hessian-approximation-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-sensitivity-analysis-and-Gauss-Newton-hessian-approximation" title="Permalink"></a></h2><p>For medium-sized models computing the full Hessian via forward-mode automatic differentiation is often too expansive, thus we need some approximation. The <a href="https://en.wikipedia.org/wiki/Gauss%E2%80%93Newton_algorithm">Guass-Newton</a> (GN)approximation often performs better than the (L)-BFGS approximation. To compute it we need the forward sensitivities. These sensitives can also be used to compute the gradient. As some optmizers such as Fides.py compute both the hessian and gradient at each iteration we can be smart here and save the sensitives between the gradient and hessian computations.</p><p>When choosing <code>gradientMethod=:ForwardEquations</code> and <code>hessianMethod=:GaussNewton</code> there are several tuneable options, key ones are:</p><ol><li><code>sensealg</code> - which sensitivity algorithm to use when computing for the sensitives. We support both <code>ForwardSensitivity()</code> and <code>ForwardDiffSensitivity()</code> with tuneable options as provided by SciMLSensitivity (see their <a href="https://github.com/SciML/SciMLSensitivity.jl">documentation</a> for info). The most efficient option though is <code>:ForwardDiff</code> where forward mode automatic differentiation is used to compute the sensitivities.</li><li><code>reuseS::Bool</code> - whether to reuse the sensitives from the gradient computations when computing the Gauss-Newton hessian-approximation. Whether this option is applicable depends on the optimizers, for example it works with Fides.py but not <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl:s</a> <code>IPNewton()</code>.<ul><li>Note - this approach requires that <code>sensealg=:ForwardDiff</code> for the gradient.</li></ul></li></ol><pre><code class="language-julia hljs">odeSolverOptions = getODESolverOptions(QNDF(), abstol=1e-8, reltol=1e-8) 
petabProblem = setupPEtabODEProblem(petabModel, odeSolverOptions, 
                                    gradientMethod=:ForwardEquations, 
                                    hessianMethod=:GaussNewton,
                                    sensealg=:ForwardDiff, 
                                    reuseS=true) 
p = petabProblem.θ_nominalT 
gradient = zeros(length(p)) 
hessian = zeros(length(p), length(p)) 
cost = petabProblem.computeCost(p)
petabProblem.computeGradient!(gradient, p)
petabProblem.computeHessian!(hessian, p)
@printf(&quot;Cost for Bachmann = %.2f\n&quot;, cost)
@printf(&quot;First element in the gradient = %.2e\n&quot;, gradient[1])
@printf(&quot;First element in the Gauss-Newton Hessian = %.2f\n&quot;, hessian[1, 1])</code></pre><pre><code class="nohighlight hljs">Cost for Bachmann = -418.41
First element in the gradient = -1.85e-03
First element in the Gauss-Newton Hessian = 584.10</code></pre></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Brannmark/">« Models with preequilibration (steady-state simulation)</a><a class="docs-footer-nextpage" href="../Beer/">Models with many conditions specific parameters »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.24 on <span class="colophon-date" title="Friday 14 April 2023 08:44">Friday 14 April 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
