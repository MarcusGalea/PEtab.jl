<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Parameter estimation · PEtab.jl</title><meta name="title" content="Parameter estimation · PEtab.jl"/><meta property="og:title" content="Parameter estimation · PEtab.jl"/><meta property="twitter:title" content="Parameter estimation · PEtab.jl"/><meta name="description" content="Documentation for PEtab.jl."/><meta property="og:description" content="Documentation for PEtab.jl."/><meta property="twitter:description" content="Documentation for PEtab.jl."/><meta property="og:url" content="https://sebapersson.github.io/PEtab.jl/Parameter_estimation/"/><meta property="twitter:url" content="https://sebapersson.github.io/PEtab.jl/Parameter_estimation/"/><link rel="canonical" href="https://sebapersson.github.io/PEtab.jl/Parameter_estimation/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">PEtab.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../Boehm/">Importing problems in PEtab standard format</a></li><li><span class="tocitem">Defining a PEtab problem in Julia</span><ul><li><a class="tocitem" href="../Define_in_julia/">Defining parameter estimation problems in Julia</a></li><li><a class="tocitem" href="../Julia_steady_state/">Pre-equilibration (steady-state simulations)</a></li><li><a class="tocitem" href="../Julia_obs_noise/">Noise and observable parameters</a></li><li><a class="tocitem" href="../Julia_condition_specific/">Condition specific system/model parameters</a></li><li><a class="tocitem" href="../Julia_event/">Events (callbacks, dosages etc...)</a></li></ul></li><li><span class="tocitem">Options for specific problem types</span><ul><li><a class="tocitem" href="../Brannmark/">Models with pre-equilibration (steady-state simulation)</a></li><li><a class="tocitem" href="../Bachmann/">Medium sized models and adjoint sensitivity analysis</a></li><li><a class="tocitem" href="../Beer/">Models with many conditions specific parameters</a></li></ul></li><li><span class="tocitem">Parameter estimation</span><ul><li class="is-active"><a class="tocitem" href>Parameter estimation</a><ul class="internal"><li><a class="tocitem" href="#Multi-Start-Local-Optimization"><span>Multi-Start Local Optimization</span></a></li><li><a class="tocitem" href="#get_startguesses"><span>Generating startguesses for parameter estimation</span></a></li><li><a class="tocitem" href="#Single-Start-Parameter-Estimation"><span>Single-Start Parameter Estimation</span></a></li></ul></li><li><a class="tocitem" href="../Avaible_optimisers/">Available optimisers</a></li><li><a class="tocitem" href="../Model_selection/">Model selection (PEtab select)</a></li><li><a class="tocitem" href="../optimisation_output_plotting/">Plots evaluating parameter estimation</a></li></ul></li><li><a class="tocitem" href="../Gradient_hessian_support/">Supported gradient and hessian methods</a></li><li><a class="tocitem" href="../Best_options/">Choosing the best options for a PEtab problem</a></li><li><a class="tocitem" href="../API_choosen/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Parameter estimation</a></li><li class="is-active"><a href>Parameter estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Parameter estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sebapersson/PEtab.jl/blob/main/docs/src/Parameter_estimation.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="parameter_estimation"><a class="docs-heading-anchor" href="#parameter_estimation">Parameter Estimation (Model Calibration)</a><a id="parameter_estimation-1"></a><a class="docs-heading-anchor-permalink" href="#parameter_estimation" title="Permalink"></a></h1><p>PEtab.jl provides interfaces to four optimization packages:</p><ul><li><a href="https://julianlsolvers.github.io/Optim.jl/stable/">Optim</a>: Supports LBFGS, BFGS, or IPNewton methods.</li><li><a href="https://coin-or.github.io/Ipopt/">IpoptOptimiser</a>: An interior-point optimizer.</li><li><a href="https://github.com/fides-dev/fides">Fides</a>: A Newton trust region method.</li><li><a href="https://github.com/fides-dev/fides">Optimization.jl</a>: PEtab provides support for converting a <code>PEtabODEProblem</code> into an <code>OptimizationProblem</code>, allowing the use of any optimizer from Optimization.jl.</li></ul><p>You can find available options for each optimizer in the <a href="../Avaible_optimisers/#options_optimizers">Available Optimizers</a> section. To help you choose the right optimizer, based on extensive benchmarks we recommend:</p><ul><li>If you have access to a full Hessian matrix, the Interior-point Newton method in <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> typically outperforms the trust-region method in Fides.py.</li><li>If you can only provide a Gauss-Newton Hessian approximation (not the full Hessian), the Newton trust-region method in Fides.py is usually more effective than the interior-point method in <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a>.</li></ul><p>The algorithms accessible through PEtab&#39;s interfaces to Optim and Ipopt are also available in Optimization.jl. However, we recommend using the wrappers provided in PEtab, as they offer additional features. For example, when employing the Optim.jl LBFGS algorithm, <a href="../Avaible_optimisers/#Optim_alg">PEtab&#39;s interface</a> provides options to save the optimization trace, record extra optimization statistics, which is not as easily available in <a href="../Avaible_optimisers/#Optimization_alg">Optimization.jl</a>. Similar holds true for Ipopt. In cases where the algorithms in Optim, Fides, or Ipopt do not yield optimal results for your specific problem, or if you prefer to employ a global optimizer such as particle swarm, Optimization.jl serves as a good interface.</p><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>To use Optim optimizers, you must load Optim with <code>using Optim</code>. To use Ipopt, you must load Ipopt with <code>using Ipopt</code>. To use Fides, load PyCall with <code>using PyCall</code> and ensure Fides is installed (see documentation for setup). To use Optimization load Optimization.jl with <code>using Optimization</code></p></div></div><p>Additionally, the <code>PEtabODEProblem</code> contain all the necessary information to use other optimization libraries like <a href="https://github.com/JuliaOpt/NLopt.jl">NLopt.jl</a>.</p><h2 id="Multi-Start-Local-Optimization"><a class="docs-heading-anchor" href="#Multi-Start-Local-Optimization">Multi-Start Local Optimization</a><a id="Multi-Start-Local-Optimization-1"></a><a class="docs-heading-anchor-permalink" href="#Multi-Start-Local-Optimization" title="Permalink"></a></h2><p>A widely adopted and effective approach for model calibration is multi-start local optimization. In this method, a local optimizer is run from a large number (typically 100-1000) of randomly generated initial parameter guesses. These guesses are efficiently generated using techniques like Latin-hypercube sampling to effectively explore the parameter space.</p><p>To perform multi-start parameter estimation, you can employ the <code>calibrate_model_multistart</code> function. This function requires a <code>PEtabODEProblem</code> or a <code>OptimizationProblem</code>, the number of multi-starts, one of the available optimizer algorithms, and a directory to save the results. If you provide <code>dir_save=nothing</code> as the directory path, the results will not be written to disk. However, as a precaution against premature termination, we strongly recommended to specify a directory.</p><p>For example, to use the Interior-point Newton method from <a href="https://github.com/JuliaNLSolvers/Optim.jl">Optim.jl</a> to perform parameter estimation on the Boehm model with 10 multi-starts you can write:</p><pre><code class="language-julia hljs">using PEtab
using Optim

dir_save = joinpath(@__DIR__, &quot;Boehm_opt&quot;)
petab_model = PEtabModel(path_to_Boehm_model)
petab_problem = PEtabODEProblem(petab_model)
res = calibrate_model_multistart(petab_problem, IPNewton(), 10, dir_save,
                                 options=Optim.Options(iterations = 200))
print(res)</code></pre><pre><code class="nohighlight hljs">PEtabMultistartOptimisationResult
--------- Summary ---------
min(f)                = 1.48e+02
Parameters esimtated  = 9
Number of multistarts = 10
Optimiser algorithm   = Optim_IPNewton</code></pre><p>In this example, we use <code>Optim.Options</code> to set the maximum number of iterations to 200. You can find a full list of options <a href="https://julianlsolvers.github.io/Optim.jl/v0.9.3/user/config/">here</a>. The results are returned as a <code>PEtabMultistartOptimisationResult</code>, which contains the best-found minima (<code>xmin</code>), the smallest objective value (<code>fmin</code>), and optimization results for each run. In case a <code>dir_save</code> is provided results can also easily be read from disk into a <code>PEtabMultistartOptimisationResult</code> struct:</p><pre><code class="language-julia hljs">res_read = PEtabMultistartOptimisationResult(dir_save)
print(res_read)</code></pre><pre><code class="nohighlight hljs">PEtabMultistartOptimisationResult
--------- Summary ---------
min(f)                = 1.48e+02
Parameters esimtated  = 9
Number of multistarts = 10
Optimiser algorithm   = Optim_IPNewton</code></pre><p>Alternatively, we can first convert the <code>PEtabODEProblem</code> into an <code>OptimizationProblem</code>, and perform multi-start optimization with any algorithm in Optimization.jl, such as a particle swarm method:</p><pre><code class="language-julia hljs">using Optimization
using OptimizationOptimJL

dir_save = joinpath(@__DIR__, &quot;Boehm_opt&quot;)
petab_model = PEtabModel(path_to_Boehm_model)
petab_problem = PEtabODEProblem(petab_model)
optimization_problem = PEtab.OptimizationProblem(petab_problem)
res = calibrate_model_multistart(optimization_problem, petab_problem, Optim.ParticleSwarm(), 10, dir_save,
                                 reltol=1e-8)</code></pre><p>Here <code>reltol</code> is one of many available solver <a href="https://docs.sciml.ai/Optimization/stable/API/solve/">options</a>.</p><p>The method for generating initial parameter guesses can also be chosen, as we support any method available in <a href="https://github.com/SciML/QuasiMonteCarlo.jl">QuasiMonteCarlo.jl</a>. For instance, to use Latin-Hypercube sampling (which is the default), and to perform multi-start calibration with Fides, write:</p><pre><code class="language-julia hljs">using PEtab
using PyCall
using QuasiMonteCarlo

petab_model = PEtabModel(path_yaml)
petab_problem = PEtabODEProblem(petab_model)
res = calibrate_model_multistart(petab_problem, Fides(nothing), 10, dir_save,
                               sampling_method=QuasiMonteCarlo.LatinHypercubeSample())
print(res)</code></pre><pre><code class="nohighlight hljs">PEtabMultistartOptimisationResult
--------- Summary ---------
min(f)                = 1.38e+02
Parameters esimtated  = 9
Number of multistarts = 10
Optimiser algorithm   = Fides</code></pre><p>In this example, we utilize Latin-Hypercube sampling by specifying <code>sampling_method=QuasiMonteCarlo.LatinHypercubeSample()</code>.</p><p>Finally, we have the option to save the trace of each optimization run. For instance, if we want to use <code>Ipopt</code> and save the trace for each run, while ensuring reproducibility by setting a seed, we can use the following code:</p><pre><code class="language-julia hljs">using PEtab
using Ipopt

petab_model = PEtabModel(path_yaml)
petab_problem = PEtabODEProblem(petab_model)
res = calibrate_model_multistart(petab_problem, IpoptOptimiser(false), 10, dir_save,
                                 save_trace=true,
                                 seed=123)
print(res)</code></pre><pre><code class="nohighlight hljs">PEtabMultistartOptimisationResult
--------- Summary ---------
min(f)                = 1.38e+02
Parameters esimtated  = 9
Number of multistarts = 10
Optimiser algorithm   = Ipopt_user_Hessian</code></pre><p>In this example, we use <code>save_trace=true</code> to enable trace saving and set <code>seed=123</code> for reproducibility. We can access the traces for the first run as follows:</p><pre><code class="language-julia hljs">res.runs[1].xtrace
res.runs[1].ftrace</code></pre><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p><code>save_trace</code> option is not available if using <code>OptimizationProblem</code> from Optimization.jl.</p></div></div><h2 id="get_startguesses"><a class="docs-heading-anchor" href="#get_startguesses">Generating startguesses for parameter estimation</a><a id="get_startguesses-1"></a><a class="docs-heading-anchor-permalink" href="#get_startguesses" title="Permalink"></a></h2><p>When you call the <code>calibrate_model_multistart</code> function, it uses the <code>generate_startguesses</code> function to create initial startguesses for parameter estimation. With <code>generate_startguesses</code>, you can generate start-guesses within the bounds of the <code>PEtabODEProblem</code> using various sampling methods from <a href="https://github.com/SciML/QuasiMonteCarlo.jl">QuasiMonteCarlo</a> through the <code>sampling_method</code> parameter. For example, to run 10 optimization runs with Sobol sampling, do:</p><pre><code class="language-julia hljs">using QuasiMonteCarlo
res = calibrate_model_multistart(petab_problem, IpoptOptimiser(false), 10, dir_save,
                                 sampling_method=SobolSample(),
                                 save_trace=true,
                                 seed=123)</code></pre><p>In addition for problems specified directly in Julia, when a parameter has a prior, the start-guesses for said parameter are sampled from the prior distribution, where the prior is clipped/truncated by the parameter&#39;s lower and upper bounds. You can disable this for all parameters by setting <code>sample_from_prior=false</code>. To disable it for specific parameters, use <code>sample_from_prior=false</code> when creating the <code>PEtabParameter</code>. For example: <code>PEtabParameters(:c1, sample_from_prior=false)</code>.</p><p>For problems specified in the PEtab table format, the <code>initializationPriorType</code> must be provided to sample initial values from priors. See the <a href="https://petab.readthedocs.io/en/latest/documentation_data_format.html#parameter-table">PEtab documentation</a> for details.</p><h2 id="Single-Start-Parameter-Estimation"><a class="docs-heading-anchor" href="#Single-Start-Parameter-Estimation">Single-Start Parameter Estimation</a><a id="Single-Start-Parameter-Estimation-1"></a><a class="docs-heading-anchor-permalink" href="#Single-Start-Parameter-Estimation" title="Permalink"></a></h2><p>If we want to perform single-start parameter estimation instead of multistart, we can use the <code>calibrate_model</code> function. This function runs a single optimization from a given initial guess.</p><p>Given a starting point <code>p0</code> which can be generated by the <code>generate_startguesses</code> function, and that we want to use Ipopt for optimization the model can be parameter estimated via:</p><pre><code class="language-julia hljs">p0 = generate_startguesses(petab_problem, 1)
res = calibrate_model(petab_problem, p0, IpoptOptimiser(false),
                      options=IpoptOptions(max_iter = 1000))
print(res)</code></pre><pre><code class="nohighlight hljs">PEtabOptimisationResult
--------- Summary ---------
min(f)                = 1.38e+02
Parameters esimtated  = 9
Optimiser iterations  = 31
Run time              = 1.9e+00s
Optimiser algorithm   = Ipopt_user_Hessian</code></pre><p>The results are returned as a <code>PEtabOptimisationResult</code>, which includes the following information: minimum parameter values found (<code>xmin</code>), smallest objective value (<code>fmin</code>), number of iterations, runtime, whether the optimizer converged, and optionally, the trace if <code>save_trace=true</code>.</p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Beer/">« Models with many conditions specific parameters</a><a class="docs-footer-nextpage" href="../Avaible_optimisers/">Available optimisers »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Wednesday 10 January 2024 10:25">Wednesday 10 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
