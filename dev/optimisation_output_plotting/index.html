<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Plots evaluating parameter estimation · PEtab.jl</title><meta name="title" content="Plots evaluating parameter estimation · PEtab.jl"/><meta property="og:title" content="Plots evaluating parameter estimation · PEtab.jl"/><meta property="twitter:title" content="Plots evaluating parameter estimation · PEtab.jl"/><meta name="description" content="Documentation for PEtab.jl."/><meta property="og:description" content="Documentation for PEtab.jl."/><meta property="twitter:description" content="Documentation for PEtab.jl."/><meta property="og:url" content="https://sebapersson.github.io/PEtab.jl/optimisation_output_plotting/"/><meta property="twitter:url" content="https://sebapersson.github.io/PEtab.jl/optimisation_output_plotting/"/><link rel="canonical" href="https://sebapersson.github.io/PEtab.jl/optimisation_output_plotting/"/><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../search_index.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">PEtab.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../Boehm/">Importing problems in PEtab standard format</a></li><li><span class="tocitem">Defining a PEtab problem in Julia</span><ul><li><a class="tocitem" href="../Define_in_julia/">Defining parameter estimation problems in Julia</a></li><li><a class="tocitem" href="../Julia_steady_state/">Pre-equilibration (steady-state simulations)</a></li><li><a class="tocitem" href="../Julia_obs_noise/">Noise and observable parameters</a></li><li><a class="tocitem" href="../Julia_condition_specific/">Condition specific system/model parameters</a></li><li><a class="tocitem" href="../Julia_event/">Events (callbacks, dosages etc...)</a></li></ul></li><li><span class="tocitem">Options for specific problem types</span><ul><li><a class="tocitem" href="../Brannmark/">Models with pre-equilibration (steady-state simulation)</a></li><li><a class="tocitem" href="../Bachmann/">Medium sized models and adjoint sensitivity analysis</a></li><li><a class="tocitem" href="../Beer/">Models with many conditions specific parameters</a></li></ul></li><li><span class="tocitem">Parameter estimation</span><ul><li><a class="tocitem" href="../Parameter_estimation/">Parameter estimation</a></li><li><a class="tocitem" href="../Avaible_optimisers/">Available optimisers</a></li><li><a class="tocitem" href="../Model_selection/">Model selection (PEtab select)</a></li><li class="is-active"><a class="tocitem" href>Plots evaluating parameter estimation</a><ul class="internal"><li><a class="tocitem" href="#Objective-function-evaluations"><span>Objective function evaluations</span></a></li><li><a class="tocitem" href="#Best-objective-function-evaluations"><span>Best objective function evaluations</span></a></li><li><a class="tocitem" href="#Waterfall-plots"><span>Waterfall plots</span></a></li><li><a class="tocitem" href="#Parallel-coordinates-plots"><span>Parallel coordinates plots</span></a></li><li><a class="tocitem" href="#Runtime-evaluation-plots"><span>Runtime evaluation plots</span></a></li><li><a class="tocitem" href="#optimisation_output_plotting_multirun_clustering"><span>Multi start run clustering</span></a></li><li><a class="tocitem" href="#optimisation_output_plotting_multirun_indexing"><span>Sub-selecting runs to plot</span></a></li><li><a class="tocitem" href="#Plots-comparing-the-fitted-model-to-the-measurements"><span>Plots comparing the fitted model to the measurements</span></a></li></ul></li></ul></li><li><a class="tocitem" href="../Gradient_hessian_support/">Supported gradient and hessian methods</a></li><li><a class="tocitem" href="../Best_options/">Choosing the best options for a PEtab problem</a></li><li><a class="tocitem" href="../API_choosen/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Parameter estimation</a></li><li class="is-active"><a href>Plots evaluating parameter estimation</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Plots evaluating parameter estimation</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/sebapersson/PEtab.jl/blob/main/docs/src/optimisation_output_plotting.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="optimisation_output_plotting"><a class="docs-heading-anchor" href="#optimisation_output_plotting">Plots evaluating parameter estimation</a><a id="optimisation_output_plotting-1"></a><a class="docs-heading-anchor-permalink" href="#optimisation_output_plotting" title="Permalink"></a></h1><p>After fitting a model&#39;s parameter to data, it is prudent to evaluate the results. The simplest approach is to simulate the model using the optimally fitting parameter set, visually inspecting its goodness of fit. However, there exist several techniques attempting to deduce whenever:</p><ul><li>There exist unfound parameter sets that yield better fits than what was found (suggesting a local minimum was reached).</li><li>There exist additional parameter sets yielding equally good fits to what was found (suggesting an <em>identifiability</em> problem).</li></ul><p>This section will demonstrate various plots implemented in PEtab that can be used to perform this kind of analysis. These plots can be generated by calling <code>plot</code> on the output of <code>calibrate_model</code> (a <code>PEtabOptimisationResult</code> structure) or <code>calibrate_model_multistart</code> (a <code>PEtabMultistartOptimisationResult</code> structure). In addition, an optional argument (<code>plot_type</code>) allows the selection of plot type.</p><p>First, we load a multi start optimisation result:</p><pre><code class="language-julia hljs">using PEtab
using Plots
petab_ms_res = PEtabMultistartOptimisationResult(joinpath(@__DIR__, &quot;assets&quot;, &quot;optimisation_results&quot;, &quot;boehm&quot;))</code></pre><p>next, we will, throughout the following sections, demonstrate the available types of plots using <code>petab_ms_res</code> as input.</p><h2 id="Objective-function-evaluations"><a class="docs-heading-anchor" href="#Objective-function-evaluations">Objective function evaluations</a><a id="Objective-function-evaluations-1"></a><a class="docs-heading-anchor-permalink" href="#Objective-function-evaluations" title="Permalink"></a></h2><p>The objective function evaluations plot is accessed through the <code>plot_type=objective</code> argument. It is valid both for single start and multi start optimisation results. It plots, for each iteration of the optimisation process, the achieved objective value.</p><p>For single start optimisation results, a single trajectory of dots is plotted. For a multi start optimisation result, each run correspond to a separate trajectory of dots.</p><pre><code class="language-julia hljs">plot(petab_ms_res; plot_type=:objective)</code></pre><img src="7d3dc5d3.svg" alt="Example block output"/><p>Here, the runs are separated my different colours. First, a clustering process is carried out, attempting to identify runs converging to the same local minimum (the clustering, including how to customise it, is described <a href="#optimisation_output_plotting_multirun_indexing">here</a>). Next, runs from the same cluster is assigned the same colour. A similar scheme is used for all plots involving multi start runs. When a large number of runs are carried out, it is also possible to select which one to include in the plot (by default the <code>10</code> best ones are used, however, this can be <a href="#optimisation_output_plotting_multirun_indexing">customised</a>).</p><p>Sometimes, the objective function is unable to successfully simulate the model for a specific parameter set (this indicates a very poor fit). If such evaluations happen, they are marked with crosses (rather than circles) in these plots.</p><h2 id="Best-objective-function-evaluations"><a class="docs-heading-anchor" href="#Best-objective-function-evaluations">Best objective function evaluations</a><a id="Best-objective-function-evaluations-1"></a><a class="docs-heading-anchor-permalink" href="#Best-objective-function-evaluations" title="Permalink"></a></h2><p>The best objective function evaluations plot is accessed through the <code>plot_type=best_objective</code> argument. It is valid both for single start and multi start optimisation results. This function is very similar to the objective function evaluation one, however, it instead plots the <em>best value reached so far</em> in the process (and is thus a decreasing function.) The best objective function evaluations plot is the default plot type for single start optimisation results.</p><pre><code class="language-julia hljs">plot(petab_ms_res; plot_type=:best_objective)</code></pre><img src="32b8f474.svg" alt="Example block output"/><h2 id="Waterfall-plots"><a class="docs-heading-anchor" href="#Waterfall-plots">Waterfall plots</a><a id="Waterfall-plots-1"></a><a class="docs-heading-anchor-permalink" href="#Waterfall-plots" title="Permalink"></a></h2><p>The waterfall plot is accessed through the <code>plot_type=waterfall</code> argument. It is only valid for multi start optimisation results. It plots all runs&#39; final objective values, sorted from best to worst (local minimums can typically be identified as plateaus in the plot). The waterfall plot is the default plot type for multi start optimisation results.</p><pre><code class="language-julia hljs">plot(petab_ms_res; plot_type=:waterfall)</code></pre><img src="9af1f31c.svg" alt="Example block output"/><h2 id="Parallel-coordinates-plots"><a class="docs-heading-anchor" href="#Parallel-coordinates-plots">Parallel coordinates plots</a><a id="Parallel-coordinates-plots-1"></a><a class="docs-heading-anchor-permalink" href="#Parallel-coordinates-plots" title="Permalink"></a></h2><p>The parallel coordinates plot is accessed through the <code>plot_type=parallel_coordinates</code> argument. It is only valid for multi start optimisation results. In it, each run corresponds to a line, drawn along its parameter values in vector of fitted parameters (starting with the first, and ending in the last, parameter). The parameter values are normalised (so that <code>0</code> corresponds to the minimum value encountered for that parameter, and <code>1</code> the maximum values). If runs in the same cluster typically share similar paths across the parameter values, this suggests that they have converged to the same local minimum. If, for one parameters, runs in the same cluster have widely different values, it suggests that that parameter is unidentifiable.</p><pre><code class="language-julia hljs">plot(petab_ms_res; plot_type=:parallel_coordinates)</code></pre><img src="6a1dc31e.svg" alt="Example block output"/><h2 id="Runtime-evaluation-plots"><a class="docs-heading-anchor" href="#Runtime-evaluation-plots">Runtime evaluation plots</a><a id="Runtime-evaluation-plots-1"></a><a class="docs-heading-anchor-permalink" href="#Runtime-evaluation-plots" title="Permalink"></a></h2><p>The runtime evaluation plot is accessed through the <code>plot_type=runtime_eval</code> argument. It is only valid for multi start optimisation results. It is a scatter plot, showing for each run, how its final objective value depends on the runtime.</p><pre><code class="language-julia hljs">plot(petab_ms_res; plot_type=:runtime_eval)</code></pre><img src="6eb3d8e3.svg" alt="Example block output"/><h2 id="optimisation_output_plotting_multirun_clustering"><a class="docs-heading-anchor" href="#optimisation_output_plotting_multirun_clustering">Multi start run clustering</a><a id="optimisation_output_plotting_multirun_clustering-1"></a><a class="docs-heading-anchor-permalink" href="#optimisation_output_plotting_multirun_clustering" title="Permalink"></a></h2><p>When using the <code>calibrate_model_multistart</code> function to fit a parameter set, several independent runs are performed. In all the previous plots, a clustering function is applied to identify runs that likely have converged to the same local minimum. Runs in the same cluster are given the same colour in the plots, allowing the cluster to be identified. By default, the <code>objective_value_clustering</code> function is used for this (roughly, it clusters runs together if their objective function evaluates to values within <code>0.1</code> of each other). It is possible for the user to define their own clustering function, and supply it to the <code>plot</code> command through the <code>clustering_function</code> argument. The clustering function should take a <code>Vector{PEtabOptimisationResult}</code> input, and return an identical sized <code>Vector{Int64}</code> (for each index giving an integer corresponding to that run&#39;s cluster).</p><h2 id="optimisation_output_plotting_multirun_indexing"><a class="docs-heading-anchor" href="#optimisation_output_plotting_multirun_indexing">Sub-selecting runs to plot</a><a id="optimisation_output_plotting_multirun_indexing-1"></a><a class="docs-heading-anchor-permalink" href="#optimisation_output_plotting_multirun_indexing" title="Permalink"></a></h2><p>When plotting a multi start output using the <code>:objective</code>, <code>:best_objective</code>, or <code>:parallel_coordinates</code> plot types, if the number of runs are large, it can sometimes be hard to distinguish information from the plot. Hence, for these plot types, only the <code>10</code> runs with the best final objective values are plotted. This can be modified through the <code>best_idxs_n</code> optional argument. This is an <code>Int64</code>, what number of runs to add to the plot (starting with the best one). Alternatively, the <code>idxs</code> optional argument can be used to give the indexes of the runs to plot.</p><p>For the <code>:waterfall</code>, <code>:runtime_eval</code> plot types, by default all runs are plotted. However, if desired, the <code>best_idxs_n</code> and <code>idxs</code> arguments can be used for these plot types as well.</p><h2 id="Plots-comparing-the-fitted-model-to-the-measurements"><a class="docs-heading-anchor" href="#Plots-comparing-the-fitted-model-to-the-measurements">Plots comparing the fitted model to the measurements</a><a id="Plots-comparing-the-fitted-model-to-the-measurements-1"></a><a class="docs-heading-anchor-permalink" href="#Plots-comparing-the-fitted-model-to-the-measurements" title="Permalink"></a></h2><p>After the model has been fitted, it can be useful to compare it to the measurements. This is possible by supplying both the optimisation solution, and the <code>PEtabModel</code> used, to the plot command. By default, it will plot, for the first condition, the output solution for all observables. However, any subset of observables can be selected (using the <code>observable_ids</code> option). It is also possible to select the condition using the <code>condition_id</code> option.</p><p>Here, we first fit a simple model (with two observables and two conditions) to simulated data. Next, we will show various ways to plot the fitted solution.</p><pre><code class="language-julia hljs"># Prepare model
using Catalyst
rn = @reaction_network begin
    kB, S + E --&gt; SE
    kD, SE --&gt; S + E
    kP, SE --&gt; P + E
end

u0 = [:E =&gt; 1.0, :SE =&gt; 0.0, :P =&gt; 0.0]
p_true = [:kB =&gt; 1.0, :kD =&gt; 0.1, :kP =&gt; 0.5]

# Simulate data.
using OrdinaryDiffEq
# Condition 1.
oprob_true_c1 = ODEProblem(rn,  [:S =&gt; 1.0; u0], (0.0, 10.0), p_true)
true_sol_c1 = solve(oprob_true_c1, Tsit5())
data_sol_c1 = solve(oprob_true_c1, Tsit5(); saveat=1.0)
c1_t, c1_E, c1_P = data_sol_c1.t[2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c1[:E][2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c1[:P][2:end]

# Condition 2.
oprob_true_c2 = ODEProblem(rn,  [:S =&gt; 0.5; u0], (0.0, 10.0), p_true)
true_sol_c2 = solve(oprob_true_c2, Tsit5())
data_sol_c2 = solve(oprob_true_c2, Tsit5(); saveat=1.0)
c2_t, c2_E, c2_P = data_sol_c2.t[2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c2[:E][2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c2[:P][2:end]

# Make PETab problem.
using PEtab
@unpack E,P = rn
obs_E = PEtabObservable(E, 0.5)
obs_P = PEtabObservable(P, 0.5)
observables = Dict(&quot;obs_E&quot; =&gt; obs_E, &quot;obs_P&quot; =&gt; obs_P)

par_kB = PEtabParameter(:kB)
par_kD = PEtabParameter(:kD)
par_kP = PEtabParameter(:kP)
params = [par_kB, par_kD, par_kP]

c1 = Dict(:S =&gt; 1.0)
c2 = Dict(:S =&gt; 0.5)
simulation_conditions = Dict(&quot;c1&quot; =&gt; c1, &quot;c2&quot; =&gt; c2)

using DataFrames
m_c1_E = DataFrame(simulation_id=&quot;c1&quot;, obs_id=&quot;obs_E&quot;, time=c1_t, measurement=c1_E)
m_c1_P = DataFrame(simulation_id=&quot;c1&quot;, obs_id=&quot;obs_P&quot;, time=c1_t, measurement=c1_P)
m_c2_E = DataFrame(simulation_id=&quot;c2&quot;, obs_id=&quot;obs_E&quot;, time=c2_t, measurement=c2_E)
m_c2_P = DataFrame(simulation_id=&quot;c2&quot;, obs_id=&quot;obs_P&quot;, time=c2_t, measurement=c2_P)
measurements = vcat(m_c1_E, m_c1_P, m_c2_E, m_c2_P)

petab_model = PEtabModel(rn, simulation_conditions , observables, measurements, params; state_map=u0)
petab_problem = PEtabODEProblem(petab_model)

using Optim
res = calibrate_model_multistart(petab_problem, IPNewton(), 50, nothing)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi"><span class="sgr38_5" style="color:#87ffff"><span class="sgr1">[ Info:</span></span> Building PEtabODEProblem for ReactionSystemModel
<span class="sgr38_5" style="color:#87ffff"><span class="sgr1">[ Info:</span></span> Building ODEProblem from ODESystem ... done. Time = 1.4e-01
<span class="sgr38_5" style="color:#87ffff"><span class="sgr1">[ Info:</span></span> Building cost function for method Standard ... done. Time = 3.8e-01
<span class="sgr38_5" style="color:#87ffff"><span class="sgr1">[ Info:</span></span> Building gradient function for method ForwardDiff ... done. Time = 4.1e-01
<span class="sgr38_5" style="color:#87ffff"><span class="sgr1">[ Info:</span></span> Building hessian function for method ForwardDiff ... done. Time = 5.9e-01</code></pre><p>Next we plot the fitted solution for <span>$P$</span>, for the first condition (<code>&quot;c1&quot;</code>`):</p><pre><code class="language-julia hljs">using Plots
plot(res, petab_problem; observable_ids=[&quot;obs_P&quot;], condition_id=&quot;c1&quot;)</code></pre><img src="681703d0.svg" alt="Example block output"/><p>If we instead wish to, for the second condition, plot both observables, we use the following command:</p><pre><code class="language-julia hljs">plot(res, petab_problem; observable_ids=[&quot;obs_E&quot;, &quot;obs_P&quot;], condition_id=&quot;c2&quot;)</code></pre><img src="77f41f58.svg" alt="Example block output"/><p>(in this example, the <code>observable_ids</code> option is technically not required, as plotting all observables is the default behaviour)</p><p>Finally, it is possible to retrieve a dictionary containing plots for all combinations of observables and conditions using:</p><pre><code class="language-julia hljs">comp_dict = get_obs_comparison_plots(res, petab_problem)</code></pre><p>Here <code>comp_dict</code> contain one entry for each condition (with keys corresponding to their condition ids). These are all dictionaries, which in turn contain one entry for each observable (with keys corresponding to their observable ids). To retrieve the plot for <span>$E$</span> and <code>&quot;c1&quot;</code>` we use:</p><pre><code class="language-julia hljs">comp_dict[&quot;c1&quot;][&quot;obs_E&quot;]</code></pre><img src="8bee108f.svg" alt="Example block output"/></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../Model_selection/">« Model selection (PEtab select)</a><a class="docs-footer-nextpage" href="../Gradient_hessian_support/">Supported gradient and hessian methods »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="auto">Automatic (OS)</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.2.1 on <span class="colophon-date" title="Wednesday 10 January 2024 10:25">Wednesday 10 January 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
