var documenterSearchIndex = {"docs":
[{"location":"Parameter_estimation/#parameter_estimation","page":"Parameter estimation","title":"Parameter Estimation (Model Calibration)","text":"","category":"section"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtab.jl provides interfaces to four optimization packages:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Optim: Supports LBFGS, BFGS, or IPNewton methods.\nIpoptOptimiser: An interior-point optimizer.\nFides: A Newton trust region method.\nOptimization.jl: PEtab provides support for converting a PEtabODEProblem into an OptimizationProblem, allowing the use of any optimizer from Optimization.jl.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"You can find available options for each optimizer in the Available Optimizers section. To help you choose the right optimizer, based on extensive benchmarks we recommend:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"If you have access to a full Hessian matrix, the Interior-point Newton method in Optim.jl typically outperforms the trust-region method in Fides.py.\nIf you can only provide a Gauss-Newton Hessian approximation (not the full Hessian), the Newton trust-region method in Fides.py is usually more effective than the interior-point method in Optim.jl.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"The algorithms accessible through PEtab's interfaces to Optim and Ipopt are also available in Optimization.jl. However, we recommend using the wrappers provided in PEtab, as they offer additional features. For example, when employing the Optim.jl LBFGS algorithm, PEtab's interface provides options to save the optimization trace, record extra optimization statistics, which is not as easily available in Optimization.jl. Similar holds true for Ipopt. In cases where the algorithms in Optim, Fides, or Ipopt do not yield optimal results for your specific problem, or if you prefer to employ a global optimizer such as particle swarm, Optimization.jl serves as a good interface.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"note: Note\nTo use Optim optimizers, you must load Optim with using Optim. To use Ipopt, you must load Ipopt with using Ipopt. To use Fides, load PyCall with using PyCall and ensure Fides is installed (see documentation for setup). To use Optimization load Optimization.jl with using Optimization","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Additionally, the PEtabODEProblem contain all the necessary information to use other optimization libraries like NLopt.jl.","category":"page"},{"location":"Parameter_estimation/#Multi-Start-Local-Optimization","page":"Parameter estimation","title":"Multi-Start Local Optimization","text":"","category":"section"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"A widely adopted and effective approach for model calibration is multi-start local optimization. In this method, a local optimizer is run from a large number (typically 100-1000) of randomly generated initial parameter guesses. These guesses are efficiently generated using techniques like Latin-hypercube sampling to effectively explore the parameter space.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"To perform multi-start parameter estimation, you can employ the calibrate_model_multistart function. This function requires a PEtabODEProblem or a OptimizationProblem, the number of multi-starts, one of the available optimizer algorithms, and a directory to save the results. If you provide dir_save=nothing as the directory path, the results will not be written to disk. However, as a precaution against premature termination, we strongly recommended to specify a directory.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"For example, to use the Interior-point Newton method from Optim.jl to perform parameter estimation on the Boehm model with 10 multi-starts you can write:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using PEtab\nusing Optim\n\ndir_save = joinpath(@__DIR__, \"Boehm_opt\")\npetab_model = PEtabModel(path_to_Boehm_model)\npetab_problem = PEtabODEProblem(petab_model)\nres = calibrate_model_multistart(petab_problem, IPNewton(), 10, dir_save,\n                                 options=Optim.Options(iterations = 200))\nprint(res)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtabMultistartOptimisationResult\n--------- Summary ---------\nmin(f)                = 1.48e+02\nParameters esimtated  = 9\nNumber of multistarts = 10\nOptimiser algorithm   = Optim_IPNewton","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"In this example, we use Optim.Options to set the maximum number of iterations to 200. You can find a full list of options here. The results are returned as a PEtabMultistartOptimisationResult, which contains the best-found minima (xmin), the smallest objective value (fmin), and optimization results for each run. In case a dir_save is provided results can also easily be read from disk into a PEtabMultistartOptimisationResult struct:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"res_read = PEtabMultistartOptimisationResult(dir_save)\nprint(res_read)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtabMultistartOptimisationResult\n--------- Summary ---------\nmin(f)                = 1.48e+02\nParameters esimtated  = 9\nNumber of multistarts = 10\nOptimiser algorithm   = Optim_IPNewton","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Alternatively, we can first convert the PEtabODEProblem into an OptimizationProblem, and perform multi-start optimization with any algorithm in Optimization.jl, such as a particle swarm method:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using Optimization\nusing OptimizationOptimJL\n\ndir_save = joinpath(@__DIR__, \"Boehm_opt\")\npetab_model = PEtabModel(path_to_Boehm_model)\npetab_problem = PEtabODEProblem(petab_model)\noptimization_problem = PEtab.OptimizationProblem(petab_problem)\nres = calibrate_model_multistart(optimization_problem, petab_problem, Optim.ParticleSwarm(), 10, dir_save,\n                                 reltol=1e-8)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Here reltol is one of many available solver options.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"The method for generating initial parameter guesses can also be chosen, as we support any method available in QuasiMonteCarlo.jl. For instance, to use Latin-Hypercube sampling (which is the default), and to perform multi-start calibration with Fides, write:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using PEtab\nusing PyCall\nusing QuasiMonteCarlo\n\npetab_model = PEtabModel(path_yaml)\npetab_problem = PEtabODEProblem(petab_model)\nres = calibrate_model_multistart(petab_problem, Fides(nothing), 10, dir_save,\n                               sampling_method=QuasiMonteCarlo.LatinHypercubeSample())\nprint(res)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtabMultistartOptimisationResult\n--------- Summary ---------\nmin(f)                = 1.38e+02\nParameters esimtated  = 9\nNumber of multistarts = 10\nOptimiser algorithm   = Fides","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"In this example, we utilize Latin-Hypercube sampling by specifying sampling_method=QuasiMonteCarlo.LatinHypercubeSample().","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Finally, we have the option to save the trace of each optimization run. For instance, if we want to use Ipopt and save the trace for each run, while ensuring reproducibility by setting a seed, we can use the following code:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using PEtab\nusing Ipopt\n\npetab_model = PEtabModel(path_yaml)\npetab_problem = PEtabODEProblem(petab_model)\nres = calibrate_model_multistart(petab_problem, IpoptOptimiser(false), 10, dir_save,\n                                 save_trace=true,\n                                 seed=123)\nprint(res)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtabMultistartOptimisationResult\n--------- Summary ---------\nmin(f)                = 1.38e+02\nParameters esimtated  = 9\nNumber of multistarts = 10\nOptimiser algorithm   = Ipopt_user_Hessian","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"In this example, we use save_trace=true to enable trace saving and set seed=123 for reproducibility. We can access the traces for the first run as follows:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"res.runs[1].xtrace\nres.runs[1].ftrace","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"note: Note\nsave_trace option is not available if using OptimizationProblem from Optimization.jl.","category":"page"},{"location":"Parameter_estimation/#get_startguesses","page":"Parameter estimation","title":"Generating startguesses for parameter estimation","text":"","category":"section"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"When you call the calibrate_model_multistart function, it uses the generate_startguesses function to create initial startguesses for parameter estimation. With generate_startguesses, you can generate start-guesses within the bounds of the PEtabODEProblem using various sampling methods from QuasiMonteCarlo through the sampling_method parameter. For example, to run 10 optimization runs with Sobol sampling, do:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using QuasiMonteCarlo\nres = calibrate_model_multistart(petab_problem, IpoptOptimiser(false), 10, dir_save,\n                                 sampling_method=SobolSample(),\n                                 save_trace=true,\n                                 seed=123)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"In addition for problems specified directly in Julia, when a parameter has a prior, the start-guesses for said parameter are sampled from the prior distribution, where the prior is clipped/truncated by the parameter's lower and upper bounds. You can disable this for all parameters by setting sample_from_prior=false. To disable it for specific parameters, use sample_from_prior=false when creating the PEtabParameter. For example: PEtabParameters(:c1, sample_from_prior=false).","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"For problems specified in the PEtab table format, the initializationPriorType must be provided to sample initial values from priors. See the PEtab documentation for details.","category":"page"},{"location":"Parameter_estimation/#Single-Start-Parameter-Estimation","page":"Parameter estimation","title":"Single-Start Parameter Estimation","text":"","category":"section"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"If we want to perform single-start parameter estimation instead of multistart, we can use the calibrate_model function. This function runs a single optimization from a given initial guess.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Given a starting point p0 which can be generated by the generate_startguesses function, and that we want to use Ipopt for optimization the model can be parameter estimated via:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"p0 = generate_startguesses(petab_problem, 1)\nres = calibrate_model(petab_problem, p0, IpoptOptimiser(false),\n                      options=IpoptOptions(max_iter = 1000))\nprint(res)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtabOptimisationResult\n--------- Summary ---------\nmin(f)                = 1.38e+02\nParameters esimtated  = 9\nOptimiser iterations  = 31\nRun time              = 1.9e+00s\nOptimiser algorithm   = Ipopt_user_Hessian","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"The results are returned as a PEtabOptimisationResult, which includes the following information: minimum parameter values found (xmin), smallest objective value (fmin), number of iterations, runtime, whether the optimizer converged, and optionally, the trace if save_trace=true.","category":"page"},{"location":"Bachmann/#Medium-sized-models-(Bachmann-model)","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium-sized models (Bachmann model)","text":"","category":"section"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"In this tutorial we will crate a PEtabODEproblem for the Bachmann model, a medium-sized ODE model. We will cover three topics:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Computing the gradient via forward-sensitivity equations\nComputing the gradient via adjoint sensitivity analysis\nComputing the Gauss-Newton Hessian approximation, which often performs better than the (L)-BFGS Hessian approximation.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"To run the code, you need the Bachmann PEtab files, which can be found here. You can find a fully runnable example of this tutorial here.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"First, we'll read the model and load the necessary libraries.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"using PEtab\nusing OrdinaryDiffEq\nusing Sundials # For CVODE_BDF\nusing Printf\n \npath_yaml = joinpath(@__DIR__, \"Bachmann\", \"Bachmann_MSB2011.yaml\") \npetab_model = PEtabModel(path_yaml, verbose=true)","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"PEtabModel for model Bachmann. ODE-system has 25 states and 39 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Bachmann/#Adjoint-sensitivity-analysis","page":"Medium sized models and adjoint sensitivity analysis","title":"Adjoint sensitivity analysis","text":"","category":"section"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"When working with a subset of medium-sized models, and definitely for large-sized models, the most efficient way to compute gradients is through adjoint sensitivity analysis (gradient_method=:Adjoint). There are several tuneable options that can improve performance, including:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"ode_solver_gradient: This determines which ODE solver and solver tolerances (abstol and reltol) to use when computing the gradient (when solving the adjoint ODE-system). Currently, the best performing stiff solver for the adjoint problem in Julia is CVODE_BDF().\nsensealg: This determines which adjoint algorithm to use. Currently, InterpolatingAdjoint and QuadratureAdjoint from SciMLSensitivity are supported. You can find more information in their documentation. You can provide any of the options that these methods are compatible with. For example, if you want to use the ReverseDiffVJP algorithm, an acceptable option is sensealg=InterpolatingAdjoint(autojacvec=ReversDiffVJP()).","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Here are a few things to keep in mind:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"note: Note\nAdjoint sensitivity analysis is not as reliable in Julia as it is in AMICI. However, our benchmarks show that SciMLSensitivity has the potential to be faster.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"using Zygote # For adjoint\nusing SciMLSensitivity # For adjoint\npetab_problem = PEtabODEProblem(petab_model, \n                                ode_solver=ODESolver(QNDF(), abstol=1e-8, reltol=1e-8), \n                                ode_solver_gradient=ODESolver(CVODE_BDF(), abstol=1e-8, reltol=1e-8),\n                                gradient_method=:Adjoint, \n                                sensealg=InterpolatingAdjoint(autojacvec=EnzymeVJP())) \np = petab_problem.θ_nominalT \ngradient = zeros(length(p)) \ncost = petab_problem.compute_cost(p)\npetab_problem.compute_gradient!(gradient, p)\n@printf(\"Cost = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Cost = -418.41\nFirst element in the gradient = -1.70e-03","category":"page"},{"location":"Bachmann/#Forward-sensitivity-analysis-and-Gauss-Newton-hessian-approximation","page":"Medium sized models and adjoint sensitivity analysis","title":"Forward sensitivity analysis and Gauss-Newton hessian approximation","text":"","category":"section"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"For medium-sized models, computing the full Hessian via forward-mode automatic differentiation can be too expensive, so we need an approximation. The Gauss-Newton (GN) approximation often performs better than the (L)-BFGS approximation. To compute it, we need the forward sensitivities. These sensitivities can also be used to compute the gradient. As some optimizers such as Fides.py compute both the Hessian and gradient at each iteration, we can save the sensitivities between the gradient and Hessian computations.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"When choosing gradient_method=:ForwardEquations and hessian_method=:GaussNewton, there are several tunable options, the key ones are:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"sensealg - which sensitivity algorithm to use when computing the sensitivities. We support both ForwardSensitivity() and ForwardDiffSensitivity() with tunable options as provided by SciMLSensitivity (see their documentation for more information). The most efficient option is :ForwardDiff, where forward-mode automatic differentiation is used to compute the sensitivities.\nreuse_sensitivities::Bool - whether or not to reuse the sensitivities from the gradient computations when computing the Gauss-Newton Hessian approximation. Whether this option is applicable depends on the optimizer. For example, it works with Fides.py but not with Optim.jl's IPNewton().\nNote - this approach requires that sensealg=:ForwardDiff for the gradient.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"petab_problem = PEtabODEProblem(petab_model, \n                                ode_solver=ODESolver(QNDF(), abstol=1e-8, reltol=1e-8),\n                                gradient_method=:ForwardEquations, \n                                hessian_method=:GaussNewton,\n                                sensealg=:ForwardDiff, \n                                reuse_sensitivities=true) \np = petab_problem.θ_nominalT \ngradient = zeros(length(p)) \nhessian = zeros(length(p), length(p)) \ncost = petab_problem.compute_cost(p)\npetab_problem.compute_gradient!(gradient, p)\npetab_problem.compute_hessian!(hessian, p)\n@printf(\"Cost for Bachmann = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])\n@printf(\"First element in the Gauss-Newton Hessian = %.2f\\n\", hessian[1, 1])","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Cost for Bachmann = -418.41\nFirst element in the gradient = -1.85e-03\nFirst element in the Gauss-Newton Hessian = 584.10","category":"page"},{"location":"Define_in_julia/#define_in_julia","page":"Defining parameter estimation problems in Julia","title":"Creating a PEtab Parameter Estimation Problem in Julia","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"While the PEtab table format is excellent for specifying parameter estimation problems for dynamic ODE models, setting up a parameter estimation problem directly in Julia can be more convenient.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Here we demonstrate how to define a parameter estimation problem using a simple Micheli-Mentan model as an example. We will discuss in detail the five essential components required to define a problem:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Dynamic Model: You can use either a ReactionSystem defined in Catalyst or an ODESystem defined in ModellingToolkit.\nObservable Formula: To link the model to the measurement data, you need an observable formula. Since real-world data often comes with measurement noise, you also must specify a noise formula and noise distribution. This is specified as a PEtabObservable.\nParameters to Estimate: Typically, you do not want to estimate all model parameters. Moreover, sometimes you might want to incorporate prior beliefs by assigning priors to certain parameters. Parameter information is provided as a vector of PEtabParameter.\nSimulation Conditions: Measurements are often taken under various experimental conditions, such as different substrate concentrations. These experimental conditions typically correspond to model control parameters, like the initial value of a model species. You specify these conditions as a Dict (see below). In case the model only has a single simulation conditions, simulation_conditions can be omitted when building the PEtabModel.\nMeasurement Data: To calibrate the model, you need measurement data, which should be provided as a DataFrame. The data format is explained below.","category":"page"},{"location":"Define_in_julia/#Defining-the-Dynamic-Model","page":"Defining parameter estimation problems in Julia","title":"Defining the Dynamic Model","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"To define the dynamic model, you have two options; you can use a Catalyst defined ReactionSystem, or a ModellingToolkit ODESystem. Using Catalyst we define the model as","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"using Catalyst\nusing PEtab\n\nrn = @reaction_network begin\n    @parameters se0\n    @species SE(t) = se0\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nnothing # hide","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"If you want to estimate the initial value of a species (like SE), you must define it as a parameter, as here with SE(t) = se0.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Using a ModellingToolkit ODESystem we define the model as:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"using ModelingToolkit\n\n@parameters c1, c2, c3, se0\n@variables t S(t) SE(t) P(t) E(t)\nD = Differential(t)\neqs = [\n    D(S) ~ -c1*S*E + c2*SE,\n    D(E) ~ -c1*S*E + c2*SE + c3*SE,\n    D(SE) ~ c1*S*E - c2*SE - c3*SE,\n    D(P) ~ c3*SE\n]\n@named sys = ODESystem(eqs; defaults=Dict(SE => se0))\nnothing # hide","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"To estimate an initial value, such as SE, for an ODESystem, you need to define it using a dictionary under the defaults keyword, here done via defaults = Dict(SE => se0).","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Regardless of how the model is defined, if you want to fixate a parameter or initial value to a constant value across all simulations, you can use a state and/or parameter map. For instance, to set E and P to be 1.0 and 0.0, and set c1 to 1.0, do:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"state_map = [:E => 1.0, :P => 0.0]\nparameter_map = [:c1 => 1.0]\nnothing # hide","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"If a parameter or initial value is not specified anywhere it defaults to zero.","category":"page"},{"location":"Define_in_julia/#Defining-the-Observable","page":"Defining parameter estimation problems in Julia","title":"Defining the Observable","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"To connect our model with measurement data, we need an observable formula. Since data from a reaction networks typically includes measurement noise, we also require a noise formula and a noise distribution.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Let us assume we are observing the product P with a normally distributed multiplicative measurement error (sigma * P) on a relative scale. To account for this relative scale we can as commonly done use scale and offset parameters. Additionally, let us assume we are directly measure the sum E + SE with log-normal measurement noise, and we already know the measurement error (sigma) is 3.0. This can be defined as","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"@unpack P, E, SE = rn\n@parameters sigma, scale, offset\nobs_P = PEtabObservable(scale * P + offset, sigma * P, transformation=:lin)\nobs_Sum = PEtabObservable(E + SE, 3.0, transformation=:log)\nnothing # hide","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"The transformation parameter can take one of three values: :lin (default for normal measurement noise), :log, or :log10 (for log-normal measurement noise).","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"To complete the definition, we group these observables together in a Dict with appropriate names:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"observables = Dict(\"obs_P\" => obs_P,\n                   \"obs_Sum\" => obs_Sum)","category":"page"},{"location":"Define_in_julia/#Defining-Parameters-to-Estimate","page":"Defining parameter estimation problems in Julia","title":"Defining Parameters to Estimate","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"To set up a parameter estimation problem, we need to specify the parameters to estimate. To improve the estimation it is often beneficial to define lower and upper bounds to restrict the parameter space. For example, let us assume we want to estimate the parameter c3 with bounds [1e-3, 1e3] (default):","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"_c3 = PEtabParameter(:c3, lb=1e-3, ub=1e3, scale=:log10)","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Here scale=:log10 means that we are estimating the parameter on a log10 scale, which typically yields better results than a linear-scale. Overall the scale parameter can take on three values: :lin, :log, and :log10 (default).","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"If you have prior information about parameters, you can specify a continuous prior distribution from Distributions.jl. For instance, if you want to estimate se0 (the initial value of species SE) and you know it should be around 3.1, you can set a prior as:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"using Distributions\n_se0 = PEtabParameter(:se0, prior=LogNormal(log(3.1), 0.5), \n                      prior_on_linear_scale=true, sample_from_prior=true)","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"In this case, prior_on_linear_scale=true (default) indicates that the prior is defined on the linear scale, not the default transformed log10 scale used for parameter estimation. Moreover, for parameters with priors, start-guesses for parameter estimation are generated from the prior distribution (instead of randomly within the upper and lower bounds), if you want to disable this for a specific parameter set sample_from_prior=false (default is true), more information can be found here.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Apart from estimating parameters in the reaction system, you can also estimate parameters related to measurement noise or parameters used exclusively in the observable formula (e.g., scale and offset parameters see above) by defining them as a PEtabParameter:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"# Using default bounds [1e-3, 1e3] and scale=:log10\n_sigma = PEtabParameter(:sigma)\n_scale = PEtabParameter(:scale)\n_offset = PEtabParameter(:offset)\nnothing # hide","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Once the parameters are defined they should be gathered into a vector","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"_c2 = PEtabParameter(:c2)\nparameters = [_c2, _c3, _se0, _sigma, _scale, _offset]","category":"page"},{"location":"Define_in_julia/#Defining-Simulation-Conditions","page":"Defining parameter estimation problems in Julia","title":"Defining Simulation Conditions","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Data is often collected under various experimental settings, such as different initial concentrations of a substrate. These variations in experimental conditions correspond to different simulation conditions during model calibration. To effectively align your measurements with the data, you need to specify these simulation conditions using a dictionary.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Specifically, assume you have measured your data under two conditions: c0 and c1, where each condition has different starting concentrations for the substrate S. This can be defined as:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"condition_c0 = Dict(:S => 5.0)\ncondition_c1 = Dict(:S => 2.0)\nnothing # hide","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Here, the key (in this case, S) can represent either a model species (as in this case) or a parameter. To complete the setup, gather all the simulation conditions in a dictionary, and assign each condition an appropriate name:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"simulation_conditions = Dict(\"c0\" => condition_c0,\n                             \"c1\" => condition_c1)","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"note: Note\nIf a parameter or species is specified for one simulation condition, it must be specified for all simulation conditions.","category":"page"},{"location":"Define_in_julia/#Defining-Measurement-Data","page":"Defining parameter estimation problems in Julia","title":"Defining Measurement Data","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"The measurement data should be organized as a DataFrame in the following format (the column names matter, but not the order)","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"simulation_id (str) obs_id (str) time (float) measurement (float)\nc0 obs_P 1.0 0.7\nc0 obs_Sum 10.0 0.1\nc1 obs_P 1.0 1.0\nc1 obs_Sum 20.0 1.5","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"For each measurement, you need to specify:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"simulation_id: Identifies the simulation condition it corresponds to.\nobs_id: Specifies the observable it corresponds to.\ntime: Indicates the time point at which the data was collected.\nmeasurement: The actual measurement value.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"For this case, the input would look like;","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"using DataFrames\n\nmeasurements = DataFrame(\n    simulation_id=[\"c0\", \"c0\", \"c1\", \"c1\"],\n    obs_id=[\"obs_P\", \"obs_Sum\", \"obs_P\", \"obs_Sum\"],\n    time=[1.0, 10.0, 1.0, 20.0],\n    measurement=[0.7, 0.1, 1.0, 1.5])","category":"page"},{"location":"Define_in_julia/#Bringing-It-All-Together","page":"Defining parameter estimation problems in Julia","title":"Bringing It All Together","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"After defining the model, observables, parameters to estimate, simulation conditions, and measurement data, you can easily create a PEtabODEProblem for your parameter estimation task using the ReactionSystem:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"petab_model = PEtabModel(rn, simulation_conditions, observables, measurements,\n                         parameters, state_map=state_map, parameter_map=parameter_map,\n                         verbose=false)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"or the ODESystem:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"petab_model = PEtabModel(sys, simulation_conditions, observables, measurements,\n                         parameters, state_map=state_map, parameter_map=parameter_map,\n                         verbose=false)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"The PEtabODEProblem contains all the necessary information to work with most available optimizers (see here). Alternatively, if you want to perform parameter estimation using a multi-start approach, you can use the calibrate_model_multistart function (see Parameter estimation). When creating the PEtabODEProblem good default options are selected based on the problem size, but if you want to set any options, a full list is available here.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"note: Note\nIf the model does not have multiple simulation conditions (e.g., data is collected under a single condition), you can omit the simulation_conditions argument when constructing the PEtabModel and the simulation_id columns from the measurement data. Simply use the following format: PEtabModel(sys, observables, measurements, parameters, <keyword arguments>).","category":"page"},{"location":"Define_in_julia/#Where-to-Go-Next","page":"Defining parameter estimation problems in Julia","title":"Where to Go Next","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"This example has covered the fundamental aspects of setting up a parameter estimation problem directly Julia, but there are additional options:","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Steady-State Initialization: In some cases, you might require your model to be at a steady-state at time zero when starting to match the model against data. To learn how to set up pre-equilibration criteria, see this tutorial.\nTime-Point Specific Parameters: You might measure the same observable with different assays, leading to different observable parameters (e.g., scale and offset) and noise parameters for various time points. To handle time-point-specific measurement and noise parameters, see this tutorial.\nCondition Specific System/Model Parameters: Sometimes a subset of model parameters, like protein synthesis rates, vary between simulation conditions, while other parameters remain constant across all conditions. To handle conditions specific parameters, see this tutorial.\nEvents: Sometimes a model incorporates events like substrate addition at specific time points, and/or parameter changes when a state/species reaches certain values. To manage these events/callbacks, see this tutorial.","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"For guidance on choosing the best options for your specific PEtab problem, we recommend the Choosing the Best Options for a PEtab Problem section and refer to the Supported Gradient and Hessian Methods section for more information on available gradient and hessian methods.","category":"page"},{"location":"Define_in_julia/#Runnable-Example","page":"Defining parameter estimation problems in Julia","title":"Runnable Example","text":"","category":"section"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"Here is the complete code from the tutorial","category":"page"},{"location":"Define_in_julia/","page":"Defining parameter estimation problems in Julia","title":"Defining parameter estimation problems in Julia","text":"using Catalyst\nusing DataFrames\nusing Distributions\nusing ModelingToolkit\nusing PEtab\n\n# Define the reaction network\nrn = @reaction_network begin\n    @parameters se0\n    @species SE(t) = se0  # se0 = initial value for S\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\n\n@parameters c1, c2, c3, se0\n@variables t S(t) SE(t) P(t) E(t)\nD = Differential(t)\neqs = [\n    D(S) ~ -c1*S*E + c2*SE,\n    D(E) ~ -c1*S*E + c2*SE + c3*SE,\n    D(SE) ~ c1*S*E - c2*SE - c3*SE,\n    D(P) ~ c3*SE\n]\n@named sys = ODESystem(eqs; defaults=Dict(SE => se0))\n\n# Define state and parameter maps\nstate_map =  [:E => 1.0, :P => 0.0]\nparameter_map = [:c1 => 1.0]\n\n# Unpack model components\n@unpack P, E, SE = rn\n@parameters sigma, scale, offset\n\n# Define observables\nobs_P = PEtabObservable(scale * P + offset, sigma * P, transformation=:lin)\nobs_Sum = PEtabObservable(E + SE, 3.0, transformation=:log)\nobservables = Dict(\"obs_P\" => obs_P,\n                   \"obs_Sum\" => obs_Sum)\n\n# Define parameters for estimation\n_c3 = PEtabParameter(:c3, scale=:log10)\n_se0 = PEtabParameter(:se0, prior=LogNormal(log(3.1), 0.5), \n                      prior_on_linear_scale=true, sample_from_prior=true)\n_c2 = PEtabParameter(:c2)\n_sigma = PEtabParameter(:sigma)\n_scale = PEtabParameter(:scale)\n_offset = PEtabParameter(:offset)\nparameters = [_c2, _c3, _se0, _sigma, _scale, _offset]\n\n# Define simulation conditions\ncondition_c0 = Dict(:S => 5.0)\ncondition_c1 = Dict(:S => 2.0)\nsimulation_conditions = Dict(\"c0\" => condition_c0,\n                             \"c1\" => condition_c1)\n\n# Define measurement data\nmeasurements = DataFrame(\n    simulation_id=[\"c0\", \"c0\", \"c1\", \"c1\"],\n    obs_id=[\"obs_P\", \"obs_Sum\", \"obs_P\", \"obs_Sum\"],\n    time=[1.0, 10.0, 1.0, 20.0],\n    measurement=[0.7, 0.1, 1.0, 1.5]\n)\n\n# Create a PEtab model. To build the petab_model with ODE-system instead of\n# ReactionSystem provide sys instead of rn as first argument\npetab_model = PEtabModel(\n    rn, simulation_conditions, observables, measurements,\n    parameters, state_map=state_map, parameter_map=parameter_map, verbose=true\n)\n\n# Create a PEtabODEProblem\npetab_problem = PEtabODEProblem(petab_model)","category":"page"},{"location":"Julia_event/#define_events","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"","category":"section"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"To account for experimental interventions, such as the addition of a substrate, changes in experimental conditions (e.g., temperature), or automatic dosages when a species exceeds a certain concentration, events (often called callbacks, dosages etc...) can be used. In a PEtabModel, events can be encoded via PEtabEvent:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"PEtabEvent(condition, affect, target)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"where","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"condition is the event trigger and can be i) a constant value or a model parameter that are assumed to be the time the event is activated, or ii) a Boolean expression triggered when, for example, a state exceeds a certain value.\naffect is the effect of the event, which can either be a value or an algebraic expression involving model parameters and/or states. In case of several affects, provide a Vector.\ntarget specifies the target on which the effect acts. It must be either a model state or parameter. In case of several targets, provide a Vector of targets where affect[i] is the effect for target[i].","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"In this section we cover two types of events: those triggered at specific time-points and those triggered by a state (e.g., when a state exceeds a certain concentration), and as working example we use a modified version of the example in the Creating a PEtab Parameter Estimation Problem in Julia tutorial:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"using Catalyst\nusing DataFrames\nusing Distributions\nusing PEtab\nusing Plots\n\n\nsystem = @reaction_network begin\n    @parameters se0\n    @species SE(t) = se0  # se0 = initial value for S\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\n\n# Define state and parameter maps\nstate_map =  [:E => 1.0, :P => 0.0]\nparameter_map = [:c1 => 1.0]\n\n# Define observables\n@unpack P, E, SE = system\nobs_P = PEtabObservable(P, 1.0, transformation=:lin)\nobs_Sum = PEtabObservable(E + SE, 3.0, transformation=:log)\nobservables = Dict(\"obs_P\" => obs_P,\n                   \"obs_Sum\" => obs_Sum)\n\n# Define parameters for estimation\n_c3 = PEtabParameter(:c3, scale=:log10)\n_se0 = PEtabParameter(:se0, prior=LogNormal(1.0, 0.5), prior_on_linear_scale=true)\n_c2 = PEtabParameter(:c2)\npetab_parameters = [_c2, _c3, _se0]\n\n# Define simulation conditions\ncondition_c0 = Dict(:S => 5.0)\ncondition_c1 = Dict(:S => 2.0)\nsimulation_conditions = Dict(\"cond0\" => condition_c0,\n                             \"cond1\" => condition_c1)\n\n# Define measurement data\nmeasurements = DataFrame(\n    simulation_id=[\"cond0\", \"cond0\", \"cond1\", \"cond1\"],\n    obs_id=[\"obs_P\", \"obs_Sum\", \"obs_P\", \"obs_Sum\"],\n    time=[1.0, 10.0, 1.0, 20.0],\n    measurement=[0.7, 0.1, 1.0, 1.5]\n)\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm) # hide\nnothing # hide","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"note: Note\nEven though events can be directly encoded in a Catalyst or ModellingToolkit model, we strongly recommend PEtabEvent for optimal performance (e.g. use DiscreteCallback when possible), and for ensuring correct evaluation of the objective function and its derivatives.","category":"page"},{"location":"Julia_event/#Time-Triggered-Events","page":"Events (callbacks, dosages etc...)","title":"Time-Triggered Events","text":"","category":"section"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"Time-triggered events are activated at specific time-points. The condition can either a constant value (e.g. 1.0) or a model parameter (e.g. c2). For example, to trigger an event at t = 2 where the value 2 is added to the state S write:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"@unpack S = system\nevent = PEtabEvent(2.0, S + 2, S)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"When building the PEtabModel the event is then provided via the events keyword:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"petab_model = PEtabModel(\n    system, simulation_conditions, observables, measurements,\n    petab_parameters, state_map=state_map, parameter_map=parameter_map,\n    events=event, verbose=false\n)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)\nnothing # hide","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"Solving the model with the parameter vector p = [c2=0.1, c3=0.1, se0=0.1] we can clearly see that at t == 2 S is incremented by 2;","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"p = [0.1, 0.1, 0.1]\nodesol = get_odesol(p, petab_problem)\nplot(odesol)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"The trigger time can also be a model parameter. For instance, to trigger the event when t == c2 and to set c1 to 2.0 write:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"event = PEtabEvent(:c2, 2.0, :c1)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"and here it is clear a change occurs at t == c2","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"petab_model = PEtabModel(\n    system, simulation_conditions, observables, measurements,\n    petab_parameters, state_map=state_map, parameter_map=parameter_map,\n    events=event, verbose=false\n)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)\nodesol = get_odesol(p, petab_problem)\nplot(odesol)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"note: Note\nIf the condition and target are single parameters or states, they can be specied as Num (from unpack) or a Symbol. If the event involves multiple parameters or states, you must provide them as either a Num (as shown below) or a String.","category":"page"},{"location":"Julia_event/#State-Triggered-Events","page":"Events (callbacks, dosages etc...)","title":"State Triggered Events","text":"","category":"section"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"State-triggered events are activated when a species/state fulfills a certain condition. For example, suppose we have a dosage machine that trigger when the substrate S drops below the threshold value of 0.1, and at this time the machine adds up the substrate so it reaches the value 1.0:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"@unpack S = system\nevent = PEtabEvent(S == 0.2, 1.0, S)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"Here, S == 0.1 means that the event is triggered when S reaches the value of 0.1. Plotting the solution we clearly see how S is affected:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"petab_model = PEtabModel(\n    system, simulation_conditions, observables, measurements,\n    petab_parameters, state_map=state_map, parameter_map=parameter_map,\n    events=event, verbose=false\n)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)\nodesol = get_odesol(p, petab_problem)\nplot(odesol)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"With state-triggered events, the direction of the condition can matter. For instance, with S == 0.2, the event is triggered whether S approaches 0.2 from above or below. If we want it to activate only when S enters from above, write:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"@unpack S = system\nevent = PEtabEvent(S < 0.2, 1.0, S)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"Here, S < 0.2 means that the event will trigger only when the expression goes from false to true, in this case when S approaches 0.2 from above. To trigger the event only when S approaches 0.2 from below, write S > 0.2, and we can clearly see that with ","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"@unpack S = system\nevent = PEtabEvent(S > 0.2, 1.0, S)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"the event is not triggered when simulating the model as S comes from above","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"petab_model = PEtabModel(\n    system, simulation_conditions, observables, measurements,\n    petab_parameters, state_map=state_map, parameter_map=parameter_map,\n    events=event, verbose=false\n)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)\nodesol = get_odesol(p, petab_problem)\nplot(odesol)","category":"page"},{"location":"Julia_event/#Modifying-Event-Parameters-for-Different-Simulation-Conditions","page":"Events (callbacks, dosages etc...)","title":"Modifying Event Parameters for Different Simulation Conditions","text":"","category":"section"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"The trigger time (condition) and/or affect can be made specific to different simulation conditions by introducing control parameters (here c_time and c_value) and setting their values accordingly in the simulation conditions:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"system = @reaction_network begin\n    @parameters se0 c_time c_value\n    @species SE(t) = se0  # se0 represents the initial value of S\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\n\n# Define state and parameter maps\nstate_map =  [:E => 1.0, :P => 0.0]\n# c_value defaults to 1 prior to the event trigger\nparameter_map = [:c1 => 1.0]\n\ncondition_c0 = Dict(:S => 5.0, :c_time => 1.0, :c_value => 2.0)\ncondition_c1 = Dict(:S => 2.0, :c_time => 4.0, :c_value => 3.0)\nsimulation_conditions = Dict(\"cond0\" => condition_c0,\n                             \"cond1\" => condition_c1)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"In this setup, when the event is defined as:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"event = PEtabEvent(:c_time, :c_value, :c1)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"the c_time parameter controls when the event is triggered, so for condition c0, the event is triggered at t=1.0, while for condition c1, it is triggered at t=4.0. Additionally, for conditions cond0 and cond1, the parameter c1 takes on the corresponding c_value values, which is 2.0 and 3.0, respectively, which can clearly be seen when plotting the solution for cond0","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"petab_model = PEtabModel(\n    system, simulation_conditions, observables, measurements,\n    petab_parameters, state_map=state_map, parameter_map=parameter_map,\n    events=event, verbose=false\n)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)\nodesol = get_odesol(p, petab_problem; condition_id=:cond0)\nplot(odesol)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"and cond1","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"odesol = get_odesol(p, petab_problem; condition_id=:cond1)\nplot(odesol)","category":"page"},{"location":"Julia_event/#Multiple-Targets-for-an-Event","page":"Events (callbacks, dosages etc...)","title":"Multiple Targets for an Event","text":"","category":"section"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"Sometimes an event can affect multiple states and/or parameters. In this case, both affect and target should be provided as vectors to the PEtabEvent. For example, suppose an event is triggered when the substrate S < 0.2, where S is incremented by 2.0, and c1 changes its values to 2.0. This can be encoded as:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"@unpack S, c1 = system\nevent = PEtabEvent(S < 0.2, [S + 2, 2.0], [S, c1])","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"These events can then be provided when building the PEtabModel using the events keyword:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"petab_model = PEtabModel(\n    system, simulation_conditions, observables, measurements,\n    petab_parameters, state_map=state_map, parameter_map=parameter_map,\n    events=event, verbose=false\n)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)\nodesol = get_odesol(p, petab_problem)\nplot(odesol)","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"note: Note\nIn case of several affects the length of the affect vector must match the length of the event vector.","category":"page"},{"location":"Julia_event/#Multiple-Events","page":"Events (callbacks, dosages etc...)","title":"Multiple Events","text":"","category":"section"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"A model can have multiple events, which can be easily defined as a PEtabModel accepts a Vector of PEtabEvent as input. For example, suppose we have an event triggered when the substrate S satisfies S < 0.2, where S changes its value to 1.0. Additionally, we have another event triggered when t == 1.0, where the parameter c1 changes its value to 2.0. This can be encoded as:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"@unpack S, c1 = system\nevent1 = PEtabEvent(S < 0.2, 1.0, S)\nevent2 = PEtabEvent(1.0, 2.0, :c1)\nevents = [event1, event2]","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"These events can then be provided when building the PEtabModel with the events keyword:","category":"page"},{"location":"Julia_event/","page":"Events (callbacks, dosages etc...)","title":"Events (callbacks, dosages etc...)","text":"petab_model = PEtabModel(\n    system, simulation_conditions, observables, measurements,\n    petab_parameters, state_map=state_map, parameter_map=parameter_map,\n    events=events, verbose=false\n)\npetab_problem = PEtabODEProblem(petab_model, verbose=false)\nodesol = get_odesol(p, petab_problem)\nplot(odesol)","category":"page"},{"location":"Julia_obs_noise/#time_point_parameters","page":"Noise and observable parameters","title":"Noise and Observable Parameters","text":"","category":"section"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"It is common to measure an observable, such as a product P, with different experimental assays. This can lead to variation in the measurement noise parameter sigma between measurements for the same observable, and additionally, different assays might measure P on different relative scales, necessitating different scale and offset parameters. Measurement-specific parameters can be handled by defining noise and observable parameters. To demonstrate how, let us continue with the same enzyme kinetics model as in the Creating a PEtab Parameter Estimation Problem in Julia tutorial.","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"using Catalyst \nusing Distributions\nusing PEtab\n\nrn = @reaction_network begin\n    @parameters se0\n    @species SE(t) = se0  # se0 = initial value for S\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\nstate_map =  [:E => 1.0, :P => 0.0]\nparameter_map = [:c1 => 1.0]\n\n_c3 = PEtabParameter(:c3, scale=:log10)\n_se0 = PEtabParameter(:c3, prior=LogNormal(1.0, 0.5), prior_on_linear_scale=true)\n_c2 = PEtabParameter(:c2)\n_sigma = PEtabParameter(:sigma)\n_scale = PEtabParameter(:scale)\n_offset = PEtabParameter(:offset)\nparameters = [_c2, _c3, _se0, _sigma, _scale, _offset]\n\ncondition_c0 = Dict(:S => 5.0)\ncondition_c1 = Dict(:S => 2.0)\nsimulation_conditions = Dict(\"c0\" => condition_c0, \n                             \"c1\" => condition_c1)","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"Now, to incorporate time-point-specific noise and measurement parameters into the observable formula, we encode them in the form observableParameter... and noiseParameters.","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"@unpack P, E, SE = rn\n@parameters noiseParameter1_obs_P observableParameter1_obs_P observableParameter2_obs_P\nobs_P = PEtabObservable(observableParameter1_obs_P * P + observableParameter2_obs_P, noiseParameter1_obs_P * P)\nobs_Sum = PEtabObservable(E + SE, 3.0, transformation=:log)\nobservables = Dict(\"obs_P\" => obs_P, \n                   \"obs_Sum\" => obs_Sum) ","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"note: Note\nnoiseParameters and observableParameter must always be on the format observableParameter${n}_${observableId} and noiseParameter${n}_${observableId}with n starting from 1, in order to correctly map parameters when building the objective function.","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"Next, we provide values for these parameters in the measurement data. These parameters can either be specified as values or parameters that have been defined as a PEtabParameter. In the case of multiple noise or observable parameters for a measurement, they are delimited by a semicolon:","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"simulation_id (str) obs_id (str) time (float) measurement (float) observable_parameters (str|float) noise_parameters (str|float)\nc0 obs_P 1.0 0.7  \nc0 obs_Sum 10.0 0.1 scale;offset sigma\nc1 obs_P 1.0 1.0  \nc1 obs_Sum 20.0 1.5 1.0;1.0 4.0","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"Note, in case an observable (like obs_P) does not have noise-or observable-parameters we do not have to provide any values for it. For the first observation for observable obs_Sum the parameter scale maps to observableParameter1_obs_Sum while offset maps to observableParameter2_obs_Sum. In Julia, the measurement data would look like:","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"measurements = DataFrame(\n    simulation_id=[\"c0\", \"c0\", \"c0\", \"c0\"],\n    obs_id=[\"obs_P\", \"obs_Sum\", \"obs_P\", \"obs_Sum\"],\n    time=[1.0, 10.0, 1.0, 20.0],\n    measurement=[0.7, 0.1, 1.0, 1.5], \n    observable_parameters=[missing, \"scale;offset\", missing, \"1.0;1.0\"],\n    noise_parameters=[missing, \"sigma\", missing, 4.0]\n)","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"With this setup, you can create a PEtabODEProblem for model calibration:","category":"page"},{"location":"Julia_obs_noise/","page":"Noise and observable parameters","title":"Noise and observable parameters","text":"petab_model = PEtabModel(\n    rn, simulation_conditions, observables, measurements,\n    parameters, state_map=state_map, parameter_map=parameter_map, verbose=true\n)\npetab_problem = PEtabODEProblem(petab_model)  ","category":"page"},{"location":"Model_selection/#Model-selection-with-PEtab-Select","page":"Model selection (PEtab select)","title":"Model selection with PEtab Select","text":"","category":"section"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"In many scenarios we have competing hypotheses (model structures) that we want to compare. For model selection, various approaches like forward search, backward search, and exhaustive search using evaluation criteria such as AIC are commonly used. These methods are supported by PEtab Select, a tool designed for model selection.","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"note: Note\nTo use the parameter estimation functionality Optim, QuasiMonteCarlo and PyCall must be loaded (see examples below).","category":"page"},{"location":"Model_selection/#Example","page":"Model selection (PEtab select)","title":"Example","text":"","category":"section"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"PEtab.jl provides support for PEtab Select through the run_PEtab_select function. This function takes two required arguments; the path to the PEtab Select YAML file, and the optimizer for parameter estimation. For the optimizer, you can choose from optimizer=Fides() (Fides Newton-trust region), optimizer=IPNewton() from Optim.jl, or optimizer=LBFGS() from Optim.jl (see). Additionally, you can pass any keyword arguments accepted by the calibrate_model function for parameter estimation and PEtabODEProblem function for setting simulation options (see).","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"Since PEtab Select is a Python package, you need to have PyCall.jl installed. Before using it, build PyCall with a Python environment that has PEtab select installed. Here's an example of how to do it (note that path_python_exe depends on your system configuration):","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"using PyCall\npath_python_exe = joinpath(\"/\", \"home\", \"sebpe\", \"anaconda3\", \"envs\", \"PeTab\", \"bin\", \"python\")\nENV[\"PYTHON\"] = path_python_exe\nimport Pkg; Pkg.build(\"PyCall\")","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"Once you have a correctly encoded PEtab Select problem (see the guide for details), you can run PEtab Select using the IPNewton() optimizer with the following code:","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"using PEtab \nusing OrdinaryDiffEq\nusing Optim\nusing QuasiMonteCarlo\n\npath_yaml = joinpath(@__DIR__, \"PEtab_select\", \"0002\", \"petab_select_problem.yaml\")\npath_save = run_PEtab_select(path_yaml, IPNewton(), \n                          nOptimisationStarts=10, \n                          ode_solver=ODESolver(Rodas5P()),\n                          gradient_method=:ForwardDiff, \n                          hessian_method=:ForwardDiff)","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"┌ Info: PEtab select problem info\n│ Method: forward\n└ Criterion: AIC\n[ Info: Model selection round 1 with 1 candidates - as the code compiles in this round compiled it takes extra long time https://xkcd.com/303/\n[ Info: Callibrating model M1_0\n[ Info: Model selection round 2 with 3 candidates\n[ Info: Callibrating model M1_1\n[ Info: Callibrating model M1_2\n[ Info: Callibrating model M1_3\n[ Info: Model selection round 3 with 2 candidates\n[ Info: Callibrating model M1_5\n[ Info: Callibrating model M1_6\n[ Info: Model selection round 4 with 1 candidates\n[ Info: Callibrating model M1_7\n[ Info: Saving results for best model at 0002/PEtab_select_forward_AIC.yaml","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"The YAML file storing the model selection results will be saved at path_save.","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"To run the code, you will need the PEtab files, which you can find here. You can also find a fully runnable example of this tutorial here.","category":"page"},{"location":"Beer/#Beer_tut","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"","category":"section"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"Here we will create a PEtabODEproblem for a small ODE-model with many parameters to estimate. Specifically, the ODE-system has leq 20 states and leq 20 parameters, but there are approximately 70 parameters to estimate, since most parameters are specific to a subset of simulation conditions. For example, cond1 has a parameter τcond1, and cond2 has τcond2, which maps to the ODE-system parameter τ, respectively.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"To run the code, you need the Beer PEtab files, which you can find here. You can also find a fully runnable example of this tutorial here.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"First, we load the necessary libraries and read the model.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"using PEtab\nusing OrdinaryDiffEq\nusing Printf\n\npath_yaml = joinpath(@__DIR__, \"Beer\", \"Beer_MolBioSystems2014.yaml\") \npetab_model = PEtabModel(path_yaml, verbose=true)","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"PEtabModel for model Beer. ODE-system has 4 states and 9 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Beer/#Handling-condition-specific-parameters","page":"Models with many conditions specific parameters","title":"Handling condition-specific parameters","text":"","category":"section"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"When dealing with small ODE-systems like Beer, the most efficient gradient method is gradient_method=:ForwardDiff. Additionally, we can compute the hessian via hessian_method=:ForwardDiff. However, by default, we have to perform as many forward-passes (solve the ODE model) as there are model-parameters when we compute the gradient and hessian as we compute derivatives by a single call to ForwardDiff.jl. This is problematic since the Beer model has both many simulation conditions and model parameters to estimate. To address this issue, we can use the option split_over_conditions=true to force one ForwardDiff.jl call per simulation condition. This is most efficient for models where a majority of parameters are specific to a subset of simulation conditions.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"For a model like Beer, the following options are thus recommended:","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"ode_solver - Rodas5P() (works well for smaller models with up to 15 states) and we use the default abstol, reltol .= 1e-8.\ngradient_method - For small models like Beer, forward mode automatic differentiation (AD) is the fastest, so we choose :ForwardDiff.\nhessian_method - For small models like Boehm with up to 20 parameters, it is computationally feasible to compute the full Hessian via forward-mode AD. Thus, we choose :ForwardDiff.\nsplit_over_conditions=true - This forces a call to ForwardDiff.jl per simulation condition.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"ode_solver = ODESolver(Rodas5P(), abstol=1e-8, reltol=1e-8)\npetab_problem = PEtabODEProblem(petab_model, ode_solver, \n                                gradient_method=:ForwardDiff, \n                                hessian_method=:ForwardDiff, \n                                split_over_conditions=true, \n                                sparse_jacobian=false)\n\np = petab_problem.θ_nominalT\ngradient = zeros(length(p))\nhessian = zeros(length(p), length(p))\ncost = petab_problem.compute_cost(p)\npetab_problem.compute_gradient!(gradient, p)\npetab_problem.compute_hessian!(hessian, p)\n@printf(\"Cost = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])\n@printf(\"First element in the hessian = %.2f\\n\", hessian[1, 1])","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"Cost = -58622.91\nFirst element in the gradient = 7.17e-02\nFirst element in the hessian = 755266.33","category":"page"},{"location":"API_choosen/#API","page":"API","title":"API","text":"","category":"section"},{"location":"API_choosen/","page":"API","title":"API","text":"PEtabModel\nPEtabODEProblem\nPEtabObservable\nPEtabParameter\nPEtabEvent\nODESolver\nSteadyStateSolver\nremake_PEtab_problem\nFides\nPEtab.OptimizationProblem\nIpoptOptions\nIpoptOptimiser\ncalibrate_model\ncalibrate_model_multistart\nPEtabMultistartOptimisationResult\nrun_PEtab_select\ngenerate_startguesses\nget_ps\nget_u0\nget_odeproblem\nget_odesol","category":"page"},{"location":"API_choosen/#PEtab.PEtabModel","page":"API","title":"PEtab.PEtabModel","text":"PEtabModel\n\nA Julia-compatible representation of a PEtab-specified problem.\n\nFor constructor see below.\n\nnote: Note\nMost of the functions in PEtabModel are not intended to be accessed by the user. For example, compute_h  (and similar functions) require indices that are built in the background to efficiently map parameters between  experimental (simulation) conditions. Rather, PEtabModel holds all information needed to create a  PEtabODEProblem, and in the future, PEtabSDEProblem, etc.\n\nFields\n\nmodel_name: The model name extracted from the PEtab YAML file.\ncompute_h: Computes the observable h for a specific time point and simulation condition.\ncompute_u0!: Computes in-place initial values using ODEProblem.p for a simulation condition; compute_u0!(u0, p).\ncompute_u0: Computes initial values as above, but not in-place; u0 = compute_u0(p).\ncompute_σ: Computes the noise parameter σ for a specific time point and simulation condition.\ncompute_∂h∂u!: Computes the gradient of h with respect to ODEModel states (u) for a specific time point and simulation condition.\ncompute_∂σ∂u!: Computes the gradient of σ with respect to ODEModel states (u) for a specific time point and simulation condition.\ncompute_∂h∂p!: Computes the gradient of h with respect to ODEProblem.p.\ncompute_∂σ∂p!: Computes the gradient of σ with respect to ODEProblem.p.\ncompute_tstops: Computes the event times in case the model has DiscreteCallbacks (events).\nconvert_tspan::Bool: Tracks whether the time span should be converted to Dual numbers for ForwardDiff.jl gradients, in case the model has DiscreteCallbacks and the trigger time is a parameter set to be estimated.\ndir_model: The directory where the model.xml and PEtab files are stored.\ndir_julia: The directory where the Julia-model files created by parsing the PEtab files (e.g., SBML file) are stored.\node_system: A ModellingToolkit.jl ODE system obtained from parsing the model SBML file.\nparameter_map: A ModellingToolkit.jl parameter map for the ODE system.\nstate_map: A ModellingToolkit.jl state map for the ODE system describing how the initial values are computed, e.g., whether or not certain initial values are computed from parameters in the parameter_map.\nparameter_names: The names of the parameters in the ode_system.\nstate_names: The names of the states in the ode_system.\npath_measurements: The path to the PEtab measurements file.\npath_conditions: The path to the PEtab conditions file.\npath_observables: The path to the PEtab observables file.\npath_parameters: The path to the PEtab parameters file.\npath_SBML: The path to the PEtab SBML file.\npath_yaml: The path to the PEtab YAML file.\nmodel_callbacks: This stores potential model callbacks or events.\ncheck_callback_is_active: Piecewise SBML statements are transformed to DiscreteCallbacks that are activated at a specific time-point. The piecewise callback has a default value at t0 and is only triggered when reaching tactivation. If tactivation ≤ 0 (never reached when solving the model), this function checks whether the callback should be triggered before solving the model.\n\nConstructor\n\nPEtabModel(path_yaml::String;\n           build_julia_files::Bool=false,\n           verbose::Bool=true,\n           ifelse_to_event::Bool=true,\n           write_to_file::Bool=true,\n           jlfile_path::String=\"\")::PEtabModel\n\nCreate a PEtabModel from a PEtab specified problem with a YAML-file located at path_yaml.\n\nWhen parsing a PEtab problem, several things happen under the hood:\n\nThe SBML file is translated into ModelingToolkit.jl format to allow for symbolic computations of the ODE-model Jacobian. Piecewise and model events are further written into DifferentialEquations.jl callbacks.\nThe observable PEtab table is translated into a Julia file with functions for computing the observable (h), noise parameter (σ), and initial values (u0).\nTo allow gradients via adjoint sensitivity analysis and/or forward sensitivity equations, the gradients of h and σ are computed symbolically with respect to the ODE model's states (u) and parameters (ode_problem.p).\n\nAll of this happens automatically, and resulting files are stored under petab_model.dir_julia assuming writetofile=true. To save time, forceBuildJlFiles=false by default, which means that Julia files are not rebuilt if they already exist.\n\nArguments\n\npath_yaml::String: Path to the PEtab problem YAML file.\nbuild_julia_files::Bool=false: If true, forces the creation of Julia files for the problem even if they already exist.\nverbose::Bool=true: If true, displays verbose output during parsing.\nifelse_to_event::Bool=true: If true, rewrites if-else statements in the SBML model as event-based callbacks.\nwrite_to_file::Bool=true: If true, writes built Julia files to disk (recomended)\n\nExample\n\npetab_model = PEtabModel(\"path_to_petab_problem_yaml\")\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.PEtabODEProblem","page":"API","title":"PEtab.PEtabODEProblem","text":"PEtabODEProblem\n\nEverything needed to setup an optimization problem (compute cost, gradient, hessian and  parameter bounds) for a PEtab model.\n\nFor constructor, see below.\n\nnote: Note\nThe parameter vector θ is always assumed to be on the parameter scale specified in the PEtab parameters file. If needed, θ is transformed to the linear scale inside the function call.\n\nFields\n\ncompute_cost: For θ computes the negative likelihood (objective to minimize)\ncompute_chi2: For θ compute χ2 value\ncompute_gradient!: For θ computes in-place gradient compute_gradient!(gradient, θ)\ncompute_gradient: For θ computes out-place gradient gradient = compute_gradient(θ)\ncompute_hessian!: For θ computes in-place hessian-(approximation) compute_hessian!(hessian, θ)\ncompute_hessian: For θ computes out-place hessian-(approximation) hessian = compute_hessian(θ)\ncompute_FIM!: For θ computes the empirical Fisher-Information-Matrix (FIM) which is the Hessian of the negative-log-likelihood  compute_FIM!(FIM, θ).\ncompute_FIM: For θ computes FIM out of place FIM = compute_FIM(θ).\ncompute_simulated_values: For θ compute the corresponding model (simulated) values to the measurements in the same order as in the Measurements PEtab table\ncompute_residuals: For θ compute the residuals (hmodel - hobserved)^2 / σ^2 in the same order as in the Measurements PEtab table\ngradient_method: The method used to compute the gradient (either :ForwardDiff, :ForwardEquations, :Adjoint, or :Zygote).\nhessian_method: The method used to compute or approximate the Hessian (either :ForwardDiff, :BlocForwardDiff, or :GaussNewton).\nFIM_method: The method used to compute FIM, either :ForwardDiff (full Hessian) or :GaussNewton (only recomended for >100 parameter models)\nn_parameters_esimtate: The number of parameters to estimate.\nθ_names: The names of the parameters in θ.\nθ_nominal: The nominal values of θ as specified in the PEtab parameters file.\nθ_nominalT: The nominal values of θ on the parameter scale (e.g., log) as specified in the PEtab parameters file.\nlower_bounds: The lower parameter bounds on the parameter scale for θ as specified in the PEtab parameters file.\nupper_bounds: The upper parameter bounds on the parameter scale for θ as specified in the PEtab parameters file.\npetab_model: The PEtabModel used to construct the PEtabODEProblem.\node_solver: The options for the ODE solver specified when creating the PEtabODEProblem.\node_solver_gradient: The options for the ODE solver gradient specified when creating the PEtabODEProblem.\n\nConstructor\n\nPEtabODEProblem(petab_model::PEtabModel; <keyword arguments>)\n\nGiven a PEtabModel creates a PEtabODEProblem with potential user specified options.\n\nThe keyword arguments (described below) allows to choose cost, gradient, and Hessian methods, ODE solver options,  and other tuneable options that can potentially make computations more efficient for some \"edge-case\" models. Please  refer to the documentation for guidance on selecting the most efficient options for different types of models. If a  keyword argument is not set, a suitable default option is chosen based on the number of model parameters.\n\nOnce created, a PEtabODEProblem contains everything needed to perform parameter estimtimation (see above)\n\nnote: Note\nEvery problem is unique, so even though the default settings often work well they might not be optimal.\n\nKeyword arguments\n\node_solver::ODESolver: Options for the ODE solver when computing the cost, such as solver and tolerances.\node_solver_gradient::ODESolver: Options for the ODE solver when computing the gradient, such as the ODE solver options used in adjoint sensitivity analysis. Defaults to ode_solver if not set to nothing.\nss_solver::SteadyStateSolver: Options for finding steady-state for models with pre-equilibrium. Steady-state can be found via simulation or rootfinding, which can be set using SteadyStateSolver (see documentation). If not set, defaults to simulation with wrms < 1 termination.\nss_solver_gradient::SteadyStateSolver: Options for finding steady-state for models with pre-equilibrium when computing gradients. Defaults to ss_solver value if not set.\ncost_method::Symbol=:Standard: Method for computing the cost (objective). Two options are available: :Standard, which is the most efficient, and :Zygote, which is less efficient but compatible with the Zygote automatic differentiation library.\ngradient_method=nothing: Method for computing the gradient of the objective. Four options are available:\n:ForwardDiff: Compute the gradient via forward-mode automatic differentiation using ForwardDiff.jl. Most efficient for models with ≤50 parameters. The number of chunks can be optionally set using chunksize.\n:ForwardEquations: Compute the gradient via the model sensitivities, where sensealg specifies how to solve for the sensitivities. Most efficient when the Hessian is approximated using the Gauss-Newton method and when the optimizer can reuse the sensitivities (reuse_sensitivities) from gradient computations in Hessian computations (e.g., when the optimizer always computes the gradient before the Hessian).\n:Adjoint: Compute the gradient via adjoint sensitivity analysis, where sensealg specifies which algorithm to use. Most efficient for large models (≥75 parameters).\n:Zygote: Compute the gradient via the Zygote package, where sensealg specifies which sensitivity algorithm to use when solving the ODE model. This is the most inefficient option and not recommended.\nhessian_method=nothing: method for computing the Hessian of the cost. There are three available options:\n:ForwardDiff: Compute the Hessian via forward-mode automatic differentiation using ForwardDiff.jl. This is often only computationally feasible for models with ≤20 parameters but can greatly improve optimizer convergence.\n:BlockForwardDiff: Compute the Hessian block approximation via forward-mode automatic differentiation using ForwardDiff.jl. The approximation consists of two block matrices: the first is the Hessian for only the dynamic parameters (parameter part of the ODE system), and the second is for the non-dynamic parameters (e.g., noise parameters). This is computationally feasible for models with ≤20 dynamic parameters and often performs better than BFGS methods.\n:GaussNewton: Approximate the Hessian via the Gauss-Newton method, which often performs better than the BFGS method. If we can reuse the sensitivities from the gradient in the optimizer (see reuse_sensitivities), this method is best paired with gradient_method=:ForwardEquations.\nFIM_method=nothing: Method for computing the empirical Fisher-Information-Matrix (FIM), can be:\n:ForwardDiff - use ForwardDiff to compute the full Hessian (FIM) matrix, default for model with ≤ 100 parameters \n:GaussNewton - approximate the FIM as the Gauss-Newton Hessian approximation (only recomeded when ForwardDiff is computationally infeasible)\nsparse_jacobian::Bool=false: When solving the ODE du/dt=f(u, p, t), whether implicit solvers use a sparse Jacobian. Sparse Jacobian often performs best for large models (≥100 states).\nspecialize_level=SciMLBase.FullSpecialize: Specialization level when building the ODE problem. It is not recommended to change this parameter (see https://docs.sciml.ai/SciMLBase/stable/interfaces/Problems/).\nsensealg: Sensitivity algorithm for gradient computations. The available options for each gradient method are:\n:ForwardDiff: None (as ForwardDiff takes care of all computation steps).\n:ForwardEquations: :ForwardDiff (uses ForwardDiff.jl and typicaly performs best) or ForwardDiffSensitivity() and ForwardSensitivity() from SciMLSensitivity.jl (https://github.com/SciML/SciMLSensitivity.jl).\n:Adjoint: InterpolatingAdjoint() and QuadratureAdjoint() from SciMLSensitivity.jl.\n:Zygote: All sensealg in SciMLSensitivity.jl.\nsensealg_ss=nothing: Sensitivity algorithm for adjoint gradient computations for steady-state simulations. The available options are SteadyStateAdjoint(), InterpolatingAdjoint(), and QuadratureAdjoint() from SciMLSensitivity.jl. SteadyStateAdjoint() is the most efficient but requires a non-singular Jacobian, and in the case of a non-singular Jacobian, the code automatically switches to InterpolatingAdjoint().\nchunksize=nothing: Chunk-size for ForwardDiff.jl when computing the gradient and Hessian via forward-mode automatic differentiation. If nothing is provided, the default value is used. Tuning chunksize is non-trivial, and we plan to add automatic functionality for this.\nsplit_over_conditions::Bool=false: For gradient and Hessian via ForwardDiff.jl, whether or not to split calls to ForwardDiff across experimental (simulation) conditions. This parameter should only be set to true if the model has many parameters specific to an experimental condition; otherwise, the overhead from the calls will increase run time. See the Beer example for a case where this is needed.\nreuse_sensitivities::Bool=false : If set to true, reuse the sensitivities computed during gradient computations for the Gauss-Newton Hessian approximation. This option is only applicable when using hessian_method=:GaussNewton and gradient_method=:ForwardEquations. Note that it should only be used when the optimizer always computes the gradient before the Hessian.\nverbose::Bool=true : If set to true, print progress messages while setting up the PEtabODEProblem.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.PEtabObservable","page":"API","title":"PEtab.PEtabObservable","text":"PEtabObservable(obs_formula, noise_formula; transformation::Symbol=:lin)\n\nLinks a model to measurements using an observable formula and measurement noise formula.\n\nThe transformation argument can take one of three values: :lin (for normal measurement noise), :log, or :log10 (for log-normal measurement noise). For a full description of options, including how to define measurement-specific observable and noise parameters, see the main documentation.\n\nExamples\n\n# Example 1: Log-normal measurement noise with known error σ=3.0\n@unpack X = rn  # 'rn' is the dynamic model\nPEtabObservable(X, 3.0, transformation=:log)\n\n# Example 2: Normal measurement noise with estimation of σ (defined as PEtabParameter)\n@unpack X, Y = rn  # 'rn' is the dynamic model\n@parameters sigma\nPEtabObservable((X + Y) / X, sigma)\n\n# Example 3: Normal measurement noise with measurement-specific noiseParameter\n@unpack X, Y = rn  # 'rn' is the dynamic model\n@parameters noiseParameter1  # Must be in the format 'noiseParameter'\nPEtabObservable(X, noiseParameter1 * X)\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.PEtabParameter","page":"API","title":"PEtab.PEtabParameter","text":"PEtabParameter(id::Union{Num, Symbol}; <keyword arguments>)\n\nRepresents a parameter to be estimated in a PEtab model calibration problem.\n\nKeyword Arguments\n\nestimate::Bool=true: Specifies whether the parameter should be estimated (default) or set as constant.\nvalue::Union{Nothing, Float64}=nothing: The parameter value to use if estimate=false. Defaults to the midpoint between lb and ub.\nscale::Symbol=:log10: The scale on which to estimate the parameter. Allowed options are :log10 (default), :log, and :lin.\nlb::Float64=1e-3: The lower parameter bound in parameter estimation (default: 1e-3).\nub::Float64=1e-3: The upper parameter bound in parameter estimation (default: 1e3).\nprior=nothing: An optional continuous prior distribution from the Distributions package.\nprior_on_linear_scale::Bool=true: Specifies whether the prior is on the linear scale (default) or the transformed scale, e.g., log10-scale.\nsample_from_prior::Bool=true: Whether to sample the parameter from the prior distribution when generating startguesses for model calibration.\n\nExamples\n\n# Example 1: Parameter with a Log-Normal prior (LN(μ=3.0, σ=1.0)) estimated on the log10 scale\nPEtabParameter(:c1, prior=LogNormal(3.0, 1.0))\n\n# Example 2: Parameter estimated on the log scale with a Normal prior (N(0.0, 1.0)) on the log scale\nPEtabParameter(:c1, scale=:log, prior=Normal(0.0, 1.0), prior_on_linear_scale=false)\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.PEtabEvent","page":"API","title":"PEtab.PEtabEvent","text":"PEtabEvent(condition, affect, target)\n\nAn event triggered by condition that sets the value of target to that of affect.\n\nIf condition is a single value or model parameter (e.g., c1 or 1.0), the event is triggered when  time reaches that value (e.g., t == c1 or t == 1.0). Condition can also depend on model states,  for example, S == 2.0 will trigger the event when the state S reaches the value 2.0. In contrast,  S > 2.0 will trigger the condition when S increases from below 2.0 (specifically, the event is  triggered when the condition changes from false to true). Note that the condition can contain  model parameter values or species, e.g., S > c1.\n\naffect can be a constant value (e.g., 1.0) or an algebraic expression of model parameters/states.  For example, to add 5.0 to the state S, write S + 5. In case an event affects several parameters and/or states provide affect as a Vector, for example [S + 5, 1.0].\n\ntarget is either a model state or parameter that the event acts on. In case an event affects several  states and/or parameters provide as a Vector where target[i] is the target of affect[i].\n\nFor more details, see the documentation.\n\nnote: Note\nIf the condition and target are single parameters or states, they can be specied as Num (from unpack) or Symbol.  If the event involves multiple parameters or states, you must provide them as either a Num (as shown below) or a  String.\n\nExamples\n\nusing Catalyst\n# Trigger event at t = 3.0, add 5 to A\nrn = @reaction_network begin\n    (k1, k2), A <--> B\nend\n@unpack A = rn\nevent = PEtabEvent(3.0, A + 5.0, A)\n\nusing Catalyst\n# Trigger event at t = k1, set k2 to 3\nrn = @reaction_network begin\n    (k1, k2), A <--> B\nend\nevent = PEtabEvent(:k1, 3.0, :k2)\n\nusing Catalyst\n# Trigger event when A == 0.2, set B to 2.0\nrn = @reaction_network begin\n    (k1, k2), A <--> B\nend\n@unpack A, B = rn\nevent = PEtabEvent(A == 0.2, 2.0, B)\n\nusing Catalyst\n# Trigger event when A == 0.2, set B to 2.0 and A += 2\nrn = @reaction_network begin\n    (k1, k2), A <--> B\nend\n@unpack A, B = rn\nevent = PEtabEvent(A == 0.2, [A + 2, 2.0], [A, B])\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.ODESolver","page":"API","title":"PEtab.ODESolver","text":"ODESolver(solver, <keyword arguments>)\n\nODE-solver options (solver, tolerances, etc...) to use when computing gradient/cost for a PEtabODEProblem.\n\nMore information about the available options and solvers can be found in the documentation for DifferentialEquations.jl (https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/). Recommended settings for which solver and options to use for different problems can be found below and in the documentation.\n\nArguments\n\nsolver: Any of the ODE solvers in DifferentialEquations.jl. For small (≤20 states) mildly stiff models, composite solvers such as AutoVern7(Rodas5P()) perform well. For stiff small models, Rodas5P() performs well. For medium-sized models (≤75 states), QNDF(), FBDF(), and CVODE_BDF() perform well. CVODE_BDF() is not compatible with automatic differentiation and thus cannot be used if the gradient is computed via automatic differentiation or if the Gauss-Newton Hessian approximation is used. If the gradient is computed via adjoint sensitivity analysis, CVODE_BDF() is often the best choice as it is typically more reliable than QNDF() and FBDF() (fails less often).\nabstol=1e-8: Absolute tolerance when solving the ODE system. Not recommended to increase above 1e-6 for gradients.\nreltol=1e-8: Relative tolerance when solving the ODE system. Not recommended to increase above 1e-6 for gradients.\nforce_dtmin=false: Whether or not to force dtmin when solving the ODE system.\ndtmin=nothing: Minimal acceptable step-size when solving the ODE system.\nmaxiters=10000: Maximum number of iterations when solving the ODE system. Increasing above the default value can cause the optimization to take substantial time.\nverbose::Bool=true: Whether or not warnings are displayed if the solver exits early. true is recommended in order to detect if a suboptimal ODE solver was chosen.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.SteadyStateSolver","page":"API","title":"PEtab.SteadyStateSolver","text":"SteadyStateSolver(method::Symbol;\n                  check_simulation_steady_state::Symbol=:wrms,\n                  rootfinding_alg=nothing,\n                  abstol=nothing,\n                  reltol=nothing,\n                  maxiters=nothing)\n\nSetup options for finding steady-state via either method=:Rootfinding or method=:Simulate.\n\nFor method=:Rootfinding, the steady-state u* is found by solving the problem du = f(u, p, t) ≈ 0 with tolerances  abstol and reltol via an automatically chosen optimization algorithm (rootfinding_alg=nothing) or via any  provided algorithm in NonlinearSolve.jl.\n\nFor method=:Simulate, the steady-state u* is found by simulating the ODE system until du = f(u, p, t) ≈ 0.  Two options are available for check_simulation_steady_state:\n\n:wrms : Weighted root-mean square √(∑((du ./ (reltol * u .+ abstol)).^2) / length(u)) < 1\n:Newton : If Newton-step Δu is sufficiently small √(∑((Δu ./ (reltol * u .+ abstol)).^2) / length(u)) < 1.       - Newton often performs better but requires an invertible Jacobian. In case it's not fulfilled, the code          switches automatically to :wrms.\n\nmaxiters refers to either the maximum number of rootfinding steps or the maximum number of integration steps,  depending on the chosen method.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.remake_PEtab_problem","page":"API","title":"PEtab.remake_PEtab_problem","text":"remake_PEtab_problem(petab_problem::PEtabODEProblem, parameters_change::Dict) :: PEtabODEProblem\n\nFixate model parameters for a given PEtabODEProblem without recompiling the problem.\n\nThis function allows you to modify parameters without the need to recompile the underlying code, resulting in reduced latency. To fixate the parameter k1, you can use parameters_change=Dict(:k1 => 1.0).\n\nIf model derivatives are computed using ForwardDiff.jl with a chunk-size of N, the new PEtabODEProblem will only evaluate the necessary number of chunks of size N to compute the full gradient for the remade problem.\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.Fides","page":"API","title":"PEtab.Fides","text":"Fides(hessian_method::Union{Nothing, Symbol}; verbose::Bool=false)\n\nFides is a Python Newton-trust region optimizer designed for box-bounded optimization problems.\n\nIt excels when the full Hessian is too computationally expensive, but a Gauss-Newton Hessian approximation can be calculated. When constructed with Fides(verbose=true), it displays optimization progress during estimation.\n\nHessian Methods\n\nIf hessian_method=nothing, the Hessian method from the PEtabODEProblem is used, which can be either exact or a Gauss-Newton approximation. Additionally, Fides supports the following Hessian approximation methods:\n\n:BB: Broyden's \"bad\" method\n:BFGS: Broyden-Fletcher-Goldfarb-Shanno update strategy\n:BG: Broyden's \"good\" method\n:Broyden: BroydenClass Update scheme \n:SR1: Symmetric Rank 1 update\n:SSM: Structured Secant Method\n:TSSM: Totally Structured Secant Method\n\nFor more information on each method, see the Fides documentation.\n\nExamples\n\n# Fides with the Hessian method as in the PEtabProblem\nfides_opt = Fides(nothing)\n\n# Fides with the BFGS Hessian approximation, with progress printing\nfides_opt = Fides(:BFGS; verbose=true)\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.OptimizationProblem","page":"API","title":"PEtab.OptimizationProblem","text":"OptimizationProblem(petab_problem::PEtabODEProblem;\n                    interior_point_alg::Bool = false,\n                    box_constraints::Bool = true)\n\nCreate an Optimization.jl OptimizationProblem from a PEtabODEProblem.\n\nTo utilize interior-point Newton methods (e.g. Optim IPNewton or Ipopt), set interior_point_alg to true.\n\nTo use algorithms not compatible with box-constraints (e.g., NewtonTrustRegion), set box_constraints to false. Note, with this options optimizers may move outside exceed the parameter bounds in the petab_problem, which can negatively impact performance.\n\nExamples\n\n# Use IPNewton with startguess u0\nusing OptimizationOptimJL\nprob = PEtab.OptimizationProblem(petab_problem, interior_point=true)\nprob.u0 .= u0\nsol = solve(prob, IPNewton())\n\n# Use Optim ParticleSwarm with startguess u0\nusing OptimizationOptimJL\nprob = PEtab.OptimizationProblem(petab_problem)\nprob.u0 .= u0\nsol = solve(prob, Optim.ParticleSwarm())\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.IpoptOptions","page":"API","title":"PEtab.IpoptOptions","text":"IpoptOptions(;print_level::Int64=0, \n             max_iter::Int64=1000, \n             tol::Float64=1e-8, \n             acceptable_tol::Float64=1e-6, \n             max_wall_time::Float64=1e20, \n             acceptable_obj_change_tol::Float64=1e20)\n\nWrapper for a subset of Ipopt options to set during parameter estimation.\n\nFor more information about each options see the Ipopt documentation\n\nArguments\n\nprint_level: Output verbosity level (valid values are 0 ≤ print_level ≤ 12)\nmax_iter: Maximum number of iterations\ntol: Relative convergence tolerance\nacceptable_tol: Acceptable relative convergence tolerance\nmax_wall_time: Max wall time optimisation is allowed to run\nacceptable_obj_change_tol: Acceptance stopping criterion based on objective function change.\n\nSee also calibrate_model and calibrate_model_multistart.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.IpoptOptimiser","page":"API","title":"PEtab.IpoptOptimiser","text":"IpoptOptimiser(LBFGS::Bool)\n\nIpopt is an Interior-point Newton method designed for nonlinear optimization.\n\nIpopt can be configured to use either the Hessian method from the PEtabODEProblem (LBFGS=false) or a LBFGS scheme (LBFGS=true).  For setting Ipopt options, see IpoptOptions.\n\nSee also calibrate_model and calibrate_model_multistart.\n\nExamples\n\n# Ipopt with the Hessian method as in the PEtabProblem\nipopt_opt = IpoptOptimiser(false)\n\n# Ipopt with LBFGS Hessian approximation\nipopt_opt = IpoptOptimiser(true)\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.calibrate_model","page":"API","title":"PEtab.calibrate_model","text":"calibrate_model(petab_problem::PEtabODEProblem,\n                p0::Vector{Float64},\n                alg;\n                save_trace::Bool=false,\n                options=algOptions)::PEtabOptimisationResult\n\nParameter estimate a model for a PEtabODEProblem using an optimization algorithm alg and an initial guess p0.\n\nThe optimization algorithm alg can be one of the following:\n\nOptim LBFGS, BFGS, or IPNewton methods\nIpoptOptimiser interior-point optimizer\nFides Newton trust region method\n\nFor how to use an OptimizationProblem from Optimization.jl see below.\n\nEach algorithm accepts specific optimizer options in the format of the respective package. For a comprehensive list of available options, please refer to the main documentation.\n\nIf you want the optimizer to return parameter and objective trace information, set save_trace=true. Results are returned as a PEtabOptimisationResult, which includes the following information: minimum parameter values found (xmin), smallest objective value (fmin), number of iterations, runtime, whether the optimizer converged, and optionally, the trace.\n\ncalibrate_model(optimization_problem::OptimizationProblem,\n                petab_problem::PEtabODEProblem,\n                p0::Vector{Float64},\n                alg;\n                kwargs...)\n\nPerform parameter estimation for an OptimizationProblem using algorithm alg and startguess p0.\n\nTo create an OptimizationProblem from a PEtabODEProblem, see PEtab.OptimizationProblem. All algorithms from Optimization.jl are supported. However, depending on the algorithm, different options must be specified when creating the OptimizationProblem.\n\nSolver options are provided via keyword arguments, and a list can be found here. To, for example, run calibration with reltol=1e-8, use calibrate_model(prob, p0, alg; reltol=1e-8).\n\nnote: Note\nTo use Optim optimizers, you must load Optim with using Optim. To use Ipopt, you must load Ipopt with using Ipopt. To use Fides, load PyCall with using PyCall and ensure Fides is installed (see documentation for setup). To use Optimization load Optimization.jl with using Optimization\n\nExamples\n\n# Perform parameter estimation using Optim's IPNewton with a given initial guess\nusing Optim\nres = calibrate_model(petab_problem, p0, Optim.IPNewton();\n                     options=Optim.Options(iterations = 1000))\n\n# Perform parameter estimation using Fides with a given initial guess\nusing PyCall\nres = calibrate_model(petab_problem, p0, Fides(nothing);\n                     options=py\"{'maxiter' : 1000}\"o)\n\n# Perform parameter estimation using Ipopt and save the trace\nusing Ipopt\nres = calibrate_model(petab_problem, p0, IpoptOptimiser(false);\n                     options=IpoptOptions(max_iter = 1000),\n                     save_trace=true)\n\n# Perform parameter estimation using Optimization\nusing Optimization\nusing OptimizationOptimJL\nprob = PEtab.OptimizationProblem(petab_problem, interior_point_alg=true)\nres = calibrate_model(prob, petab_problem, p0, IPNewton())\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.calibrate_model_multistart","page":"API","title":"PEtab.calibrate_model_multistart","text":"calibrate_model_multistart(petab_problem::PEtabODEProblem,\n                           alg,\n                           n_multistarts::Signed,\n                           dir_save::Union{Nothing, String};\n                           sampling_method=QuasiMonteCarlo.LatinHypercubeSample(),\n                           sample_from_prior::Bool=true,\n                           options=options,\n                           seed=nothing,\n                           save_trace::Bool=false)::PEtabMultistartOptimisationResult\n\nPerform multistart optimization for a PEtabODEProblem using the algorithm alg.\n\nThe optimization algorithm alg can be one of the following:\n\nOptim LBFGS, BFGS, or IPNewton methods\nIpoptOptimiser interior-point optimizer\nFides Newton trust region method\n\nFor each algorithm, optimizer options can be provided in the format of the respective package. For a comprehensive list of available options, please refer to the main documentation. If you want the optimizer to return parameter and objective trace information, set save_trace=true.\n\nMultistart optimization involves generating multiple starting points for optimization runs. These starting points are generated using the specified sampling_method from QuasiMonteCarlo.jl, with the default being LatinHypercubeSample, a method that typically produces better results than random sampling. If sample_from_prior=true (default), for parameters with priors samples are taken from the prior distribution, where the distribution is clipped/truncated by the parameter's lower- and upper bound. For reproducibility, you can set a random number generator seed using the seed parameter.\n\nIf dir_save is provided as nothing, results are not written to disk. Otherwise, if a directory path is provided, results are written to disk. Writing results to disk is recommended in case the optimization process is terminated after a number of optimization runs.\n\nThe results are returned as a PEtabMultistartOptimisationResult, which stores the best-found minima (xmin), smallest objective value (fmin), as well as optimization results for each run.\n\ncalibrate_model_multistart(optimization_problem::OptimizationProblem,\n                           alg,\n                           n_multistarts::Signed,\n                           dir_save::Union{Nothing, String};\n                           sampling_method=QuasiMonteCarlo.LatinHypercubeSample(),\n                           sample_from_prior::Bool=true,\n                           seed::Union{Nothing, Integer}=nothing,\n                           kwargs...)::PEtabMultistartOptimisationResult\n\nPerform multistart optimization for a OptimizationProblem using the algorithm alg.\n\nTo create an OptimizationProblem from a PEtabODEProblem, see PEtab.OptimizationProblem. All algorithms from Optimization.jl are supported. However, depending on the algorithm, different options must be specified when creating the OptimizationProblem.\n\nSolver options are provided via keyword arguments, and a list can be found here. To, for example, run calibration with reltol=1e-8, use calibrate_model_multistart(prob, alg, n, dir_save; reltol=1e-8).\n\nnote: Note\nTo use Optim optimizers, you must load Optim with using Optim. To use Ipopt, you must load Ipopt with using Ipopt. To use Fides, load PyCall with using PyCall and ensure Fides is installed (see documentation for setup). To use Optimization load Optimization.jl with using Optimization\n\nExamples\n\n# Perform 100 optimization runs using Optim's IPNewton, save results in dir_save\nusing Optim\ndir_save = joinpath(@__DIR__, \"Results\")\nres = calibrate_model_multistart(petab_problem, Optim.IPNewton(), 100, dir_save;\n                               options=Optim.Options(iterations = 1000))\n\n# Perform 100 optimization runs using Fides, save results in dir_save\nusing PyCall\ndir_save = joinpath(@__DIR__, \"Results\")\nres = calibrate_model_multistart(petab_problem, Fides(nothing), 100, dir_save;\n                               options=py\"{'maxiter' : 1000}\"o)\n\n# Perform 100 optimization runs using Ipopt, save results in dir_save. For each\n# run save the trace\nusing Ipopt\ndir_save = joinpath(@__DIR__, \"Results\")\nres = calibrate_model_multistart(petab_problem, IpoptOptimiser(false), 100, dir_save;\n                               options=IpoptOptions(max_iter = 1000),\n                               save_trace=true)\n\n# Perform 100 optimization runs using Optimization with IPNewton, save results in dir_save.\nusing Optimization\nusing OptimizationOptimJL\nprob = PEtab.OptimizationProblem(petab_problem, interior_point_alg=true)\nres = calibrate_model_multistart(prob, IPNewton(), 100, dir_save;\n                                 reltol=1e-8)\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.PEtabMultistartOptimisationResult","page":"API","title":"PEtab.PEtabMultistartOptimisationResult","text":"PEtabMultistartOptimisationResult(dir_res::String; which_run::String=\"1\")\n\nRead PEtab multistart optimization results saved at dir_res.\n\nEach time a new optimization run is performed, results are saved with unique numerical endings  appended to the directory specified by dir_res. Results from a specific run can be retreived  by specifying the numerical ending by which_run. For example, to access results from the second run,  set which_run=\"2\".\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.run_PEtab_select","page":"API","title":"PEtab.run_PEtab_select","text":"run_PEtab_select(path_yaml, alg; <keyword arguments>)\n\nGiven a PEtab-select YAML file perform model selection with the algorithms specified in the YAML file.\n\nResults are written to a YAML file in the same directory as the PEtab-select YAML file.\n\nEach candidate model produced during the model selection undergoes parameter estimation using local multi-start optimization. Three alg are supported: optimizer=Fides() (Fides Newton-trust region), optimizer=IPNewton() from Optim.jl, and optimizer=LBFGS() from Optim.jl. Additional keywords for the optimisation are n_multistarts::Int- number of multi-starts for parameter estimation (defaults to 100) and optimizationSamplingMethod - which is any sampling method from QuasiMonteCarlo.jl for generating start guesses (defaults to LatinHypercubeSample).\n\nSimulation options can be set using any keyword argument accepted by the PEtabODEProblem function. For example, setting gradient_method=:ForwardDiff specifies the use of forward-mode automatic differentiation for gradient computation. If left blank, we automatically select appropriate options based on the size of the problem.\n\nnote: Note\nTo use Optim optimizers, you must load Optim with using Optim. To use Ipopt, you must load Ipopt with using Ipopt. To use Fides, load PyCall with using PyCall and ensure Fides is installed (see documentation for setup).\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.generate_startguesses","page":"API","title":"PEtab.generate_startguesses","text":"generate_startguesses(petab_problem::PEtabODEProblem,\n                      n_multistarts::Int64;\n                      sampling_method::T=QuasiMonteCarlo.LatinHypercubeSample(),\n                      sample_from_prior::Bool=true,\n                      allow_inf_for_startguess::Bool=false,\n                      verbose::Bool=false)::Array{Float64} where T <: QuasiMonteCarlo.SamplingAlgorithm\n\nGenerate n_multistarts initial parameter guesses within the parameter bounds in the petab_problem with sampling_method\n\nAny sampling algorithm from QuasiMonteCarlo is supported, but LatinHypercubeSample is recomended as it usually performs well. If sample_from_prior=true (default), for parameters with priors samples are taken from said prior distribution, where the distribution is clipped/truncated by the parameter's lower- and upper bound.\n\nIf n_multistarts is set to 1, a single random vector within the parameter bounds is returned. For n_multistarts > 1, a matrix is returned, with each column representing a different initial guess.\n\nBy default allow_inf_startguess=false - only initial guesses that result in finite cost evaluations are returned. If allow_inf_startguess=true, initial guesses that result in Inf are allowed.\n\nExample\n\n# Generate a single initial guess within the parameter bounds\nstart_guess = generate_startguesses(petab_problem, 1)\n\n# Generate 10 initial guesses using Sobol sampling\nstart_guess = generate_startguesses(petab_problem, 10,\n                                    sampling_method=QuasiMonteCarlo.SobolSample())\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.get_ps","page":"API","title":"PEtab.get_ps","text":"get_ps(res::Union{PEtabOptimisationResult, PEtabMultistartOptimisationResult, Vector{Float64}}, \n       petab_problem::PEtabODEProblem;\n       condition_id::Union{String, Symbol, Nothing}=nothing,\n       retmap::Bool=true)\n\nFrom a fitted PEtab model or parameter vector retrieve the ODE parameters to simulate the model for the specified condition_id.\n\nIf condition_id is provided, the parameters are extracted for that specific simulation condition. If not provided,  parameters for the first (default) simulation condition are returned.\n\nIf a parameter vector is provided it must have the parameters in the same order as petab_problem.θ_names.\n\nIf retmap=true, a parameter vector is returned; otherwise, a vector is returned.\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.get_u0","page":"API","title":"PEtab.get_u0","text":"get_u0(res::Union{PEtabOptimisationResult, PEtabMultistartOptimisationResult, Vector{Float64}}, \n       petab_problem::PEtabODEProblem;\n       condition_id::Union{String, Symbol}=nothing,\n       pre_eq_id::Union{String, Symbol, Nothing}=nothing, \n       retmap::Bool=true)\n\nFrom a fitted PEtab model or parameter vector retrieve the inital values (u0) to simulate the model for the specified condition_id.\n\nIf condition_id is provided, the initial values are extracted for that specific simulation condition. If not provided,  initial values for the first (default) simulation condition are returned.\n\nIf a pre_eq_id is provided, the initial values are taken from the pre-equilibration simulation corresponding to  pre_eq_id. If there are potential overrides of initial values in the simulation conditions, they take priority over  the pre-equilibrium simulation.\n\nIf a parameter vector is provided it must have the parameters in the same order as petab_problem.θ_names.\n\nIf retmap=true, a parameter vector is returned; otherwise, a vector is returned.\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.get_odeproblem","page":"API","title":"PEtab.get_odeproblem","text":"get_odeproblem(res::Union{PEtabOptimisationResult, PEtabMultistartOptimisationResult, Vector{Float64}}, \n               petab_problem::PEtabODEProblem;\n               condition_id::Union{String, Symbol, Nothing}=nothing, \n               pre_eq_id::Union{String, Symbol, Nothing}=nothing)\n\nFrom a fitted PEtab model or parameter vector retrieve the ODEProblem and callbacks to simulate the model for the specified condition_id.\n\nIf condition_id is provided, the parameters are extracted for that specific simulation condition. If not provided,  parameters for the first (default) simulation condition are returned.\n\nIf a pre_eq_id is provided, the initial values are taken from the pre-equilibration simulation corresponding to  pre_eq_id.\n\nIf a parameter vector is provided it must have the parameters in the same order as petab_problem.θ_names.\n\nPotential events are returned as second argument, and potential time of events (tstops) are returned as  third argument.\n\nExample\n\nusing OrdinaryDiffEq\n# Solve the model with callbacks \nprob, cb, tstops = get_odeproblem(res, petab_problem, condition_id=\"cond1\")\nsol = solve(prob, Rodas5P(), callback=cb, tstops=tstops)\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.get_odesol","page":"API","title":"PEtab.get_odesol","text":"get_odesol(res::Union{PEtabOptimisationResult, PEtabMultistartOptimisationResult, Vector{Float64}}, \n           petab_problem::PEtabODEProblem;\n           condition_id::Union{String, Symbol, Nothing}=nothing, \n           pre_eq_id::Union{String, Symbol, Nothing}=nothing)\n\nFrom a fitted PEtab model or parameter vector retrieve the ODE solution for the specified condition_id.\n\nIf condition_id is provided, the parameters are extracted for that specific simulation condition. If not provided,  parameters for the first (default) simulation condition are returned.\n\nIf a pre_eq_id is provided, the initial values are taken from the pre-equilibration simulation corresponding to  pre_eq_id.\n\nIf a parameter vector is provided it must have the parameters in the same order as petab_problem.θ_names.\n\nPotential events are accounted for when solving the ODE model. The ODE solver options specified when creating the  petab_problem are used for solving the model.\n\n\n\n\n\n","category":"function"},{"location":"Best_options/#best_options","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"PEtab.jl provides several gradient and hessian methods that can be used with the ODE solvers in the DifferentialEquations.jl package. You can choose from a variety of options when creating a PEtabODEProblem. If you do not specify any of these options, appropriate options will be selected automatically based on an extensive benchmark study. These default options usually work well for specific problem types. In the following section, we will discuss the main findings of the benchmark study.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nThese recommendations often work well for specific problem types, they may not be optimal for every model, as each problem is unique.","category":"page"},{"location":"Best_options/#Small-models-(\\leq-20-parameters-and-\\leq-15-ODE:s)","page":"Choosing the best options for a PEtab problem","title":"Small models (leq 20 parameters and leq 15 ODE:s)","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"ODE solver: For small stiff models, the Rosenbrock Rodas5P() solver is often the fastest and most accurate option. While Julia bdf-solvers such as QNDF() can also perform well, they are often less reliable and less accurate than Rodas5P(). If the model is \"mildly\" stiff, composite solvers such as AutoVern7(Rodas5P()) often perform best. Regardless of solver, we recommend using low tolerances (around abstol, reltol = 1e-8, 1e-8) to obtain accurate gradients.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Gradient method: For small models, forward-mode automatic differentiation via ForwardDiff.jl tends to be the best performing option, and is often twice as fast as the forward-sensitivity equations approach in AMICI. Therefore, we recommend using gradient_method=:ForwardDiff.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nFor :ForwardDiff, the user can set the chunk-size, which can substantially improve performance. We plan to add automatic tuning of this in the future.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nIf the model has many simulation condition-specific parameters (parameters that only appear in a subset of simulation conditions), it can be efficient to set split_over_conditions=true (see this tutorial).","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Hessian method: For small models, it is computationally feasible to compute an accurate full Hessian via ForwardDiff.jl. For most models we benchmarked, using a provided Hessian improved convergence. Therefore, we recommend using hessian_method=:ForwardDiff.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nFor models with pre-equilibration (steady-state simulations), our benchmarks suggest that it might be better to use the Gauss-Newton Hessian approximation.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nFor models where it is too expensive to compute the full Hessian (e.g. due to many simulation conditions), the Hessian block approximation can be a good option.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nIn particular, the interior-point Newton method from Optim.jl performs well if provided with a full Hessian.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Overall, for a small model, a good setup often is:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petab_problem = PEtabODEProblem(petab_model,\n                                ode_solver=ODESolver(Rodas5P(), abstol=1e-8, reltol=1e-8),\n                                gradient_method=:ForwardDiff,\n                                hessian_method=:ForwardDiff)","category":"page"},{"location":"Best_options/#Medium-sized-models-(\\leq-75-parameters-and-\\leq-50-ODE:s)","page":"Choosing the best options for a PEtab problem","title":"Medium-sized models (leq 75 parameters and leq 50 ODE:s)","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"ODE solver: For medium-sized stiff models, bdf-solvers like QNDF() are often fast enough and accurate. However, they can fail for certain models with many events when low tolerances are used. In such cases, KenCarp4() is a good alternative. Another option is Sundials' CVODE_BDF(), but it is written in C++ and not compatible with forward-mode automatic differentiation. To obtain accurate gradients, we recommend using low tolerances (around abstol, reltol = 1e-8, 1e-8) regardless of solver.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Gradient method: For medium-sized models, when using the Gauss-Newton method to approximate the Hessian, we recommend computing the gradient via the forward sensitivities (gradient_method=:ForwardEquations), where the sensitivities are computed via forward-mode automatic differentiation (sensealg=:ForwardDiff). This way, the sensitivities can be reused when computing the Hessian if the optimizer always computes the gradient first. Otherwise, if a BFGS Hessian-approximation is used, gradient_method=:ForwardDiff often performs best.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nFor :ForwardDiff, the user can set the chunk-size to improve performance, and we plan to add automatic tuning of it.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nIf the model has many simulation condition-specific parameters (parameters that only appear in a subset of simulation conditions), it can be efficient to set split_over_conditions=true (see this tutorial).","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Hessian method: For medium-sized models, it is often computationally infeasible to compute an accurate full Hessian via ForwardDiff.jl. Instead, we recommend the Gauss-Newton Hessian approximation, which often performs better than the commonly used (L)-BFGS approximation. Thus, we recommend hessian_method=:GaussNewton.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nTrust-region Newton methods like Fides.py perform well if provided with a full Hessian. Interior-point methods don't perform as well.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Overall, when the gradient is always computed before the Hessian in the optimizer, a good setup is often:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petab_problem = PEtabODEProblem(petab_model,\n                                ode_solver=ODESolver(QNDF(), abstol=1e-8, reltol=1e-8),\n                                gradient_method=:ForwardEquations,\n                                hessian_method=:GaussNewton,\n                                reuse_sensitivities=true)","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Otherwise, a good setup is:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petab_problem = PEtabODEProblem(petab_model,\n                                ode_solver=ODESolver(QNDF(), abstol=1e-8, reltol=1e-8),\n                                gradient_method=:ForwardDiff,\n                                hessian_method=:GaussNewton)","category":"page"},{"location":"Best_options/#Large-models-(\\geq-75-parameters-and-\\geq-50-ODE:s)","page":"Choosing the best options for a PEtab problem","title":"Large models (geq 75 parameters and geq 50 ODE:s)","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"ODE solver: To efficiently solve large models, we recommend benchmarking different ODE solvers that are suitble for large problems; such as QNDF(), FBDF(), KenCarp4(), and CVODE_BDF(). You can also try providing the ODE solver with a sparse Jacobian (sparse_jacobian::Bool=false) and testing different linear solvers such as CVODE_BDF(linsolve=:KLU). Check out this link for more information on solving large stiff models in Julia.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nIt is important to compare different ODE solvers, as this can significantly reduce runtime.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Gradient method: For large models, the most scalable approach is adjoint sensitivity analysis (gradient_method=:Adjoint). We support InterpolatingAdjoint() and QuadratureAdjoint() from SciMLSensitivity (see their documentation for info), but we recommend InterpolatingAdjoint() because it's more reliable.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nWhen using adjoint sensitivity analysis, we recommend manually setting the ODE solver gradient options. Currently, CVODE_BDF() outperforms all native Julia solvers.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nYou can provide any options that InterpolatingAdjoint() and QuadratureAdjoint() accept.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nAdjoint sensitivity analysis is not as reliable in Julia as in AMICI (see), but our benchmarks show that SciMLSensitivity has the potential to be faster.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Hessian method: For large models, computing the sensitives (Gauss-Newton) or a full hessian is not computationally feasible. Thus, the best option is often to use an L-(BFGS) approximation. BFGS support is built into most available optimizers such as Optim.jl, Ipopt.jl, and Fides.py.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"All in all, for a large model, a good setup often is:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petab_problem = PEtabODEProblem(petab_model,\n                                ode_solver=ODESolver(CVODE_BDF(), abstol=1e-8, reltol=1e-8),\n                                ode_solver_gradient=ODESolver(CVODE_BDF(), abstol=1e-8, reltol=1e-8),\n                                gradient_method=:Adjoint,\n                                sensealg=InterpolatingAdjoint())","category":"page"},{"location":"Avaible_optimisers/#options_optimizers","page":"Available optimisers","title":"Available Optimizers","text":"","category":"section"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"PEtab.jl offers an interface to several popular optimization packages such as Optim.jl, Ipopt.jl, Fides.py and Optimization.jl for performing parameter estimation. Below, you find the available options for each optimizer.","category":"page"},{"location":"Avaible_optimisers/#Optim_alg","page":"Available optimisers","title":"Optim","text":"","category":"section"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"PEtab.jl supports three optimization methods from Optim.jl: LBFGS, BFGS, and IPNewton (Interior-point Newton). You can further customize the optimization by providing options via Optim.Options(). A complete list of available options can be found here.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"For example, LBFGS with 10,000 iterations can be used via:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"res = calibrate_model(petab_problem, p0, Optim.LBFGS(),\n                     options=Optim.Options(iterations = 10000))","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"If no options are provided, the default values are used:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Optim.Options(iterations = 1000,\n              show_trace = false,\n              allow_f_increases = true,\n              successive_f_tol = 3,\n              f_tol = 1e-8,\n              g_tol = 1e-6,\n              x_tol = 0.0)","category":"page"},{"location":"Avaible_optimisers/#Ipopt","page":"Available optimisers","title":"Ipopt","text":"","category":"section"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Ipopt is an Interior-point Newton method designed for nonlinear optimization. In PEtab.jl, you can configure Ipopt to use either the Hessian method from the PEtabODEProblem or a LBFGS Hessian approximation.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"To use the LBFGS Hessian approximation with Ipopt write:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using Optim\nres = calibrate_model(petab_problem, p0, IpoptOptimiser(true))","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"With true indicates the use of the LBFGS approximation.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"To use the method in the PEtabODEProblem, and want to run Ipopt for 200 iterations, write:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using Ipopt\nres = calibrate_model(petab_problem, p0, IpoptOptimiser(false),\n                     options=IpoptOptions(max_iter = 200))","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"In this case, false means you are using the method defined in the PEtabODEProblem, and the max_iter option limits the optimization to 200 iterations.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"You can further configure Ipopt's behavior using IpoptOptions. Available options are:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"print_level: Output verbosity level (valid values: 0 ≤ print_level ≤ 12)\nmax_iter: Maximum number of iterations\ntol: Relative convergence tolerance\nacceptable_tol: Acceptable relative convergence tolerance\nmax_wall_time: Maximum wall time for optimization\nacceptable_obj_change_tol: Stopping criterion based on objective function change.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"If no options are provided, PEtab.jl defaults to:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using Ipopt\nIpoptOptions(;print_level::Int64=0,\n             max_iter::Int64=1000,\n             tol::Float64=1e-8,\n             acceptable_tol::Float64=1e-6,\n             max_wall_time::Float64=1e20,\n             acceptable_obj_change_tol::Float64=1e20)","category":"page"},{"location":"Avaible_optimisers/#Fides","page":"Available optimisers","title":"Fides","text":"","category":"section"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Fides.py is a trust-region Newton method known for box-constrained optimisation problems. It is particularly efficient when computing the full Hessian is computationally expensive, but a Gauss-Newton Hessian approximation is feasible.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"In PEtab.jl, you can use Fides for parameter estimation, but note that Fides is a Python library. To set up the necessary environment for Fides, make sure you have PyCall.jl installed in your Julia environment. You will also need to build PyCall with a Python environment that has Fides installed:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using PyCall\n\n# Set the path to your Python executable\npath_python_exe = \"path_python\"\n\n# Set the PYTHON environment variable to the path of your Python executable\nENV[\"PYTHON\"] = path_python_exe\n\n# Build PyCall with the specified Python environment\nimport Pkg\nPkg.build(\"PyCall\")","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"!!!note     path_python_exe should point to your Python executable, and it depends on the system configuration","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Fides can be configured to use different Hessian methods; the method from the PEtabODEProblem or various approximation methods:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":":BB: Broyden's \"bad\" method\n:BFGS: Broyden-Fletcher-Goldfarb-Shanno update strategy\n:BG: Broyden's \"good\" method\n:Broyden: BroydenClass Update scheme\n:SR1: Symmetric Rank 1 update\n:SSM: Structured Secant Method\n:TSSM: Totally Structured Secant Method","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"To use Fides with a specific Hessian approximation method, such as BFGS, write:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using PyCall\nres = calibrate_model(petab_problem, p0, Fides(:BFGS))","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"If you prefer to use the Hessian method from the PEtabODEProblem and limit Fides to 200 iterations, write:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using PyCall\nres = calibrate_model(petab_problem, p0, Fides(nothing),\n                     options=py\"{'maxiter' : 1000}\"o)","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Fides options are specified using a Python dictionary. Available options and their default values can be found in the Fides documentation.","category":"page"},{"location":"Avaible_optimisers/#Optimization_alg","page":"Available optimisers","title":"Optimization.jl","text":"","category":"section"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Optimization.jl provides a unified interface for over 100 optimization algorithms (see their documentation for the complete list). PEtab supports the conversion of a PEtabODEProblem into an OptimizationProblem, allowing any optimizer from Optimization.jl to be used.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"To convert PEtabODEProblem into an OptimizationProblem do:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using Optimization\nprob = PEtab.OptimizationProblem(petab_problem;\n                                 interior_point_alg=true,\n                                 box_constraints=true)","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"The optional keywords interior_point_alg (default false) should be set to true to use any of Optimization's interior point Newton algorithms (e.g., IPNewton or Ipopt). To use algorithms not compatible with box constraints (e.g., NewtonTrustRegion), set box_constraints to false. Disabling box-constraints might cause optimizers to move outside the parameter bounds in the petab_problem, however, potentially negatively impacting performance.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Once you have an OptimizationProblem and an initial guess p0, performing parameter estimation is straightforward through the Optimization.jl interface. For example, to use the ParticleSwarm method from Optim.jl:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"using Optimization\nusing OptimizationOptimJL                                 \nsol = solve(prob, Optim.ParticleSwarm(); reltol=1e-8)","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Solver options are set using keywords. Here we set the relative tolerance for terminating the optimization as reltol=1e-8. A full list of options can be found here.","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"It is also possible to run multi-start parameter estimation using an OptimizationProblem:","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"res = calibrate_model_multistart(optimization_problem, petab_problem, alg, \n                                 nstarts, dir_save, reltol=1e-8)","category":"page"},{"location":"Avaible_optimisers/","page":"Available optimisers","title":"Available optimisers","text":"Here, alg can be any algorithm available in Optimization.jl.","category":"page"},{"location":"Brannmark/#steady_state_conditions","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"","category":"section"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"Here we will create a PEtabODEproblem for the Brannmark model, which is a model with requires pre-equilibration before comparing the model against data. In other words, to emulate a perturbation experiment the model must first reach a steady state where du = f(u p t) approx 0 before it is matches against data. This can be achieved through simulations or root finding.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"To run the code, you will need the Brannmark PEtab files which can be found here. A fully runnable example of this tutorial is available here.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"First, we load the necessary libraries and read the model.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"using PEtab\nusing OrdinaryDiffEq\nusing Printf\n\npath_yaml = joinpath(@__DIR__, \"Brannmark\", \"Brannmark_JBC2010.yaml\")\npetab_model = PEtabModel(path_yaml, verbose=true)","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"PEtabModel for model Brannmark. ODE-system has 9 states and 23 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Brannmark/#Steady-state-solver","page":"Models with pre-equilibration (steady-state simulation)","title":"Steady-state solver","text":"","category":"section"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"When dealing with pre-equilibration models, we must first reach a steady state du = f(u p t)  0 before running the main simulation where the model is matched against data. We can do this in two ways: i) using :Rootfinding, where we use any algorithm from NonlinearSolve.jl to find the roots of f, and ii) using :Simulate, where we simulate the model from the initial condition until it reaches a steady state. The latter method is more stable and often performs better.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"When creating a PEtabODEProblem, we can set steady-state solver options via SteadyStateSolver. The first argument is the method to use, either :Rootfinding or :Simulate (recommended). For :Simulate, we can choose how to terminate the steady-state simulation using the check_simulation_steady_state argument, which accepts two options:","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":":wrms: the weighted root-mean square sqrtsum_i=1^n bigg( fracduimathrmreltol*ui + mathrmabstol bigg)  frac1n leq 1, where n is the number of ODEs.\n:Newton: if the Newton-step Delta u is sufficiently small sqrtsum_i=1^n bigg( fracDelta uimathrmreltol*ui + mathrmabstol bigg)  frac1n leq 1.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"Newton often performs better, but it requires an invertible Jacobian. If the Jacobian is non-invertible, the code automatically switches to :wrms. The default values for abstol and reltol are the tolerances of the ODE solver divided by 100.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"In the example below, we use :Simulate with :wrms termination:","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"petab_problem = PEtabODEProblem(petab_model, \n                                ode_solver=ODESolver(Rodas5P()),\n                                ss_solver=SteadyStateSolver(:Simulate, \n                                                            check_simulation_steady_state=:wrms),\n                                gradient_method=:ForwardDiff) \np = petab_problem.θ_nominalT \ngradient = zeros(length(p)) \ncost = petab_problem.compute_cost(p)\npetab_problem.compute_gradient!(gradient, p)\n@printf(\"Cost= %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"Cost = 141.89\nFirst element in the gradient = 2.70e-03","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"Some useful notes regarding the steady-state solver:","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"If you do not specify a SteadyStateSolverOption, the default option is :Simulate with :wrms.\nYou can also set a separate steady-state solver option for the gradient using ss_solver_gradient.\nAll gradient and hessian options are compatible with :Simulate. However, :Rootfinding is only compatible with approaches that use forward-mode automatic differentiation.","category":"page"},{"location":"Julia_condition_specific/#define_conditions","page":"Condition specific system/model parameters","title":"Condition Specific System/Model Parameters","text":"","category":"section"},{"location":"Julia_condition_specific/","page":"Condition specific system/model parameters","title":"Condition specific system/model parameters","text":"In some cases, certain model parameters such like a substrate enzyme binding rate may vary between experimental conditions while other parameters remain constant. These condition-specific parameters can be defined via the simulation conditions. To demonstrate how, let us consider the same enzyme kinetics model as used in the Creating a PEtab Parameter Estimation Problem in Julia tutorial.","category":"page"},{"location":"Julia_condition_specific/","page":"Condition specific system/model parameters","title":"Condition specific system/model parameters","text":"using Catalyst\nusing DataFrames\nusing Distributions\nusing PEtab\n\nrn = @reaction_network begin\n    @parameters se0\n    @species SE(t) = se0  # se0 = initial value for S\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\n\n# Define state and parameter maps\nstate_map = [:E => 1.0, :P => 0.0]\nparameter_map = [:c2 => 1.0]\n\n# Unpack model components\n@unpack P, E, SE = rn\n@parameters sigma, scale, offset\n\n# Define observables\nobs_P = PEtabObservable(scale * P + offset, sigma * P, transformation=:lin)\nobs_Sum = PEtabObservable(E + SE, 3.0, transformation=:log)\nobservables = Dict(\"obs_P\" => obs_P,\n                   \"obs_Sum\" => obs_Sum)\n\nmeasurements = DataFrame(\n    simulation_id=[\"cond0\", \"cond0\", \"cond1\", \"cond1\"],\n    obs_id=[\"obs_P\", \"obs_Sum\", \"obs_P\", \"obs_Sum\"],\n    time=[1.0, 10.0, 1.0, 20.0],\n    measurement=[0.7, 0.1, 1.0, 1.5]\n)","category":"page"},{"location":"Julia_condition_specific/","page":"Condition specific system/model parameters","title":"Condition specific system/model parameters","text":"Now, assume that for condition cond0, the substrate binding rate c1 should have a different value than under simulation condition cond1. This can be defined as follows:","category":"page"},{"location":"Julia_condition_specific/","page":"Condition specific system/model parameters","title":"Condition specific system/model parameters","text":"_c3 = PEtabParameter(:c3, scale=:log10)\n_se0 = PEtabParameter(:se, prior=LogNormal(1.0, 0.5), prior_on_linear_scale=true)\n_sigma = PEtabParameter(:sigma)\n_scale = PEtabParameter(:scale)\n_offset = PEtabParameter(:offset)\n_c1_cond0 = PEtabParameter(:c1_cond0)\n_c1_cond1 = PEtabParameter(:c1_cond1)\nparameters = [_c1_cond0, _c1_cond1, _se0, _sigma, _scale, _offset]\n\n# Define simulation conditions\ncondition_c0 = Dict(:S => 5.0, :c1 => :c1_cond0)\ncondition_c1 = Dict(:S => 2.0, :c1 => :c1_cond1)\nsimulation_conditions = Dict(\"cond0\" => condition_c0,\n                             \"cond1\" => condition_c1)","category":"page"},{"location":"Julia_condition_specific/","page":"Condition specific system/model parameters","title":"Condition specific system/model parameters","text":"When simulating the model, the value of c1_cond0 is used for simulation condition cond0, and the value of c1_cond1 is used for simulation condition cond1. With this setup, you can create a PEtabODEProblem for model calibration:","category":"page"},{"location":"Julia_condition_specific/","page":"Condition specific system/model parameters","title":"Condition specific system/model parameters","text":"petab_model = PEtabModel(\n    rn, simulation_conditions, observables, measurements,\n    parameters, state_map=state_map, parameter_map=parameter_map, verbose=true\n)\npetab_problem = PEtabODEProblem(petab_model)","category":"page"},{"location":"Julia_condition_specific/","page":"Condition specific system/model parameters","title":"Condition specific system/model parameters","text":"Note that for models with many conditions specific parameters performance can be improved by setting split_over_conditions=true when building the PEtabODEProblem, for additional information see this tutorial.","category":"page"},{"location":"Boehm/#import_petab_problem","page":"Importing problems in PEtab standard format","title":"Importing a PEtab problem","text":"","category":"section"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"In this starting tutorial, we will use the small Boehm model to demonstrate how to import a parameter-estimation problem specifed in the PEtab-format.","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"To run the code, you will need the Boehm PEtab files, which can be accessed here. For a fully functional example of this tutorial, see here.","category":"page"},{"location":"Boehm/#Reading-a-PEtab-model","page":"Importing problems in PEtab standard format","title":"Reading a PEtab model","text":"","category":"section"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"To get started, we first need to read the PEtab files into Julia. This can be easily done using PEtabModel(path_yaml), which by using the PEtab-yaml file parses the PEtab files into a PEtabModel struct. Here several things happen behind the scenes:","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"The SBML file is converted into ModelingToolkit.jl format, which allows for symbolic computation of the ODE-model Jacobian.\nThe observable PEtab table is translated into Julia functions that compute observables (h), noise parameter (sigma), and initial values (u_0).\nTo compute gradients via adjoint sensitivity analysis or forward sensitivity equations, the derivatives of h and sigma are calculated symbolically with respect to the ODE-model states (u) and parameters.","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"All of these steps happen automatically, and you can find the resulting files in the dirYamlFile/Juliamodelfiles/ directory assuming (as default) write_to_file=true, otherwise no model files are written to disk. By default, the PEtabModel constructor does not rebuild the Julia files if they already exist to save time.","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"using PEtab\nusing OrdinaryDiffEq\nusing Printf\n\npath_yaml = joinpath(@__DIR__, \"Boehm\", \"Boehm_JProteomeRes2014.yaml\")\npetab_model = PEtabModel(path_yaml, verbose=true)","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"PEtabModel for model Boehm. ODE-system has 8 states and 10 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Boehm/#Creating-a-PEtabODEProblem","page":"Importing problems in PEtab standard format","title":"Creating a PEtabODEProblem","text":"","category":"section"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"Next step is to create a PEtabODEProblem from a PEtab model, for which we use the PEtabODEProblem constructor. This constructors allows various options (see here for a full list), where the most important ones are:","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"ode_solver: This option lets us choose an ODE solver and set tolerances for the solver. For example, we can choose the Rodas5P() solver and set tolerances of abstol, reltol = 1e-8. This solver works well for smaller models with up to 15 states.\ngradient_method: This option lets us choose a gradient computation method. For small models like Boehm, forward mode automatic differentiation (AD) is the fastest method, so we choose :ForwardDiff.\nhessian_method: This option lets us choose a Hessian computation method. For small models with up to 20 parameters, it is computationally feasible to compute the full Hessian via forward-mode AD. Thus, we choose :ForwardDiff.","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"petab_problem = PEtabODEProblem(petab_model, \n                                ode_solver=ODESolver(Rodas5P(), abstol=1e-8, reltol=1e-8), \n                                gradient_method=:ForwardDiff, \n                                hessian_method=:ForwardDiff)","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"PEtabODEProblem for Boehm. ODE-states: 8. Parameters to estimate: 9 where 6 are dynamic.\n---------- Problem settings ----------\nGradient method : ForwardDiff\nHessian method : ForwardDiff\n--------- ODE-solver settings --------\nCost Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)\nGradient Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"If we don not provide any of these arguments, appropriate options are automatically selected based on the size of the problem following the guidelines in Choosing best options for a PEtab problem.","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"petab_problem = PEtabODEProblem(petab_model)","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"PEtabODEProblem for Boehm. ODE-states: 8. Parameters to estimate: 9 where 6 are dynamic.\n---------- Problem settings ----------\nGradient method : ForwardDiff\nHessian method : ForwardDiff\n--------- ODE-solver settings --------\nCost Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)\nGradient Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)","category":"page"},{"location":"Boehm/#Computing-the-cost,-gradient-and-hessian","page":"Importing problems in PEtab standard format","title":"Computing the cost, gradient and hessian","text":"","category":"section"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"The PEtabODEProblem includes all the necessary information to set up an optimization problem using most available optimizers. Its main fields are:","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"petabODEProblem.compute_cost - This field computes the cost (i.e., the objective function) for a given parameter vector θ.\npetabODEProblem.compute_gradient! - This field computes the gradient of the cost with respect to θ using the chosen method.\npetabODEProblem.compute_hessian! - This field computes the Hessian of the cost with respect to θ using the chosen method.\npetabODEProblem.lower_bounds - This field is a vector containing the lower bounds for the parameters, as specified in the PEtab parameters file.\npetabODEProblem.upper_bounds - This field is a vector containing the upper bounds for the parameters, as specified in the PEtab parameters file.\npetabODEProblem.θ_names - This field is a vector containing the names of the parameters to be estimated.","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"note: Note\nThe parameter vector θ is assumed to be on the scale specified by the PEtab parameters file. For example, if parameter i is on the log scale, then θ[i] should also be on the log scale.","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"note: Note\nThe compute_gradient! and compute_hessian! functions are in-place functions, meaning that their first argument is a pre-allocated gradient or Hessian, respectively (see below).","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"# Parameters are log-scaled\np = petab_problem.θ_nominalT \ngradient = zeros(length(p))\nhessian = zeros(length(p), length(p))\ncost = petab_problem.compute_cost(p)\npetab_problem.compute_gradient!(gradient, p)\npetab_problem.compute_hessian!(hessian, p)\n@printf(\"Cost = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])\n@printf(\"First element in the hessian = %.2f\\n\", hessian[1, 1])","category":"page"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"Cost = 138.22\nFirst element in the gradient = 2.20e-02\nFirst element in the hessian = 2199.49","category":"page"},{"location":"Boehm/#Where-to-go-from-here","page":"Importing problems in PEtab standard format","title":"Where to go from here","text":"","category":"section"},{"location":"Boehm/","page":"Importing problems in PEtab standard format","title":"Importing problems in PEtab standard format","text":"Next, if you want the estimate the model we suggest you take a look at the Parameter Estimation (Model Calibration). We also recommend Choosing best options for a PEtab problem guide. In case you want to setup the PEtab problem directory in Julia take a look at Creating a PEtab Parameter Estimation Problem in Julia","category":"page"},{"location":"Julia_steady_state/#define_with_ss","page":"Pre-equilibration (steady-state simulations)","title":"Pre-Equilibration (Steady-State Simulations)","text":"","category":"section"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"In certain scenarios, such as during perturbation experiments, the model should be at a steady state at time zero before it is matched against data. This can be achieved by defining pre-equilibration simulation conditions. To demonstrate how to use these, let us consider the same enzyme kinetics model as used in the Creating a PEtab Parameter Estimation Problem in Julia tutorial.","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"using Catalyst \nusing Distributions\nusing PEtab\n\nrn = @reaction_network begin\n    @parameters se0\n    @species SE(t) = se0  # se0 = initial value for S\n    c1, S + E --> SE\n    c2, SE --> S + E\n    c3, SE --> P + E\nend\n\n# Define state and parameter maps\nstate_map =  [:E => 1.0, :P => 0.0]\nparameter_map = [:c1 => 1.0]\n\n# Unpack model components\n@unpack P, E, SE = rn\n@parameters sigma, scale, offset\n\n# Define observables\nobs_P = PEtabObservable(scale * P + offset, sigma * P, transformation=:lin)\nobs_Sum = PEtabObservable(E + SE, 3.0, transformation=:log)\nobservables = Dict(\"obs_P\" => obs_P, \n                   \"obs_Sum\" => obs_Sum) \n\n# Define parameters for estimation\n_c3 = PEtabParameter(:c3, scale=:log10)\n_se0 = PEtabParameter(:c3, prior=LogNormal(1.0, 0.5), prior_on_linear_scale=true)\n_c2 = PEtabParameter(:c2)\n_sigma = PEtabParameter(:sigma)\n_scale = PEtabParameter(:scale)\n_offset = PEtabParameter(:offset)\nparameters = [_c2, _c3, _se0, _sigma, _scale, _offset]\n\n# Define simulation conditions\ncondition_c0 = Dict(:S => 5.0)\ncondition_c1 = Dict(:S => 2.0)\nsimulation_conditions = Dict(\"c0\" => condition_c0, \n                             \"c1\" => condition_c1)","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"Now, let us assume that before gathering data for conditions c0 and c1, 2mM of the substrate S was added to the system, which was then allowed to settle into a steady state. You can define this pre-equilibration condition (the conditions under which the system reached steady state) just like any other simulation condition and then add it to simulation_conditions.","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"condition_c_pre = Dict(:S => 2.0)\nsimulation_conditions[\"c_pre\"] = condition_c_pre","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"To ensure that the correct pre-equilibration simulation is performed when simulating the model during parameter estimation, add a new column pre_eq_id to the measurement data:","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"simulation_id (str) pre_eq_id (str) obs_id (str) time (float) measurement (float)\nc0 c_pre obs_P 1.0 0.7\nc0 c_pre obs_Sum 10.0 0.1\nc1 c_pre obs_P 1.0 1.0\nc1 c_pre obs_Sum 20.0 1.5","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"In Julia, it would look like this:","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"using DataFrames\nmeasurements = DataFrame(\n    simulation_id=[\"c0\", \"c0\", \"c1\", \"c1\"],\n    pre_eq_id=[\"c_pre\", \"c_pre\", \"c_pre\", \"c_pre\"], # Steady-state pre-eq simulations \n    obs_id=[\"obs_P\", \"obs_Sum\", \"obs_P\", \"obs_Sum\"],\n    time=[1.0, 10.0, 1.0, 20.0],\n    measurement=[0.7, 0.1, 1.0, 1.5]\n)","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"With this setup, you can create a PEtabODEProblem for model calibration:","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"petab_model = PEtabModel(\n    rn, simulation_conditions, observables, measurements,\n    parameters, state_map=state_map, parameter_map=parameter_map, verbose=true\n)\npetab_problem = PEtabODEProblem(petab_model)  ","category":"page"},{"location":"Julia_steady_state/","page":"Pre-equilibration (steady-state simulations)","title":"Pre-equilibration (steady-state simulations)","text":"Note that you can specify multiple pre-equilibration conditions if needed. For information on different SteadyStateSolver, see this tutorial.","category":"page"},{"location":"optimisation_output_plotting/#optimisation_output_plotting","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"After fitting a model's parameter to data, it is prudent to evaluate the results. The simplest approach is to simulate the model using the optimally fitting parameter set, visually inspecting its goodness of fit. However, there exist several techniques attempting to deduce whenever:","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"There exist unfound parameter sets that yield better fits than what was found (suggesting a local minimum was reached).\nThere exist additional parameter sets yielding equally good fits to what was found (suggesting an identifiability problem).","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"This section will demonstrate various plots implemented in PEtab that can be used to perform this kind of analysis. These plots can be generated by calling plot on the output of calibrate_model (a PEtabOptimisationResult structure) or calibrate_model_multistart (a PEtabMultistartOptimisationResult structure). In addition, an optional argument (plot_type) allows the selection of plot type.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"First, we load a multi start optimisation result:","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"using PEtab\nusing Plots\npetab_ms_res = PEtabMultistartOptimisationResult(joinpath(@__DIR__, \"assets\", \"optimisation_results\", \"boehm\"))\ndefault(left_margin=12.5Plots.Measures.mm, bottom_margin=12.5Plots.Measures.mm) # hide\nnothing # hide","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"next, we will, throughout the following sections, demonstrate the available types of plots using petab_ms_res as input.","category":"page"},{"location":"optimisation_output_plotting/#Objective-function-evaluations","page":"Plots evaluating parameter estimation","title":"Objective function evaluations","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"The objective function evaluations plot is accessed through the plot_type=objective argument. It is valid both for single start and multi start optimisation results. It plots, for each iteration of the optimisation process, the achieved objective value.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"For single start optimisation results, a single trajectory of dots is plotted. For a multi start optimisation result, each run correspond to a separate trajectory of dots.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"plot(petab_ms_res; plot_type=:objective)","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"Here, the runs are separated my different colours. First, a clustering process is carried out, attempting to identify runs converging to the same local minimum (the clustering, including how to customise it, is described here). Next, runs from the same cluster is assigned the same colour. A similar scheme is used for all plots involving multi start runs. When a large number of runs are carried out, it is also possible to select which one to include in the plot (by default the 10 best ones are used, however, this can be customised).","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"Sometimes, the objective function is unable to successfully simulate the model for a specific parameter set (this indicates a very poor fit). If such evaluations happen, they are marked with crosses (rather than circles) in these plots.","category":"page"},{"location":"optimisation_output_plotting/#Best-objective-function-evaluations","page":"Plots evaluating parameter estimation","title":"Best objective function evaluations","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"The best objective function evaluations plot is accessed through the plot_type=best_objective argument. It is valid both for single start and multi start optimisation results. This function is very similar to the objective function evaluation one, however, it instead plots the best value reached so far in the process (and is thus a decreasing function.) The best objective function evaluations plot is the default plot type for single start optimisation results.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"plot(petab_ms_res; plot_type=:best_objective)","category":"page"},{"location":"optimisation_output_plotting/#Waterfall-plots","page":"Plots evaluating parameter estimation","title":"Waterfall plots","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"The waterfall plot is accessed through the plot_type=waterfall argument. It is only valid for multi start optimisation results. It plots all runs' final objective values, sorted from best to worst (local minimums can typically be identified as plateaus in the plot). The waterfall plot is the default plot type for multi start optimisation results.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"plot(petab_ms_res; plot_type=:waterfall)","category":"page"},{"location":"optimisation_output_plotting/#Parallel-coordinates-plots","page":"Plots evaluating parameter estimation","title":"Parallel coordinates plots","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"The parallel coordinates plot is accessed through the plot_type=parallel_coordinates argument. It is only valid for multi start optimisation results. In it, each run corresponds to a line, drawn along its parameter values in vector of fitted parameters (starting with the first, and ending in the last, parameter). The parameter values are normalised (so that 0 corresponds to the minimum value encountered for that parameter, and 1 the maximum values). If runs in the same cluster typically share similar paths across the parameter values, this suggests that they have converged to the same local minimum. If, for one parameters, runs in the same cluster have widely different values, it suggests that that parameter is unidentifiable.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"plot(petab_ms_res; plot_type=:parallel_coordinates)","category":"page"},{"location":"optimisation_output_plotting/#Runtime-evaluation-plots","page":"Plots evaluating parameter estimation","title":"Runtime evaluation plots","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"The runtime evaluation plot is accessed through the plot_type=runtime_eval argument. It is only valid for multi start optimisation results. It is a scatter plot, showing for each run, how its final objective value depends on the runtime.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"plot(petab_ms_res; plot_type=:runtime_eval)","category":"page"},{"location":"optimisation_output_plotting/#optimisation_output_plotting_multirun_clustering","page":"Plots evaluating parameter estimation","title":"Multi start run clustering","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"When using the calibrate_model_multistart function to fit a parameter set, several independent runs are performed. In all the previous plots, a clustering function is applied to identify runs that likely have converged to the same local minimum. Runs in the same cluster are given the same colour in the plots, allowing the cluster to be identified. By default, the objective_value_clustering function is used for this (roughly, it clusters runs together if their objective function evaluates to values within 0.1 of each other). It is possible for the user to define their own clustering function, and supply it to the plot command through the clustering_function argument. The clustering function should take a Vector{PEtabOptimisationResult} input, and return an identical sized Vector{Int64} (for each index giving an integer corresponding to that run's cluster).","category":"page"},{"location":"optimisation_output_plotting/#optimisation_output_plotting_multirun_indexing","page":"Plots evaluating parameter estimation","title":"Sub-selecting runs to plot","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"When plotting a multi start output using the :objective, :best_objective, or :parallel_coordinates plot types, if the number of runs are large, it can sometimes be hard to distinguish information from the plot. Hence, for these plot types, only the 10 runs with the best final objective values are plotted. This can be modified through the best_idxs_n optional argument. This is an Int64, what number of runs to add to the plot (starting with the best one). Alternatively, the idxs optional argument can be used to give the indexes of the runs to plot.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"For the :waterfall, :runtime_eval plot types, by default all runs are plotted. However, if desired, the best_idxs_n and idxs arguments can be used for these plot types as well.","category":"page"},{"location":"optimisation_output_plotting/#Plots-comparing-the-fitted-model-to-the-measurements","page":"Plots evaluating parameter estimation","title":"Plots comparing the fitted model to the measurements","text":"","category":"section"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"After the model has been fitted, it can be useful to compare it to the measurements. This is possible by supplying both the optimisation solution, and the PEtabModel used, to the plot command. By default, it will plot, for the first condition, the output solution for all observables. However, any subset of observables can be selected (using the observable_ids option). It is also possible to select the condition using the condition_id option.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"Here, we first fit a simple model (with two observables and two conditions) to simulated data. Next, we will show various ways to plot the fitted solution.","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"# Prepare model\nusing Catalyst\nrn = @reaction_network begin\n    kB, S + E --> SE\n    kD, SE --> S + E\n    kP, SE --> P + E\nend\n\nu0 = [:E => 1.0, :SE => 0.0, :P => 0.0]\np_true = [:kB => 1.0, :kD => 0.1, :kP => 0.5]\n\n# Simulate data.\nusing OrdinaryDiffEq\n# Condition 1.\noprob_true_c1 = ODEProblem(rn,  [:S => 1.0; u0], (0.0, 10.0), p_true)\ntrue_sol_c1 = solve(oprob_true_c1, Tsit5())\ndata_sol_c1 = solve(oprob_true_c1, Tsit5(); saveat=1.0)\nc1_t, c1_E, c1_P = data_sol_c1.t[2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c1[:E][2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c1[:P][2:end]\n\n# Condition 2.\noprob_true_c2 = ODEProblem(rn,  [:S => 0.5; u0], (0.0, 10.0), p_true)\ntrue_sol_c2 = solve(oprob_true_c2, Tsit5())\ndata_sol_c2 = solve(oprob_true_c2, Tsit5(); saveat=1.0)\nc2_t, c2_E, c2_P = data_sol_c2.t[2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c2[:E][2:end], (0.8 .+ 0.4*rand(10)) .* data_sol_c2[:P][2:end]\n\n# Make PETab problem.\nusing PEtab\n@unpack E,P = rn\nobs_E = PEtabObservable(E, 0.5)\nobs_P = PEtabObservable(P, 0.5)\nobservables = Dict(\"obs_E\" => obs_E, \"obs_P\" => obs_P)\n\npar_kB = PEtabParameter(:kB)\npar_kD = PEtabParameter(:kD)\npar_kP = PEtabParameter(:kP)\nparams = [par_kB, par_kD, par_kP]\n\nc1 = Dict(:S => 1.0)\nc2 = Dict(:S => 0.5)\nsimulation_conditions = Dict(\"c1\" => c1, \"c2\" => c2)\n\nusing DataFrames\nm_c1_E = DataFrame(simulation_id=\"c1\", obs_id=\"obs_E\", time=c1_t, measurement=c1_E)\nm_c1_P = DataFrame(simulation_id=\"c1\", obs_id=\"obs_P\", time=c1_t, measurement=c1_P)\nm_c2_E = DataFrame(simulation_id=\"c2\", obs_id=\"obs_E\", time=c2_t, measurement=c2_E)\nm_c2_P = DataFrame(simulation_id=\"c2\", obs_id=\"obs_P\", time=c2_t, measurement=c2_P)\nmeasurements = vcat(m_c1_E, m_c1_P, m_c2_E, m_c2_P)\n\npetab_model = PEtabModel(rn, simulation_conditions , observables, measurements, params; state_map=u0)\npetab_problem = PEtabODEProblem(petab_model)\n\nusing Optim\nres = calibrate_model_multistart(petab_problem, IPNewton(), 50, nothing)\nnothing #hide","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"Next we plot the fitted solution for P, for the first condition (\"c1\"`):","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"using Plots\nplot(res, petab_problem; observable_ids=[\"obs_P\"], condition_id=\"c1\")","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"If we instead wish to, for the second condition, plot both observables, we use the following command:","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"plot(res, petab_problem; observable_ids=[\"obs_E\", \"obs_P\"], condition_id=\"c2\")","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"(in this example, the observable_ids option is technically not required, as plotting all observables is the default behaviour)","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"Finally, it is possible to retrieve a dictionary containing plots for all combinations of observables and conditions using:","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"comp_dict = get_obs_comparison_plots(res, petab_problem)\nnothing # hide","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"Here comp_dict contain one entry for each condition (with keys corresponding to their condition ids). These are all dictionaries, which in turn contain one entry for each observable (with keys corresponding to their observable ids). To retrieve the plot for E and \"c1\"` we use:","category":"page"},{"location":"optimisation_output_plotting/","page":"Plots evaluating parameter estimation","title":"Plots evaluating parameter estimation","text":"comp_dict[\"c1\"][\"obs_E\"]","category":"page"},{"location":"#PEtab.jl","page":"Home","title":"PEtab.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PEtab.jl is a Julia package for creating ODE parameter estimation problems in Julia. It uses Julia's DifferentialEquations.jl package for ODE solvers and ModelingToolkit.jl for symbolic model processing, which enables fast model simulations. This, combined with support for gradients via forward- and adjoint-sensitivity approaches, and hessian via both exact and approximate methods, allows for efficient parameter estimation for both small and large models.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Parameter estimation problems can be directly imported if they are specified in the PEtab standard format, alternatively problems can be directly specified in Julia where the dynamic model can be provided as a ModelingToolkit.jl ODE-system or a Catalyst reaction system. Once a problem has been parsed PEtab.jl provides wrappers to Optim, Ipopt, and Fides to perform efficient multi-start parameter estimation.","category":"page"},{"location":"","page":"Home","title":"Home","text":"In this documentation you will find:","category":"page"},{"location":"","page":"Home","title":"Home","text":"How to import a problem provided in the PEtab standard format, see here.\nHow to specify a parameter estimation problem directly in Julia, see here, with additional information on how to setup problems with:\nPre-Equilibration (Steady-State Simulations)\nNoise and Observable Parameters\nCondition specific parameters\nEvents (callbacks, dosages etc...)\nAvailable options for various specific problem types (e.g. models with steady-state simulations), see Select options for a PEtab problem.\nRecommended ODE-solvers, gradient, and Hessian methods for a parameter estimation problem, see Choosing the best options for a PEtab problem.\nHow to perform efficient parameter estimation for a PEtab problem, see Parameter estimation.\nDetails about available hessian and gradient options, see Supported gradient and hessian methods.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To install PEtab.jl in Julia in the Julia REPL enter","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> ] add PEtab","category":"page"},{"location":"","page":"Home","title":"Home","text":"or enter","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> using Pkg; Pkg.add(\"PEtab\")","category":"page"},{"location":"","page":"Home","title":"Home","text":"PEtab.jl is compatible with Julia version 1.6 and above. However, for best performance, we strongly recommend using Julia version 1.10.","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Full PEtab support, which with other things include:\nSupport for multiple observables.\nSupport for multiple simulation conditions.\nSuport for pre-equilibration (steady-state simulations).\nSupport for parameter specific to a simulation condition.\nAbility to import ODE systems defined in SBML files.\nSupport for models created in Julia, either as a ModelingToolkit.jl ODE-system or as Catalyst reaction systems.\nModel selection via PEtab Select.\nSymbolic model pre-processing using ModelingToolkit.jl.\nCompatibility with all ODE solvers in DifferentialEquations.jl.\nSeveral options for computing gradients:\nForward-mode automatic differentiation with ForwardDiff.jl.\nForward sensitivity analysis using ForwardDiff.jl or SciMLSensitivity.jl.\nAdjoint sensitivity analysis with algorithms from SciMLSensitivity.jl.\nAutomatic differentiation via Zygote.jl.\nSeveral options for computing Hessians:\nExact calculation using Forward-mode automatic differentiation with ForwardDiff.jl.\nApproximate block approach with ForwardDiff.jl.\nGauss-Newton method, which is often more performant than (L)-BFGS.\nSupport for models incorporating discrete events and logical operations.","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We will soon publish a preprint you can cite if you found PEtab.jl helpful in your work.","category":"page"},{"location":"Gradient_hessian_support/#gradient_support","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"","category":"section"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"PEtab.jl offers various gradient and Hessian methods that can be used to build a PEtabODEProblem. In this section, we will provide a brief overview of each method and the corresponding adjustable parameters.","category":"page"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"note: Note\nTo use any functionality from SciMLSensitivity (e.g. for adjoint) it must be loaded prior to creating the PEtabODEProblem. Similarly, to use Zygote automatic differentiation Zygote and SciMLSensitivity must first be loaded.","category":"page"},{"location":"Gradient_hessian_support/#Gradient-methods","page":"Supported gradient and hessian methods","title":"Gradient methods","text":"","category":"section"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":":ForwardDiff: Uses ForwardDiff to compute the gradient via forward mode automatic differentiation. You can set the chunk size using the chunksize argument to improve performance. We plan to add automatic tuning for this in the future.\n:ForwardEquations: Computes the gradient via the forward sensitivities. You can choose the method for computing sensitivities using the sensealg argument. We support both ForwardSensitivity() and ForwardDiffSensitivity(), which have adjustable options provided by SciMLSensitivity (see their documentation). The most efficient option is sensealg=:ForwardDiff though, which uses forward mode automatic differentiation to compute sensitivities.\n:Adjoint: Computes the gradient via adjoint sensitivity analysis. You can choose between the InterpolatingAdjoint and QuadratureAdjoint methods from SciMLSensitivity (see their documentation) using the sensealg argument. You can provide any options accepted by these methods.\n:Zygote: Computes the gradient using the Zygote automatic differentiation library. You can choose any of the methods provided by SciMLSensitivity using the sensealg argument.\nNote: Because the code uses many for-loops, :Zygote is the slowest option and not recommended.","category":"page"},{"location":"Gradient_hessian_support/#Hessian-methods","page":"Supported gradient and hessian methods","title":"Hessian methods","text":"","category":"section"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":":ForwardDiff: This method computes the Hessian via forward mode automatic differentiation using ForwardDiff. You can use the chunksize argument to set the chunk size, which can help improve performance. In the future, we plan to add automatic tuning for this parameter.\n:BlockForwardDiff: This method computes a Hessian block approximation via forward mode automatic differentiation using ForwardDiff. For PEtab models, there are typically two sets of parameters to estimate: the parameters that are part of the ODE system theta_p and those that are not theta_q. This method computes the Hessian for each block and assumes that cross-terms are zero-valued. The resulting Hessian block takes the form:","category":"page"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"H_block =\nbeginbmatrix\nH_p  mathbf0 \nmathbf0  mathbfH_q\nendbmatrix","category":"page"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":":GaussNewton: This method computes a Hessian approximation using the Gauss-Newton method. It often performs better than a (L)-BFGS approximation, but requires access to sensitivities, which may only be feasible to compute for smaller models with 75 or fewer parameters.","category":"page"}]
}
