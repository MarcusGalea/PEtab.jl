var documenterSearchIndex = {"docs":
[{"location":"Parameter_estimation/#parameter_estimation","page":"Parameter estimation","title":"Optimization (Parameter Estimation)","text":"","category":"section"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtab.jl seamlessly integrates with various optimization packages such as Optim.jl, Ipopt.jl, and Fides.py. Check out our examples, or see below, to see how it is done.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"For parameter estimation in ODE models used in systems biology, a widely adopted approach is multi-start local optimization. In this method, a local optimizer is run from a large number (around 100-1000) of random start-guesses. These start-guesses are efficiently generated using techniques like Latin-hypercube sampling to explore the parameter space effectively. When it comes to selecting the optimizer, based on extensive benchmarks, here's a useful rule of thumb:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"If you can provide a full Hessian, the Interior-point Newton method in Optim.jl generally outperforms the trust-region method in Fides.py.\nIf you can only provide a Gauss-Newton Hessian approximation (not the full Hessian), the Newton trust-region method in Fides.py usually outperforms the interior-point method in Optim.jl.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtab.jl offers a lightweight interface for performing multi-start parameter estimation with Optim.jl and Fides.py (see below).","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"note: Note\nKeep in mind that each problem is unique, and although the suggested options are generally effective, they may not always be the ideal choice for a particular model.","category":"page"},{"location":"Parameter_estimation/#Parameter-estimation-using-Optim.jl","page":"Parameter estimation","title":"Parameter estimation using Optim.jl","text":"","category":"section"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"For Optim.jl in PEtab.jl, we provide support for three methods:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"IPNewton(): Interior point Newton method.\nLBFGS(): Newton's method with LBFGS Hessian approximation and box-constraints (Fminbox).\nBFGS(): Newton's method with BFGS Hessian approximation and box-constraints (Fminbox).","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"To perform parameter estimation, you can use the calibrateModel function. This function requires a PEtabODEProblem, an optimization algorithm, and the following keyword options:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"nOptimisationStarts::Int: The number of multi-starts to be performed. The default value is 100.\nsamplingMethod: The method for generating start guesses. It supports any method from QuasiMonteCarlo.jl, with LatinHypercube being the default.\noptions: Optimization options. For Optim.jl optimizers, it accepts an Optim.Options struct.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Here's an example where we run a 50 multi-start for the Boehm model using the Interior-point method and Latin-Hypercube sampling to generate the start-guesses:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"using Optim\nimport QuasiMonteCarlo\nfvals, xvals = callibrateModel(petabProblem, IPNewton(), \n                               nOptimisationStarts=5, \n                               samplingMethod=QuasiMonteCarlo.LatinHypercubeSample(), \n                               options=Optim.Options(show_trace = false, iterations=200))\n@printf(\"Best found value = %.3f\\n\", minimum(fvals))","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Best found value = 138.222","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Note that via Optim.Options we set the maximum number of iterations to 200.","category":"page"},{"location":"Parameter_estimation/#Parameter-estimation-using-Fides.py","page":"Parameter estimation","title":"Parameter estimation using Fides.py","text":"","category":"section"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Fides.py is a trust-region Newton method that excels when computing the full Hessian is computationally expensive but we can compute the Gauss-Newton Hessian approximation.","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Fides (specifically, Newton trust-region with box-constraints) is not available directly in Julia. Therefore, to use it, you need to call a Python library. To set up the necessary environment, make sure you have PyCall.jl installed. Next you must build PyCall with a Python environment that has Fides installed (note: pathToPythonExe depends on your system configuration):","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"pathToPythonExe = joinpath(\"/\", \"home\", \"sebpe\", \"anaconda3\", \"envs\", \"PeTab\", \"bin\", \"python\")\nENV[\"PYTHON\"] = pathToPythonExe\nimport Pkg; Pkg.build(\"PyCall\")","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Fides always computes the cost, gradient, and Hessian at each iteration. Therefore, if you use the Gauss-Newton Hessian approximation, you can reuse the forward sensitivities (reuseS=true) from the gradient calculation by setting gradientMethod=:ForwardEquations in the createPEtabODEProblem function:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(Rodas5P()), \n                                     gradientMethod=:ForwardEquations, \n                                     hessianMethod=:GaussNewton, \n                                     sensealg=:ForwardDiff, \n                                     reuseS=true)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"PEtabODEProblem for Boehm. ODE-states: 8. Parameters to estimate: 9 where 6 are dynamic.\n---------- Problem settings ----------\nGradient method : ForwardEquations\nHessian method : GaussNewton\n--------- ODE-solver settings --------\nCost Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)\nGradient Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Now, you can proceed with the parameter estimation:","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"fvals, xvals = calibrateModel(petabProblem, Fides(verbose=false), \n                              nOptimisationStarts=5, \n                              samplingMethod=QuasiMonteCarlo.LatinHypercubeSample(), \n                              options=py\"{'maxiter' : 200}\"o)\n@printf(\"Best found value = %.3f\\n\", minimum(fvals))     ","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Best found value = 147.544","category":"page"},{"location":"Parameter_estimation/","page":"Parameter estimation","title":"Parameter estimation","text":"Please note that since Fides is a Python package, when providing options, they must be in the form of a Python dictionary using the py\"...\" string.","category":"page"},{"location":"Bachmann/#Medium-sized-models-(Bachmann-model)","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium-sized models (Bachmann model)","text":"","category":"section"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"In this tutorial, we will guide you through the process of creating a PEtabODEproblem for the Bachmann model, a medium-sized ODE model. We'll cover three topics:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Computing the gradient via forward-sensitivity equations\nComputing the gradient via adjoint sensitivity analysis\nComputing the Gauss-Newton Hessian approximation, which often performs better than the (L)-BFGS Hessian approximation.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"To run the code, you'll need the Bachmann PEtab files, which can be found here. You can find a fully runnable example of this tutorial here.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"First, we'll read the model and load the necessary libraries.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"using PEtab\nusing OrdinaryDiffEq\nusing Sundials # For CVODE_BDF\nusing Printf\n \npathYaml = joinpath(@__DIR__, \"Bachmann\", \"Bachmann_MSB2011.yaml\") \npetabModel = readPEtabModel(pathYaml, verbose=true)","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"PEtabModel for model Bachmann. ODE-system has 25 states and 39 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Bachmann/#Adjoint-sensitivity-analysis","page":"Medium sized models and adjoint sensitivity analysis","title":"Adjoint sensitivity analysis","text":"","category":"section"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"When working with a subset of medium and definitely for large-sized models, the most efficient way to compute gradients is through adjoint sensitivity analysis (gradientMethod=:Adjoint). There are several tuneable options that can improve performance, including:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"odeSolverGradientOptions: This determines which ODE solver and solver tolerances (abstol and reltol) to use when computing the gradient (i.e., when solving the adjoint ODE-system). Currently, the best performing stiff solver for the adjoint problem in Julia is CVODE_BDF().\nsensealg: This determines which adjoint algorithm to use. Currently, InterpolatingAdjoint and QuadratureAdjoint from SciMLSensitivity are supported. You can find more information in their documentation. You can provide any of the options that these methods are compatible with. For example, if you want to use the ReverseDiffVJP algorithm, an acceptable option is sensealg=InterpolatingAdjoint(autojacvec=ReversDiffVJP()).","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Here are a few things to keep in mind:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Note1: Adjoint sensitivity analysis is not as reliable in Julia as it is in AMICI. However, our benchmarks show that SciMLSensitivity has the potential to be faster.\nNote2: Compilation times for adjoint sensitivity analysis can be quite substantial.\nNote3: In the example below, we use QNDF() for the cost, which is often one of the best Julia solvers for larger models.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"using SciMLSensitivity # For adjoint\npetabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(QNDF(), abstol=1e-8, reltol=1e-8), \n                                     odeSolverGradientOptions=ODESolverOptions(CVODE_BDF(), abstol=1e-8, reltol=1e-8),\n                                     gradientMethod=:Adjoint, \n                                     sensealg=InterpolatingAdjoint(autojacvec=EnzymeVJP())) \np = petabProblem.θ_nominalT \ngradient = zeros(length(p)) \ncost = petabProblem.computeCost(p)\npetabProblem.computeGradient!(gradient, p)\n@printf(\"Cost = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Cost = -418.41\nFirst element in the gradient = -1.70e-03","category":"page"},{"location":"Bachmann/#Forward-sensitivity-analysis-and-Gauss-Newton-hessian-approximation","page":"Medium sized models and adjoint sensitivity analysis","title":"Forward sensitivity analysis and Gauss-Newton hessian approximation","text":"","category":"section"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"For medium-sized models, computing the full Hessian via forward-mode automatic differentiation can be too expensive, so we need an approximation. The Gauss-Newton (GN) approximation often performs better than the (L)-BFGS approximation. To compute it, we need the forward sensitivities. These sensitivities can also be used to compute the gradient. As some optimizers such as Fides.py compute both the Hessian and gradient at each iteration, we can save the sensitivities between the gradient and Hessian computations.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"When choosing gradientMethod=:ForwardEquations and hessianMethod=:GaussNewton, there are several tunable options, the key ones are:","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"sensealg - which sensitivity algorithm to use when computing the sensitivities. We support both ForwardSensitivity() and ForwardDiffSensitivity() with tunable options as provided by SciMLSensitivity (see their documentation for more information). The most efficient option is :ForwardDiff, where forward-mode automatic differentiation is used to compute the sensitivities.\nreuseS::Bool - whether or not to reuse the sensitivities from the gradient computations when computing the Gauss-Newton Hessian approximation. Whether this option is applicable depends on the optimizer. For example, it works with Fides.py but not with Optim.jl's IPNewton().\nNote - this approach requires that sensealg=:ForwardDiff for the gradient.","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(QNDF(), abstol=1e-8, reltol=1e-8),\n                                     gradientMethod=:ForwardEquations, \n                                     hessianMethod=:GaussNewton,\n                                     sensealg=:ForwardDiff, \n                                     reuseS=true) \np = petabProblem.θ_nominalT \ngradient = zeros(length(p)) \nhessian = zeros(length(p), length(p)) \ncost = petabProblem.computeCost(p)\npetabProblem.computeGradient!(gradient, p)\npetabProblem.computeHessian!(hessian, p)\n@printf(\"Cost for Bachmann = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])\n@printf(\"First element in the Gauss-Newton Hessian = %.2f\\n\", hessian[1, 1])","category":"page"},{"location":"Bachmann/","page":"Medium sized models and adjoint sensitivity analysis","title":"Medium sized models and adjoint sensitivity analysis","text":"Cost for Bachmann = -418.41\nFirst element in the gradient = -1.85e-03\nFirst element in the Gauss-Newton Hessian = 584.10","category":"page"},{"location":"Beer_julia_import/#Beer_Julia_import","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"","category":"section"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"In this tutorial, we'll demonstrate how to create a PEtabODEproblem problem using a Julia model file instead of an SBML file.","category":"page"},{"location":"Beer_julia_import/#Create-the-model-file","page":"Providing the model as a Julia file instead of an SBML File","title":"Create the model file","text":"","category":"section"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"To start, we'll create a .jl file that utilizes ModelingToolkit.jl to define a system:","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"function BeerODEModel()\n\n    ModelingToolkit.@variables t Glu(t) cGlu(t) Ind(t) Bac(t) lag(t)\n    ModelingToolkit.@parameters kdegi medium Bacmax ksyn kdim tau init_Bac beta\n\n    ### Store dependent variables in array for ODESystem command\n    stateArray = [Glu, cGlu, Ind, Bac]\n    ### Store parameters in array for ODESystem command\n    parameterArray = [kdegi, medium, Bacmax, ksyn, kdim, tau, init_Bac, beta]\n\n    ### Equations\n    EquationList = [\n    Differential(t)(Glu) ~ -Bac * Glu * ksyn,\n    Differential(t)(cGlu) ~ Bac * Glu * ksyn - (cGlu)^(2) * kdim,\n    Differential(t)(Ind) ~ cGlu^2 * kdim - Ind * kdegi,\n    Differential(t)(Bac) ~ Bac * beta * lag * (Bacmax - Bac) / Bacmax,\n    lag ~ ifelse(t - tau < 0, 0, 1)\n    ]\n\n    @named odeSystem = ODESystem(EquationList, t, stateArray, parameterArray)\n\n    ### Initial species concentrations ###\n    initialValues = [\n    Glu => 10.0,\n    cGlu => 0.0,\n    Ind => 0.0,\n    Bac => init_Bac\n    ]\n\n    ### SBML file parameter values ###\n    parameterValues = [\n    kdegi => 1.0,\n    Bacmax => 1.0,\n    ksyn => 1.0,\n    kdim => 1.0,\n    tau => 1.0,\n    init_Bac => 0.0147007946993721,\n    beta => 1.0\n    ]\n\n    return odeSystem, initialValues, parameterValues\nend\n","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"NOTE - If you are providing a model directly in Julia, there are a few things you need to keep in mind:","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"The model must be defined within a function, like BeerODEModel, which returns the odeSystem, initialValues, and parameterValues in that order (the names of the variables don't matter).\nThe states and parameters must be stored in arrays, like stateArray and parameterArray, and provided as arguments when creating the ODESystem. Otherwise, a parameter might get simplified away in the symbolic pre-processing.\nWhen creating the initial-value map, like initialValues, the initial values can be constants or a mathematical expression that depends on parameters. For example, Glu => kdegi / tau would be an acceptable option.\nIf you have an event, like a dosage or a time delay (like lag), encode it using an ifelse statement. This will later be rewritten to a callback (event) In the example above we included ifelse(t - tau < 0, 0, 1) to capture:","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"    lag = \n    begincases\n        0 quad t leq  tau \n        1 quad t   tau \n    endcases","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"For more information on how to specify the model in the ModelingToolkit.jl format, please refer to their documentation.","category":"page"},{"location":"Beer_julia_import/#Import-the-model-file","page":"Providing the model as a Julia file instead of an SBML File","title":"Import the model file","text":"","category":"section"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"To import the Julia model, we need to set the path to Julia file via the variable jlFilePath. By doing so, we inform readPEtabModel to skip searching for an SBML file and instead import the Julia model:","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"using PEtab\nusing OrdinaryDiffEq\nusing Printf\n\npathYaml = joinpath(@__DIR__, \"Beer\", \"Beer_MolBioSystems2014.yaml\") \npathJuliaFile = joinpath(@__DIR__, \"Beer\", \"Julia_import_files\", \"Beer_Julia_Import.jl\")\npetabModel = readPEtabModel(pathYaml, verbose=true, jlFilePath=pathJuliaFile)","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"PEtabModel for model Beer. ODE-system has 4 states and 9 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Beer_julia_import/","page":"Providing the model as a Julia file instead of an SBML File","title":"Providing the model as a Julia file instead of an SBML File","text":"Moving forward, you can use the imported model similar to any other model imported from an SBML-file. To get an idea of how to use the wpetabModel` to compute the cost, gradient or hessian for an ODE parameter estimation problem, please refer to the tutorial for the Beer model.","category":"page"},{"location":"Model_selection/#Model-selection-with-PEtab-Select","page":"Model selection (PEtab select)","title":"Model selection with PEtab Select","text":"","category":"section"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"In many scenarios we have competing hypotheses (model structures) that we want to compare. For model selection, various approaches like forward search, backward search, and exhaustive search using evaluation criteria such as AIC are commonly used. These methods are supported by PEtab Select, a tool designed for model selection.","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"PEtab.jl provides support for PEtab Select through the runPEtabSelect function. This function takes two required arguments; the path to the PEtab Select YAML file, and the optimizer for parameter estimation. For the optimizer, you can choose from optimizer=Fides() (Fides Newton-trust region), optimizer=IPNewton() from Optim.jl, or optimizer=LBFGS() from Optim.jl (see). Additionally, you can pass any keyword arguments accepted by the calibrateModel function for parameter estimation and createPEtabODEProblem function for setting simulation options (see).","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"Since PEtab Select is a Python package, you need to have PyCall.jl installed. Before using it, build PyCall with a Python environment that has PEtab select installed. Here's an example of how to do it (note that pathToPythonExe depends on your system configuration):","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"pathToPythonExe = joinpath(\"/\", \"home\", \"sebpe\", \"anaconda3\", \"envs\", \"PeTab\", \"bin\", \"python\")\nENV[\"PYTHON\"] = pathToPythonExe\nimport Pkg; Pkg.build(\"PyCall\")","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"Once you have a correctly encoded PEtab Select problem (see the guide for details), you can run PEtab Select using the IPNewton() optimizer with the following code:","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"using PEtab \nusing OrdinaryDiffEq\nusing Optim\n\npathYAML = joinpath(@__DIR__, \"PEtab_select\", \"0002\", \"petab_select_problem.yaml\")\npathSave = runPEtabSelect(pathYAML, IPNewton(), \n                          nOptimisationStarts=10, \n                          odeSolverOptions=ODESolverOptions(Rodas5P()),\n                          gradientMethod=:ForwardDiff, \n                          hessianMethod=:ForwardDiff)","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"┌ Info: PEtab select problem info\n│ Method: forward\n└ Criterion: AIC\n[ Info: Model selection round 1 with 1 candidates - as the code compiles in this round compiled it takes extra long time https://xkcd.com/303/\n[ Info: Callibrating model M1_0\n[ Info: Model selection round 2 with 3 candidates\n[ Info: Callibrating model M1_1\n[ Info: Callibrating model M1_2\n[ Info: Callibrating model M1_3\n[ Info: Model selection round 3 with 2 candidates\n[ Info: Callibrating model M1_5\n[ Info: Callibrating model M1_6\n[ Info: Model selection round 4 with 1 candidates\n[ Info: Callibrating model M1_7\n[ Info: Saving results for best model at 0002/PEtab_select_forward_AIC.yaml","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"The YAML file storing the model selection results will be saved at pathSave.","category":"page"},{"location":"Model_selection/","page":"Model selection (PEtab select)","title":"Model selection (PEtab select)","text":"To run the code, you will need the PEtab files, which you can find here. You can also find a fully runnable example of this tutorial here.","category":"page"},{"location":"Beer/#Beer_tut","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"","category":"section"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"This tutorial demonstrates how to create a PEtabODEproblem for a small ODE-model with many parameters to estimate. Specifically, the ODE-system has leq 20 states and leq 20 parameters, but there are approximately 70 parameters to estimate, since most parameters are specific to a subset of simulation conditions. For example, cond1 has a parameter τcond1, and cond2 has τcond2, which maps to the ODE-system parameter τ, respectively.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"To run the code, you need the Beer PEtab files, which you can find here. You can also find a fully runnable example of this tutorial here.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"First, we load the necessary libraries and read the model.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"using PEtab\nusing OrdinaryDiffEq\nusing Printf\n\npathYaml = joinpath(@__DIR__, \"Beer\", \"Beer_MolBioSystems2014.yaml\") \npetabModel = readPEtabModel(pathYaml, verbose=true)","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"PEtabModel for model Beer. ODE-system has 4 states and 9 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Beer/#Handling-condition-specific-parameters","page":"Models with many conditions specific parameters","title":"Handling condition-specific parameters","text":"","category":"section"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"When dealing with small ODE-systems like Beer, the most efficient gradient method is gradientMethod=:ForwardDiff. Additionally, we can compute the hessian via hessianMethod=:ForwardDiff. However, since there are several condition-specific parameters in Beer, we have to perform as many forward-passes (solve the ODE model) as there are model-parameters when we compute the gradient and hessian via a single call to ForwardDiff.jl. To address this issue, we can use the option splitOverConditions=true to force one ForwardDiff.jl call per simulation condition. This is most efficient for models where a majority of parameters are specific to a subset of simulation conditions.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"For a model like Beer, the following options are thus recommended:","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"odeSolverOptions - Rodas5P() (works well for smaller models with up to 15 states) and we use the default abstol, reltol .= 1e-8.\ngradientMethod - For small models like Beer, forward mode automatic differentiation (AD) is the fastest, so we choose :ForwardDiff.\nhessianMethod - For small models like Boehm with up to 20 parameters, it is computationally feasible to compute the full Hessian via forward-mode AD. Thus, we choose :ForwardDiff.\nsplitOverConditions=true - This forces a call to ForwardDiff.jl per simulation condition.","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"odeSolverOptions = ODESolverOptions(Rodas5P(), abstol=1e-8, reltol=1e-8)\npetabProblem = createPEtabODEProblem(petabModel, odeSolverOptions, \n                                    gradientMethod=:ForwardDiff, \n                                    hessianMethod=:ForwardDiff, \n                                    splitOverConditions=true)\n\np = petabProblem.θ_nominalT\ngradient = zeros(length(p))\nhessian = zeros(length(p), length(p))\ncost = petabProblem.computeCost(p)\npetabProblem.computeGradient!(gradient, p)\npetabProblem.computeHessian!(hessian, p)\n@printf(\"Cost = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])\n@printf(\"First element in the hessian = %.2f\\n\", hessian[1, 1])","category":"page"},{"location":"Beer/","page":"Models with many conditions specific parameters","title":"Models with many conditions specific parameters","text":"Cost = -58622.91\nFirst element in the gradient = 7.17e-02\nFirst element in the hessian = 755266.33","category":"page"},{"location":"API_choosen/#API","page":"API","title":"API","text":"","category":"section"},{"location":"API_choosen/","page":"API","title":"API","text":"PEtabModel\nreadPEtabModel\nPEtabODEProblem\ncreatePEtabODEProblem\nODESolverOptions\nSteadyStateSolverOptions\nremakePEtabProblem\nFides\ncallibrateModel\nrunPEtabSelect","category":"page"},{"location":"API_choosen/#PEtab.PEtabModel","page":"API","title":"PEtab.PEtabModel","text":"PEtabModel\n\nA Julia-compatible representation of a PEtab-specified problem.\n\nCreated by readPEtabModel, this object contains helper functions for setting up cost, gradient, and Hessian computations, as well as handling potential model events (callbacks).\n\nNote1: Several of the functions in PEtabModel are not intended to be accessed by the user. For example, compute_h (and similar functions) require indices that are built in the background to efficiently map parameters between experimental (simulation) conditions. Rather, PEtabModel holds all information needed to create a PEtabODEProblem, and in the future, PEtabSDEProblem, etc.\n\nNote2: ODEProblem.p refers to the parameters for the underlying DifferentialEquations.jl ODEProblem.\n\nFields\n\nmodelName: The model name extracted from the PEtab YAML file.\ncompute_h: Computes the observable h for a specific time point and simulation condition.\ncompute_u0!: Computes in-place initial values using ODEProblem.p for a simulation condition; compute_u0!(u0, p).\ncompute_u0: Computes initial values as above, but not in-place; u0 = compute_u0(p).\ncompute_σ: Computes the noise parameter σ for a specific time point and simulation condition.\ncompute_∂h∂u!: Computes the gradient of h with respect to ODEModel states (u) for a specific time point and simulation condition.\ncompute_∂σ∂u!: Computes the gradient of σ with respect to ODEModel states (u) for a specific time point and simulation condition.\ncompute_∂h∂p!: Computes the gradient of h with respect to ODEProblem.p.\ncompute_∂σ∂p!: Computes the gradient of σ with respect to ODEProblem.p.\ncomputeTStops: Computes the event times in case the model has DiscreteCallbacks (events).\nconvertTspan::Bool: Tracks whether the time span should be converted to Dual numbers for ForwardDiff.jl gradients, in case the model has DiscreteCallbacks and the trigger time is a parameter set to be estimated.\ndirModel: The directory where the model.xml and PEtab files are stored.\ndirJulia: The directory where the Julia-model files created by parsing the PEtab files (e.g., SBML file) are stored.\nodeSystem: A ModellingToolkit.jl ODE system obtained from parsing the model SBML file.\nparameterMap: A ModellingToolkit.jl parameter map for the ODE system.\nstateMap: A ModellingToolkit.jl state map for the ODE system describing how the initial values are computed, e.g., whether or not certain initial values are computed from parameters in the parameterMap.\nparameterNames: The names of the parameters in the odeSystem.\nstateNames: The names of the states in the odeSystem.\npathMeasurements: The path to the PEtab measurements file.\npathConditions: The path to the PEtab conditions file.\npathObservables: The path to the PEtab observables file.\npathParameters: The path to the PEtab parameters file.\npathSBML: The path to the PEtab SBML file.\npathYAML: The path to the PEtab YAML file.\nmodelCallbackSet: This stores potential model callbacks or events.\ncheckIfCallbackIsActive: Piecewise SBML statements are transformed to DiscreteCallbacks that are activated at a specific time-point. The piecewise callback has a default value at t0 and is only triggered when reaching tactivation. If tactivation ≤ 0 (never reached when solving the model), this function checks whether the callback should be triggered before solving the model.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.readPEtabModel","page":"API","title":"PEtab.readPEtabModel","text":"readPEtabModel(pathYAML::String;\n               forceBuildJuliaFiles::Bool=false,\n               verbose::Bool=true,\n               ifElseToEvent::Bool=true,\n               jlFilePath::String=\"\")::PEtabModel\n\nParses a PEtab specified problem with a YAML-file located at pathYAML into a Julia-accessible format.\n\nWhen parsing a PEtab problem, several things happen under the hood:\n\nThe SBML file is translated into ModelingToolkit.jl format to allow for symbolic computations of the ODE-model Jacobian. Piecewise and model events are further written into DifferentialEquations.jl callbacks.\nThe observable PEtab table is translated into a Julia file with functions for computing the observable (h), noise parameter (σ), and initial values (u0).\nTo allow gradients via adjoint sensitivity analysis and/or forward sensitivity equations, the gradients of h and σ are computed symbolically with respect to the ODE model's states (u) and parameters (odeProblem.p).\n\nAll of this happens automatically, and resulting files are stored under petabModel.dirJulia. To save time, forceBuildJlFiles=false by default, which means that Julia files are not rebuilt if they already exist.\n\nIn case a Julia model files is provided instead of a SBML file provide file path under jlFilePath.\n\nArguments\n\npathYAML::String: Path to the PEtab problem YAML file.\nforceBuildJuliaFiles::Bool=false: If true, forces the creation of Julia files for the problem even if they already exist.\nverbose::Bool=true: If true, displays verbose output during parsing.\nifElseToEvent::Bool=true: If true, rewrites if-else statements in the SBML model as event-based callbacks.\njlFilePath::String=\"\": Path to an existing Julia file. Should only be provided if a Julia model file is availble.\n\nExample\n\npetabModel = readPEtabModel(\"path/to/petab/problem.yaml\")\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.PEtabODEProblem","page":"API","title":"PEtab.PEtabODEProblem","text":"PEtabODEProblem\n\nEverything needed to setup an optimization problem (compute cost, gradient, hessian and parameter bounds) for a PEtab model.\n\nnote: Note\nThe parameter vector θ is always assumed to be on the parameter scale specified in the PEtab parameters file. If needed, θ is transformed to the linear scale inside the function call.\n\nFields\n\ncomputeCost: For θ computes the negative likelihood (objective to minimize)\ncomputeChi2: For θ compute χ2 value\ncomputeGradient!: For θ computes in-place gradient computeGradient!(gradient, θ)\ncomputeGradient: For θ computes out-place gradient gradient = computeGradient(θ)\ncomputeHessian!: For θ computes in-place hessian-(approximation) computeHessian!(hessian, θ)\ncomputeHessian: For θ computes out-place hessian-(approximation) hessian = computeHessian(θ)\ncomputeSimulatedValues: For θ compute the corresponding model (simulated) values to the measurements in the same order as in the Measurements PEtab table\ncomputeResiduals: For θ compute the residuals (hmodel - hobserved)^2 / σ^2 in the same order as in the Measurements PEtab table\ngradientMethod: The method used to compute the gradient (either :ForwardDiff, :ForwardEquations, :Adjoint, or :Zygote).\nhessianMethod: The method used to compute or approximate the Hessian (either :ForwardDiff, :BlocForwardDiff, or :GaussNewton).\nnParametersToEstimate: The number of parameters to estimate.\nθ_estNames: The names of the parameters in θ.\nθ_nominal: The nominal values of θ as specified in the PEtab parameters file.\nθ_nominalT: The nominal values of θ on the parameter scale (e.g., log) as specified in the PEtab parameters file.\nlowerBounds: The lower parameter bounds on the parameter scale for θ as specified in the PEtab parameters file.\nupperBounds: The upper parameter bounds on the parameter scale for θ as specified in the PEtab parameters file.\npetabModel: The PEtabModel used to construct the PEtabODEProblem.\nodeSolverOptions: The options for the ODE solver specified when creating the PEtabODEProblem.\nodeSolverGradientOptions: The options for the ODE solver gradient specified when creating the PEtabODEProblem.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.createPEtabODEProblem","page":"API","title":"PEtab.createPEtabODEProblem","text":"createPEtabODEProblem(petabModel::PEtabModel; <keyword arguments>)\n\nGiven a PEtabModel creates a PEtabODEProblem with potential user specified options.\n\nThe keyword arguments (described below) allow the user to choose cost, gradient, and Hessian methods, ODE solver options, and other tuneable options that can potentially make computations more efficient for some \"edge-case\" models. Please refer to the documentation for guidance on selecting the most efficient options for different types of models.\n\nIf a keyword argument is not set, a suitable default option is chosen based on the number of model parameters.\n\nnote: Note\nEvery problem is unique, so even though the default settings often work well they might not be optimal.\n\nKeyword arguments\n\nodeSolverOptions::ODESolverOptions: Options for the ODE solver when computing the cost, such as solver and tolerances.\nodeSolverGradientOptions::ODESolverOptions: Options for the ODE solver when computing the gradient, such as the ODE solver options used in adjoint sensitivity analysis. Defaults to odeSolverOptions if not set to nothing.\nssSolverOptions::SteadyStateSolverOptions: Options for finding steady-state for models with pre-equilibrium. Steady-state can be found via simulation or rootfinding, which can be set using SteadyStateSolverOptions (see documentation). If not set, defaults to simulation with wrms < 1 termination.\nssSolverGradientOptions::SteadyStateSolverOptions: Options for finding steady-state for models with pre-equilibrium when computing gradients. Defaults to ssSolverOptions value if not set.\ncostMethod::Symbol=:Standard: Method for computing the cost (objective). Two options are available: :Standard, which is the most efficient, and :Zygote, which is less efficient but compatible with the Zygote automatic differentiation library.\ngradientMethod=nothing: Method for computing the gradient of the objective. Four options are available:\n:ForwardDiff: Compute the gradient via forward-mode automatic differentiation using ForwardDiff.jl. Most efficient for models with ≤50 parameters. The number of chunks can be optionally set using chunkSize.\n:ForwardEquations: Compute the gradient via the model sensitivities, where sensealg specifies how to solve for the sensitivities. Most efficient when the Hessian is approximated using the Gauss-Newton method and when the optimizer can reuse the sensitivities (reuseS) from gradient computations in Hessian computations (e.g., when the optimizer always computes the gradient before the Hessian).\n:Adjoint: Compute the gradient via adjoint sensitivity analysis, where sensealg specifies which algorithm to use. Most efficient for large models (≥75 parameters).\n:Zygote: Compute the gradient via the Zygote package, where sensealg specifies which sensitivity algorithm to use when solving the ODE model. This is the most inefficient option and not recommended.\nhessianMethod=nothing: method for computing the Hessian of the cost. There are three available options:\n:ForwardDiff: Compute the Hessian via forward-mode automatic differentiation using ForwardDiff.jl. This is often only computationally feasible for models with ≤20 parameters but can greatly improve optimizer convergence.\n:BlockForwardDiff: Compute the Hessian block approximation via forward-mode automatic differentiation using ForwardDiff.jl. The approximation consists of two block matrices: the first is the Hessian for only the dynamic parameters (parameter part of the ODE system), and the second is for the non-dynamic parameters (e.g., noise parameters). This is computationally feasible for models with ≤20 dynamic parameters and often performs better than BFGS methods.\n:GaussNewton: Approximate the Hessian via the Gauss-Newton method, which often performs better than the BFGS method. If we can reuse the sensitivities from the gradient in the optimizer (see reuseS), this method is best paired with gradientMethod=:ForwardEquations.\nsparseJacobian::Bool=false: When solving the ODE du/dt=f(u, p, t), whether implicit solvers use a sparse Jacobian. Sparse Jacobian often performs best for large models (≥100 states).\nspecializeLevel=SciMLBase.FullSpecialize: Specialization level when building the ODE problem. It is not recommended to change this parameter (see https://docs.sciml.ai/SciMLBase/stable/interfaces/Problems/).\nsensealg: Sensitivity algorithm for gradient computations. The available options for each gradient method are:\n:ForwardDiff: None (as ForwardDiff takes care of all computation steps).\n:ForwardEquations: :ForwardDiff (uses ForwardDiff.jl and typicaly performs best) or ForwardDiffSensitivity() and ForwardSensitivity() from SciMLSensitivity.jl (https://github.com/SciML/SciMLSensitivity.jl).\n:Adjoint: InterpolatingAdjoint() and QuadratureAdjoint() from SciMLSensitivity.jl.\n:Zygote: All sensealg in SciMLSensitivity.jl.\nsensealgSS=nothing: Sensitivity algorithm for adjoint gradient computations for steady-state simulations. The available options are SteadyStateAdjoint(), InterpolatingAdjoint(), and QuadratureAdjoint() from SciMLSensitivity.jl. SteadyStateAdjoint() is the most efficient but requires a non-singular Jacobian, and in the case of a non-singular Jacobian, the code automatically switches to InterpolatingAdjoint().\nchunkSize=nothing: Chunk-size for ForwardDiff.jl when computing the gradient and Hessian via forward-mode automatic differentiation. If nothing is provided, the default value is used. Tuning chunkSize is non-trivial, and we plan to add automatic functionality for this.\nsplitOverConditions::Bool=false: For gradient and Hessian via ForwardDiff.jl, whether or not to split calls to ForwardDiff across experimental (simulation) conditions. This parameter should only be set to true if the model has many parameters specific to an experimental condition; otherwise, the overhead from the calls will increase run time. See the Beer example for a case where this is needed.\nreuseS::Bool=false : If set to true, reuse the sensitivities computed during gradient computations for the Gauss-Newton Hessian approximation. This option is only applicable when using hessianMethod=:GaussNewton and gradientMethod=:ForwardEquations. Note that it should only be used when the optimizer always computes the gradient before the Hessian.\nverbose::Bool=true : If set to true, print progress messages while setting up the PEtabODEProblem.\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.ODESolverOptions","page":"API","title":"PEtab.ODESolverOptions","text":"ODESolverOptions(solver, <keyword arguments>)\n\nODE-solver options (solver, tolerances, etc...) to use when computing gradient/cost for a PEtabODEProblem.\n\nMore information about the available options and solvers can be found in the documentation for DifferentialEquations.jl (https://docs.sciml.ai/DiffEqDocs/stable/solvers/ode_solve/). Recommended settings for which solver and options to use for different problems can be found below and in the documentation.\n\nArguments\n\nsolver: Any of the ODE solvers in DifferentialEquations.jl. For small (≤20 states) mildly stiff models, composite solvers such as AutoVern7(Rodas5P()) perform well. For stiff small models, Rodas5P() performs well. For medium-sized models (≤75 states), QNDF(), FBDF(), and CVODE_BDF() perform well. CVODE_BDF() is not compatible with automatic differentiation and thus cannot be used if the gradient is computed via automatic differentiation or if the Gauss-Newton Hessian approximation is used. If the gradient is computed via adjoint sensitivity analysis, CVODE_BDF() is often the best choice as it is typically more reliable than QNDF() and FBDF() (fails less often).\nabstol=1e-8: Absolute tolerance when solving the ODE system. Not recommended to increase above 1e-6 for gradients.\nreltol=1e-8: Relative tolerance when solving the ODE system. Not recommended to increase above 1e-6 for gradients.\nforce_dtmin=false: Whether or not to force dtmin when solving the ODE system.\ndtmin=nothing: Minimal acceptable step-size when solving the ODE system.\nmaxiters=10000: Maximum number of iterations when solving the ODE system. Increasing above the default value can cause the optimization to take substantial time.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.SteadyStateSolverOptions","page":"API","title":"PEtab.SteadyStateSolverOptions","text":"SteadyStateSolverOptions(method::Symbol;\n                         howCheckSimulationReachedSteadyState::Symbol=:wrms,\n                         rootfindingAlgorithm=nothing,\n                         abstol=nothing,\n                         reltol=nothing,\n                         maxiters=nothing)\n\nSetup options for finding steady-state via either method=:Rootfinding or method=:Simulate.\n\nFor method=:Rootfinding, the steady-state u* is found by solving the problem du = f(u, p, t) ≈ 0 with tolerances abstol and reltol via an automatically chosen optimization algorithm (rootfindingAlgorithm=nothing) or via any algorithm in NonlinearSolve.jl.\n\nFor method=:Simulate, the steady-state u* is found by simulating the ODE system until du = f(u, p, t) ≈ 0. Two options are available for howCheckSimulationReachedSteadyState:\n\n:wrms : Weighted root-mean square √(∑((du ./ (reltol * u .+ abstol)).^2) / length(u)) < 1\n:Newton : If Newton-step Δu is sufficiently small √(∑((Δu ./ (reltol * u .+ abstol)).^2) / length(u)) < 1.       - Newton often performs better but requires an invertible Jacobian. In case it's not fulfilled, the code switches automatically to :wrms.\n\nmaxiters refers to either the maximum number of rootfinding steps or the maximum number of integration steps, depending on the chosen method.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.remakePEtabProblem","page":"API","title":"PEtab.remakePEtabProblem","text":"remakePEtabProblem(petabProblem::PEtabODEProblem, parametersChange::Dict) :: PEtabODEProblem\n\nFixate model parameters for a given PEtabODEProblem without recompiling the problem.\n\nThis function allows you to modify parameters without the need to recompile the underlying code, resulting in reduced latency. To fixate the parameter k1, you can use parametersChange=Dict(:k1 => 1.0).\n\nIf model derivatives are computed using ForwardDiff.jl with a chunk-size of N, the new PEtabODEProblem will only evaluate the necessary number of chunks of size N to compute the full gradient for the remade problem.\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.Fides","page":"API","title":"PEtab.Fides","text":"Fides\n\nFides is a Python Newton-trust region optimizer for box-bounded optimization problems.\n\nIt is particularly effective when the full Hessian cannot be computed, but the Gauss-Newton Hessian approximation can be computed. If constructed with Fides(verbose=true), it prints optimization progress during the process.\n\n\n\n\n\n","category":"type"},{"location":"API_choosen/#PEtab.callibrateModel","page":"API","title":"PEtab.callibrateModel","text":"calibrateModel(petabProblem::PEtabODEProblem,\n               optimizer;\n               <keyword arguments>)\n\nPerform multi-start local optimization for a given PEtabODEProblem and return (fmin, minimizer) for all runs.\n\nArguments\n\npetabProblem::PEtabODEProblem: The PEtabODEProblem to be calibrated.\noptimizer: The optimizer algorithm to be used. Currently, we support three different algorithms:\nFides(): The Newton trust-region Fides optimizer from Python. Please refer to the documentation for setup  examples. This optimizer performs well when computing the full Hessian is not possible, and the Gauss-Newton Hessian approximation can be used.\nIPNewton(): The interior-point Newton method from Optim.jl. This optimizer performs well when it is  computationally feasible to compute the full Hessian.\nLBFGS() or BFGS() from Optim.jl: These optimizers are suitable when the computation of the Gauss-Newton  Hessian approximation is too expensive, such as when adjoint sensitivity analysis is required for the gradient.\nnOptimisationStarts::Int: Number of multi-starts to be performed. Defaults to 100.\nsamplingMethod: Method for generating start guesses. Any method from QuasiMonteCarlo.jl is supported, with LatinHypercube as the default.\noptions: Optimization options. For Optim.jl optimizers, it accepts an Optim.Options struct. For Fides, please refer to the Fides documentation and the PEtab.jl documentation for information on setting options.\n\n\n\n\n\n","category":"function"},{"location":"API_choosen/#PEtab.runPEtabSelect","page":"API","title":"PEtab.runPEtabSelect","text":"runPEtabSelect(pathYAML, optimizer; <keyword arguments>)\n\nGiven a PEtab-select YAML file perform model selection with the algorithms specified in the YAML file.\n\nResults are written to a YAML file in the same directory as the PEtab-select YAML file.\n\nEach candidate model produced during the model selection undergoes parameter estimation using local multi-start optimization. Three optimizers are supported: optimizer=Fides() (Fides Newton-trust region), optimizer=IPNewton() from Optim.jl, and optimizer=LBFGS() from Optim.jl. Additional keywords for the optimisation are nOptimisationStarts::Int- number of multi-starts for parameter estimation (defaults to 100) and optimizationSamplingMethod - which is any sampling method from QuasiMonteCarlo.jl for generating start guesses (defaults to LatinHypercubeSample). See also (add callibrate model)\n\nSimulation options can be set using any keyword argument accepted by the createPEtabODEProblem function. For example, setting gradientMethod=:ForwardDiff specifies the use of forward-mode automatic differentiation for gradient computation. If left blank, we automatically select appropriate options based on the size of the problem.\n\n\n\n\n\n","category":"function"},{"location":"Best_options/#best_options","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"PEtab.jl provides several gradient and hessian methods that can be used with the ODE solvers in the DifferentialEquations.jl package. You can choose from a variety of options when creating a PEtabODEProblem using the createPEtabODEProblem function. If you don't specify any of these options, appropriate options will be selected automatically based on an extensive benchmark study. These default options usually work well for specific problem types. In the following section, we will discuss the main findings of the benchmark study.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"note: Note\nThese recommendations often work well for specific problem types, they may not be optimal for every model, as each problem is unique.","category":"page"},{"location":"Best_options/#Small-models-(\\leq-20-parameters-and-\\leq-15-ODE:s)","page":"Choosing the best options for a PEtab problem","title":"Small models (leq 20 parameters and leq 15 ODE:s)","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"ODE solver: For small stiff models, the Rosenbrock Rodas5P() solver is often the fastest and most accurate option. While Julia bdf-solvers such as QNDF() can also perform well, they are often less reliable and less accurate than Rodas5P(). If the model is \"mildly\" stiff, composite solvers such as AutoVern7(Rodas5P()) often perform best. Regardless of solver, we recommend using low tolerances (around abstol, reltol = 1e-8, 1e-8) to obtain accurate gradients.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Gradient method: For small models, forward-mode automatic differentiation via ForwardDiff.jl tends to be the best performing option, and is often twice as fast as the forward-sensitivity equations approach in AMICI. Therefore, we recommend using gradientMethod=:ForwardDiff.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Note1 - For :ForwardDiff, the user can set the chunk-size, which can substantially improve performance. We plan to add automatic tuning of this in the future.\nNote2 - If the model has many simulation condition-specific parameters (parameters that only appear in a subset of simulation conditions), it can be efficient to set splitOverConditions=true (see this tutorial).","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Hessian method: For small models, it is computationally feasible to compute an accurate full Hessian via ForwardDiff.jl. For most models we benchmarked, using a provided Hessian improved convergence. Therefore, we recommend using hessianMethod=:ForwardDiff.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Note1 - For models with pre-equilibration (steady-state simulations), our benchmarks suggest that it might be better to use the Gauss-Newton Hessian approximation.\nNote2 - For models where it is too expensive to compute the full Hessian (e.g. due to many simulation conditions), the Hessian block approximation can be a good option.\nNote3 - In particular, the interior-point Newton method from Optim.jl performs well if provided with a full Hessian.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Overall, for a small model, a good setup often includes:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(Rodas5P(), abstol=1e-8, reltol=1e-8), \n                                     gradientMethod=:ForwardDiff, \n                                     hessianMethod=:ForwardDiff)","category":"page"},{"location":"Best_options/#Medium-sized-models-(\\leq-75-parameters-and-\\leq-50-ODE:s)","page":"Choosing the best options for a PEtab problem","title":"Medium-sized models (leq 75 parameters and leq 50 ODE:s)","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"ODE solver: For medium-sized stiff models, bdf-solvers like QNDF() are often fast enough and accurate. However, they can fail for certain models with many events when low tolerances are used. In such cases, KenCarp4() is a good alternative. Another option is Sundials' CVODE_BDF(), but it's written in C++ and not compatible with forward-mode automatic differentiation. To obtain accurate gradients, we recommend using low tolerances (around abstol, reltol = 1e-8, 1e-8) regardless of solver.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Gradient method: For medium-sized models, when using the Gauss-Newton method to approximate the Hessian, we recommend computing the gradient via the forward sensitivities (gradientMethod=:ForwardEquations), where the sensitivities are computed via forward-mode automatic differentiation (sensealg=:ForwardDiff). This way, the sensitivities can be reused when computing the Hessian if the optimizer always computes the gradient first. Otherwise, if a BFGS Hessian-approximation is used, gradientMethod=:ForwardDiff often performs best.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Note1 - For :ForwardDiff, the user can set the chunk-size to improve performance, and we plan to add automatic tuning of it.\nNote2 - If the model has many simulation condition-specific parameters (parameters that only appear in a subset of simulation conditions), it can be efficient to set splitOverConditions=true (see this tutorial).","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Hessian method: For medium-sized models, it's often computationally infeasible to compute an accurate full Hessian via ForwardDiff.jl. Instead, we recommend the Gauss-Newton Hessian approximation, which often performs better than the commonly used (L)-BFGS approximation. Thus, we recommend hessianMethod=:GaussNewton.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Note1 - Trust-region Newton methods like Fides.py perform well if provided with a full Hessian. Interior-point methods don't perform as well.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Overall, when the gradient is always computed before the Hessian in the optimizer, a good setup is often:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(QNDF(), abstol=1e-8, reltol=1e-8),\n                                     gradientMethod=:ForwardEquations, \n                                     hessianMethod=:GaussNewton, \n                                     reuseS=true)","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Otherwise, a good setup is:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(QNDF(), abstol=1e-8, reltol=1e-8),\n                                     gradientMethod=:ForwardDiff, \n                                     hessianMethod=:GaussNewton)","category":"page"},{"location":"Best_options/#Large-models-(\\geq-75-parameters-and-\\geq-50-ODE:s)","page":"Choosing the best options for a PEtab problem","title":"Large models (geq 75 parameters and geq 50 ODE:s)","text":"","category":"section"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"ODE solver: To efficiently solve large models, we recommend benchmarking different ODE solvers such as QNDF(), FBDF(), KenCarp4(), and CVODE_BDF(). You can also try providing the ODE solver with a sparse Jacobian (sparseJacobian::Bool=false) and testing different linear solvers such as CVODE_BDF(linsolve=:KLU). Check out this link for more information on solving large stiff models.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Note - It's important to compare different ODE solvers, as this can significantly reduce runtime.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Gradient method: For large models, the most scalable approach is adjoint sensitivity analysis (gradientMethod=:Adjoint). We support InterpolatingAdjoint() and QuadratureAdjoint() from SciMLSensitivity (see their documentation for info), but we recommend InterpolatingAdjoint() because it's more reliable.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Note1 - When using adjoint sensitivity analysis, we recommend manually setting the ODE solver gradient options. Currently, CVODE_BDF() outperforms all native Julia solvers.\nNote2 - You can provide any options that InterpolatingAdjoint() and QuadratureAdjoint() accept.\nNote3 - Adjoint sensitivity analysis is not as reliable in Julia as in AMICI (see), but our benchmarks show that SciMLSensitivity has the potential to be faster.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"Hessian method: For large models, computing the sensitives (Gauss-Newton) or a full hessian is not computationally feasible. Thus, the best option is often to use an L-(BFGS) approximation. BFGS support is built into most available optimizers such as Optim.jl, Ipopt.jl, and Fides.py.","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"All in all, for a large model, a good setup often is:","category":"page"},{"location":"Best_options/","page":"Choosing the best options for a PEtab problem","title":"Choosing the best options for a PEtab problem","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(CVODE_BDF(), abstol=1e-8, reltol=1e-8), \n                                     odeSolverGradientOptions=ODESolverOptions(CVODE_BDF(), abstol=1e-8, reltol=1e-8),\n                                     gradientMethod=:Adjoint, \n                                     sensealg=InterpolatingAdjoint()) ","category":"page"},{"location":"Brannmark/#Models-with-pre-equilibration-(steady-state-simulation)","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"","category":"section"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"In this tutorial, we'll create a PEtabODEproblem for the Brannmark model, which requires pre-equilibration before comparing the model against data. In other words, the model must first reach a steady state where du = f(u p t) approx 0 before it is matches against data. This can be achieved through simulations or root finding.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"To run the code, you will need the Brannmark PEtab files which can be found here. A fully runnable example of this tutorial is available here.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"First, we load the necessary libraries and read the model.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"using PEtab\nusing OrdinaryDiffEq\nusing Printf\n\npathYaml = joinpath(@__DIR__, \"Brannmark\", \"Brannmark_JBC2010.yaml\")\npetabModel = readPEtabModel(pathYaml, verbose=true)","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"PEtabModel for model Brannmark. ODE-system has 9 states and 23 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Brannmark/#Steady-state-solver","page":"Models with pre-equilibration (steady-state simulation)","title":"Steady-state solver","text":"","category":"section"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"When dealing with pre-equilibration models, we must first reach a steady state du = f(u p t)  0 before running the main simulation. We can do this in two ways: i) using :Rootfinding, where we use any algorithm from NonlinearSolve.jl to find the roots of f, and ii) using :Simulate, where we simulate the model from the initial condition until it reaches a steady state. The latter method is more stable and often performs better.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"When creating a PEtabODEProblem, we can set steady-state solver options via SteadyStateSolverOptions. The first argument is the method to use, either :Rootfinding or :Simulate (recommended). For :Simulate, we can choose how to terminate the steady-state simulation using the howCheckSimulationReachedSteadyState argument, which accepts two options:","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":":wrms: the weighted root-mean square sqrtsum_i=1^n bigg( fracduimathrmreltol*ui + mathrmabstol bigg)  frac1n leq 1, where n is the number of ODEs.\n:Newton: if the Newton-step Delta u is sufficiently small sqrtsum_i=1^n bigg( fracDelta uimathrmreltol*ui + mathrmabstol bigg)  frac1n leq 1.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"Newton often performs better, but it requires an invertible Jacobian. If the Jacobian is non-invertible, the code automatically switches to :wrms. The default values for abstol and reltol are the tolerances of the ODE solver divided by 100.","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"In the example below, we use :Simulate with :wrms termination:","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(Rodas5P()),\n                                     ssSolverOptions=SteadyStateSolverOptions(:Simulate,\n                                                     howCheckSimulationReachedSteadyState=:wrms),\n                                     gradientMethod=:ForwardDiff) \np = petabProblem.θ_nominalT \ngradient = zeros(length(p)) \ncost = petabProblem.computeCost(p)\npetabProblem.computeGradient!(gradient, p)\n@printf(\"Cost= %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"Cost = 141.89\nFirst element in the gradient = 2.70e-03","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"Some useful notes regarding the steady-state solver:","category":"page"},{"location":"Brannmark/","page":"Models with pre-equilibration (steady-state simulation)","title":"Models with pre-equilibration (steady-state simulation)","text":"If you do not specify a SteadyStateSolverOption, the default option is :Simulate with :wrms.\nYou can also set a separate steady-state solver option for the gradient using ssSolverGradientOptions.\nAll gradient and hessian options are compatible with :Simulate. However, :Rootfinding is only compatible with approaches that use forward-mode automatic differentiation.","category":"page"},{"location":"Boehm/#Getting-started","page":"Getting started","title":"Getting started","text":"","category":"section"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"In this starting tutorial, we will use the small Boehm model to demonstrate the key features of PEtab.jl.","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"To run the code, you will need the Boehm PEtab files, which can be accessed here. For a fully functional example of this tutorial, please visit this link.","category":"page"},{"location":"Boehm/#Reading-a-PEtab-model","page":"Getting started","title":"Reading a PEtab model","text":"","category":"section"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"To get started, we first need to read the PEtab files into Julia. This can be easily done using the PEtab.jl package. Once we provide the path to the PEtab yaml-file, PEtab.jl reads all the PEtab files and creates a PEtabModel struct. Here are some of the things that happen behind the scenes:","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"The SBML file is converted into ModelingToolkit.jl format, which allows for symbolic computation of the ODE-model Jacobian.\nThe observable PEtab table is translated into Julia functions that compute observables (h), noise parameter (sigma), and initial values (u_0).\nTo compute gradients via adjoint sensitivity analysis or forward sensitivity equations, the derivatives of h and sigma are calculated symbolically with respect to the ODE-model states (u) and parameters.","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"All of these steps happen automatically, and you can find the resulting files in the dirYamlFile/Juliamodelfiles/ directory. By default, the readPEtabModel function does not rebuild the Julia files if they already exist, so it saves time.","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"using PEtab\nusing OrdinaryDiffEq\nusing Printf\n\npathYaml = joinpath(@__DIR__, \"Boehm\", \"Boehm_JProteomeRes2014.yaml\")\npetabModel = readPEtabModel(pathYaml, verbose=true)","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"PEtabModel for model Boehm. ODE-system has 8 states and 10 parameters.\nGenerated Julia files are at ...","category":"page"},{"location":"Boehm/#Creating-a-PEtabODEProblem","page":"Getting started","title":"Creating a PEtabODEProblem","text":"","category":"section"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"To create a PEtabODEProblem from a PEtab model, we use the createPEtabODEProblem function. This function allows us to customize various options (see the API documentation for a full list), but the most important ones are:","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"odeSolverOptions: This option lets us choose an ODE solver and set tolerances for the solver. For example, we can choose the Rodas5P() solver and set tolerances of abstol, reltol = 1e-8. This solver works well for smaller models with up to 15 states.\ngradientMethod: This option lets us choose a gradient computation method. For small models like Boehm, forward mode automatic differentiation (AD) is the fastest method, so we choose :ForwardDiff.\nhessianMethod: This option lets us choose a Hessian computation method. For small models with up to 20 parameters, it is computationally feasible to compute the full Hessian via forward-mode AD. Thus, we choose :ForwardDiff.","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"petabProblem = createPEtabODEProblem(petabModel, \n                                     odeSolverOptions=ODESolverOptions(Rodas5P(), abstol=1e-8, reltol=1e-8), \n                                     gradientMethod=:ForwardDiff, \n                                     hessianMethod=:ForwardDiff)","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"PEtabODEProblem for Boehm. ODE-states: 8. Parameters to estimate: 9 where 6 are dynamic.\n---------- Problem settings ----------\nGradient method : ForwardDiff\nHessian method : ForwardDiff\n--------- ODE-solver settings --------\nCost Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)\nGradient Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"If we don't provide any of these arguments, we automatically select appropriate options based on the size of the problem following the guidelines in Choosing best options for a PEtab problem.","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"petabProblem = createPEtabODEProblem(petabModel)","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"PEtabODEProblem for Boehm. ODE-states: 8. Parameters to estimate: 9 where 6 are dynamic.\n---------- Problem settings ----------\nGradient method : ForwardDiff\nHessian method : ForwardDiff\n--------- ODE-solver settings --------\nCost Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)\nGradient Rodas5P(). Options (abstol, reltol, maxiters) = (1.0e-08, 1.0e-08, 1.0e+04)","category":"page"},{"location":"Boehm/#Computing-the-cost,-gradient-and-hessian","page":"Getting started","title":"Computing the cost, gradient and hessian","text":"","category":"section"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"The PEtabODEProblem includes all the necessary information to set up an optimization problem using most available optimizers. Its main fields are:","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"petabODEProblem.computeCost - This field computes the cost (i.e., the objective function) for a given parameter vector θ.\npetabODEProblem.computeGradient! - This field computes the gradient of the cost with respect to θ using the chosen method.\npetabODEProblem.computeHessian! - This field computes the Hessian of the cost with respect to θ using the chosen method.\npetabODEProblem.lowerBounds - This field is a vector containing the lower bounds for the parameters, as specified in the PEtab parameters file.\npetabODEProblem.upperBounds - This field is a vector containing the upper bounds for the parameters, as specified in the PEtab parameters file.\npetabODEProblem.θ_estNames - This field is a vector containing the names of the parameters to be estimated.","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"Note1 - The parameter vector θ is assumed to be on the scale specified by the PEtab parameters file. For example, if parameter i is on the log scale, then θ[i] should also be on the log scale.\nNote2 - The computeGradient! and computeHessian! functions are in-place functions, meaning that their first argument is a pre-allocated gradient or Hessian, respectively (see below).","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"# Parameters are log-scaled\np = petabProblem.θ_nominalT \ngradient = zeros(length(p))\nhessian = zeros(length(p), length(p))\ncost = petabProblem.computeCost(p)\npetabProblem.computeGradient!(gradient, p)\npetabProblem.computeHessian!(hessian, p)\n@printf(\"Cost = %.2f\\n\", cost)\n@printf(\"First element in the gradient = %.2e\\n\", gradient[1])\n@printf(\"First element in the hessian = %.2f\\n\", hessian[1, 1])","category":"page"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"Cost = 138.22\nFirst element in the gradient = 2.20e-02\nFirst element in the hessian = 2199.49","category":"page"},{"location":"Boehm/#Where-to-go-from-here","page":"Getting started","title":"Where to go from here","text":"","category":"section"},{"location":"Boehm/","page":"Getting started","title":"Getting started","text":"Next, we suggest you take a look at the Choosing best options for a PEtab problem guide. Additionally, we recommend exploring the Supported gradient and hessian methods section. In case you want to provide your model-file as a Julia-file instead of an SBML file take a look at Providing a model as a Julia file instead of an SBML File.","category":"page"},{"location":"#PEtab.jl","page":"Home","title":"PEtab.jl","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"This is the documentation of PEtab.jl, a Julia package designed to import ODE parameter estimation problems specified in the PEtab format into Julia.","category":"page"},{"location":"","page":"Home","title":"Home","text":"PEtab.jl uses Julia's DifferentialEquations.jl package for ODE solvers and ModelingToolkit.jl for symbolic model processing, which enables fast model simulations. This, combined with support for gradients via forward- and adjoint-sensitivity approaches, and hessian via both exact and approximate methods, allows for efficient parameter estimation for both small and large models. In an extensive benchmark study, PEtab.jl was found to be 3-4 times faster than the PyPesto toolbox that leverages the AMICI interface to the Sundials suite.","category":"page"},{"location":"","page":"Home","title":"Home","text":"This documentation includes:","category":"page"},{"location":"","page":"Home","title":"Home","text":"A guide for getting started with PEtab.jl\nTutorials on medium-sized models, small models with several condition-specific parameters, models with pre-equilibration onditions (steady-state simulations), and how to define and import a model written in Julia.\nDetails about available hessian and gradient options.\nDiscussion of the best options for specific model types, including small, medium, and large models.","category":"page"},{"location":"#Installation","page":"Home","title":"Installation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"To read SBML files PEtab.jl uses the Python python-libsbml library which can be installed via:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pip install python-libsbml","category":"page"},{"location":"","page":"Home","title":"Home","text":"Given this PEtab.jl can be installed via","category":"page"},{"location":"","page":"Home","title":"Home","text":"julia> ] add PEtab","category":"page"},{"location":"#Feature-list","page":"Home","title":"Feature list","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"PEtab.jl provides a range of features to import and analyze ODE parameter estimation problems specified in the PEtab format. These include:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Importing ODE systems specified either by an SBML file or as a Julia file.\nModel selection via PEtab Select.\nSymbolic model pre-processing via ModelingToolkit.jl.\nSupport for all ODE solvers in DifferentialEquations.jl.\nGradient calculations using several approaches:\nForward-mode automatic differentiation with ForwardDiff.jl.\nForward sensitivity analysis with ForwardDiff.jl or SciMLSensitivity.jl.\nAdjoint sensitivity analysis with any of the algorithms in SciMLSensitivity.jl.\nAutomatic differentiation via Zygote.jl.\nHessians computed via:\nForward-mode automatic differentiation with ForwardDiff.jl (exact).\nBlock approach with ForwardDiff.jl (approximate).\nGauss-Newton method (approximate and often more performant than (L)-BFGS).\nHandling pre-equilibration and pre-simulation conditions.\nSupport for models with discrete events and logical operations.","category":"page"},{"location":"#Citation","page":"Home","title":"Citation","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"We will soon publish a preprint you can cite if you found PEtab.jl helpful in your work.","category":"page"},{"location":"Gradient_hessian_support/#gradient_support","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"","category":"section"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"PEtab.jl offers various gradient and Hessian methods that can be used to build a PEtabODEProblem using createPEtabODEProblem(). In this section, we will provide a brief overview of each method and the corresponding adjustable parameters.","category":"page"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"note: Note\nTo use any functionality from SciMLSensitivity (e.g. for adjoint) it must be loaded prior to creating the PEtabODEProblem. Similarly, to use Zygote automatic differentiation Zygote and SciMLSensitivity must first be loaded.","category":"page"},{"location":"Gradient_hessian_support/#Gradient-methods","page":"Supported gradient and hessian methods","title":"Gradient methods","text":"","category":"section"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":":ForwardDiff: Uses ForwardDiff to compute the gradient via forward mode automatic differentiation. You can set the chunk size using the chunkSize argument to improve performance. We plan to add automatic tuning for this in the future.\n:ForwardEquations: Computes the gradient via the forward sensitivities. You can choose the method for computing sensitivities using the sensealg argument. We support both ForwardSensitivity() and ForwardDiffSensitivity(), which have adjustable options provided by SciMLSensitivity (see their documentation). The most efficient option is sensealg=:ForwardDiff though, which uses forward mode automatic differentiation to compute sensitivities.\n:Adjoint: Computes the gradient via adjoint sensitivity analysis. You can choose between the InterpolatingAdjoint and QuadratureAdjoint methods from SciMLSensitivity (see their documentation) using the sensealg argument. You can provide any options accepted by these methods.\n:Zygote: Computes the gradient using the Zygote automatic differentiation library. You can choose any of the methods provided by SciMLSensitivity using the sensealg argument.\nNote: Because the code uses many for-loops, :Zygote is the slowest option and not recommended.","category":"page"},{"location":"Gradient_hessian_support/#Hessian-methods","page":"Supported gradient and hessian methods","title":"Hessian methods","text":"","category":"section"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":":ForwardDiff: This method computes the Hessian via forward mode automatic differentiation using ForwardDiff. You can use the chunkSize argument to set the chunk size, which can help improve performance. In the future, we plan to add automatic tuning for this parameter.\n:BlockForwardDiff: This method computes a Hessian block approximation via forward mode automatic differentiation using ForwardDiff. For PEtab models, there are typically two sets of parameters to estimate: the parameters that are part of the ODE system theta_p and those that are not theta_q. This method computes the Hessian for each block and assumes that cross-terms are zero-valued. The resulting Hessian block takes the form:","category":"page"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":"H_block = \nbeginbmatrix\nH_p  mathbf0 \nmathbf0  mathbfH_q\nendbmatrix","category":"page"},{"location":"Gradient_hessian_support/","page":"Supported gradient and hessian methods","title":"Supported gradient and hessian methods","text":":GaussNewton: This method computes a Hessian approximation using the Gauss-Newton method. It often performs better than a (L)-BFGS approximation, but requires access to sensitivities, which may only be feasible to compute for smaller models with 75 or fewer parameters. ","category":"page"}]
}
